<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>&lt;未完成&gt;深度学习基础——神经网络关键知识点简记</title>
      <link href="/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%B3%E9%94%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AE%80%E8%AE%B0/"/>
      <url>/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%B3%E9%94%AE%E7%9F%A5%E8%AF%86%E7%82%B9%E7%AE%80%E8%AE%B0/</url>
      
        <content type="html"><![CDATA[<p>前文中介绍了一些用TensorFlow实现神经网络的例子，但是如果你不懂神经网络的一些基础概念的话，会看得一头雾水。所以本文将介绍以下神经网络中常用的关键知识点：</p><ul><li>前向传播与误差反向传播</li><li>激活函数</li><li>softmax算法</li><li>损失函数</li><li>优化器</li></ul><p>当然侧重点还是在使用上，目的是让您理解使用的道理即可，不会涉及过多原理、底层算法知识等。</p><a id="more"></a><h1 id="1-神经元的拟合原理"><a href="#1-神经元的拟合原理" class="headerlink" title="1 神经元的拟合原理"></a>1 神经元的拟合原理</h1><h2 id="1-1-前向传播"><a href="#1-1-前向传播" class="headerlink" title="1.1 前向传播"></a>1.1 前向传播</h2><h2 id="1-2-BP算法介绍"><a href="#1-2-BP算法介绍" class="headerlink" title="1.2 BP算法介绍"></a>1.2 BP算法介绍</h2><h1 id="2-激活函数"><a href="#2-激活函数" class="headerlink" title="2 激活函数"></a>2 激活函数</h1><h2 id="2-1-sigmod"><a href="#2-1-sigmod" class="headerlink" title="2.1 sigmod"></a>2.1 sigmod</h2><h2 id="2-2-tanh"><a href="#2-2-tanh" class="headerlink" title="2.2 tanh"></a>2.2 tanh</h2><h2 id="2-3-relu"><a href="#2-3-relu" class="headerlink" title="2.3 relu"></a>2.3 relu</h2><h2 id="2-4-选择合适的激活函数"><a href="#2-4-选择合适的激活函数" class="headerlink" title="2.4 选择合适的激活函数"></a>2.4 选择合适的激活函数</h2><h1 id="3-softmax算法"><a href="#3-softmax算法" class="headerlink" title="3 softmax算法"></a>3 softmax算法</h1><h1 id="4-损失函数"><a href="#4-损失函数" class="headerlink" title="4 损失函数"></a>4 损失函数</h1><h2 id="4-1-二次代价函数"><a href="#4-1-二次代价函数" class="headerlink" title="4.1 二次代价函数"></a>4.1 二次代价函数</h2><h2 id="4-2-交叉熵"><a href="#4-2-交叉熵" class="headerlink" title="4.2 交叉熵"></a>4.2 交叉熵</h2><h2 id="4-3-选择合适的损失函数"><a href="#4-3-选择合适的损失函数" class="headerlink" title="4.3 选择合适的损失函数"></a>4.3 选择合适的损失函数</h2><h1 id="5-优化器"><a href="#5-优化器" class="headerlink" title="5 优化器"></a>5 优化器</h1><h2 id="5-1-梯度下降"><a href="#5-1-梯度下降" class="headerlink" title="5.1 梯度下降"></a>5.1 梯度下降</h2><h2 id="5-2-Adam"><a href="#5-2-Adam" class="headerlink" title="5.2 Adam"></a>5.2 Adam</h2><h2 id="5-3-TensorFlow中的优化器"><a href="#5-3-TensorFlow中的优化器" class="headerlink" title="5.3 TensorFlow中的优化器"></a>5.3 TensorFlow中的优化器</h2><h1 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6 参考资料"></a>6 参考资料</h1><p>[1]李金洪.深度学习之TensorFlow:入门、原理与进阶实战[M].北京:机械工业出版社.2018-01</p><p>（未完待续）</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> 激活函数 </tag>
            
            <tag> 损失函数 </tag>
            
            <tag> softmax </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo博客中加入代码块复制功能</title>
      <link href="/Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8A%A0%E5%85%A5%E4%BB%A3%E7%A0%81%E5%9D%97%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD/"/>
      <url>/Hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%8A%A0%E5%85%A5%E4%BB%A3%E7%A0%81%E5%9D%97%E5%A4%8D%E5%88%B6%E5%8A%9F%E8%83%BD/</url>
      
        <content type="html"><![CDATA[<p>技术文章里怎么能没有代码复制功能，一键复制是多么提高效率的一件事啊。本文就将教你给博客添加代码复制这个功能。</p><a id="more"></a><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本人使用的是Hexo的NexT主题，NexT版本为v6.1。事实上，在NexT主题的v6.3版本里已经加入了代码复制这个功能，所以如果你刚开始使用NexT，直接升级主题，并在主题配置文件中打开代码复制的开关就好了。</p><p>因为本人对此NexT主题已经改动了不少源码，升级的话会很麻烦，所以便考虑自己加入这个功能。好了，废话不多说了，开始正题。</p><h1 id="1-添加copy-code-swig"><a href="#1-添加copy-code-swig" class="headerlink" title="1 添加copy-code.swig"></a>1 添加copy-code.swig</h1><p>在博客根目录下，输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> themes/next/layout/_third-party/</span><br></pre></td></tr></table></figure><p>然后在此文件夹下创建名为<code>copy-code.swig</code>的文件，在此文件中输入以下内容：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">&#123;% if theme.codeblock.copy_button.enable %&#125;</span><br><span class="line">  <span class="tag">&lt;<span class="name">style</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">    .copy-btn &#123;</span></span><br><span class="line"><span class="undefined">      display: inline-block;</span></span><br><span class="line"><span class="undefined">      padding: 6px 12px;</span></span><br><span class="line"><span class="undefined">      font-size: 13px;</span></span><br><span class="line"><span class="undefined">      font-weight: 700;</span></span><br><span class="line"><span class="undefined">      line-height: 20px;</span></span><br><span class="line"><span class="undefined">      color: #333;</span></span><br><span class="line"><span class="undefined">      white-space: nowrap;</span></span><br><span class="line"><span class="undefined">      vertical-align: middle;</span></span><br><span class="line"><span class="undefined">      cursor: pointer;</span></span><br><span class="line"><span class="undefined">      background-color: #eee;</span></span><br><span class="line"><span class="undefined">      background-image: linear-gradient(#fcfcfc, #eee);</span></span><br><span class="line"><span class="undefined">      border: 1px solid #d5d5d5;</span></span><br><span class="line"><span class="undefined">      border-radius: 3px;</span></span><br><span class="line"><span class="undefined">      user-select: none;</span></span><br><span class="line"><span class="undefined">      outline: 0;</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    .highlight-wrap .copy-btn &#123;</span></span><br><span class="line"><span class="undefined">      transition: opacity .3s ease-in-out;</span></span><br><span class="line"><span class="undefined">      opacity: 0;</span></span><br><span class="line"><span class="undefined">      padding: 2px 6px;</span></span><br><span class="line"><span class="undefined">      position: absolute;</span></span><br><span class="line"><span class="undefined">      right: 4px;</span></span><br><span class="line"><span class="undefined">      top: 8px;</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    .highlight-wrap:hover .copy-btn,</span></span><br><span class="line"><span class="undefined">    .highlight-wrap .copy-btn:focus &#123;</span></span><br><span class="line"><span class="undefined">      opacity: 1</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined"></span></span><br><span class="line"><span class="undefined">    .highlight-wrap &#123;</span></span><br><span class="line"><span class="undefined">      position: relative;</span></span><br><span class="line"><span class="undefined">    &#125;</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">style</span>&gt;</span></span><br><span class="line">  </span><br><span class="line">  <span class="tag">&lt;<span class="name">script</span>&gt;</span><span class="undefined"></span></span><br><span class="line"><span class="undefined">    $('.highlight').each(function (i, e) &#123;</span></span><br><span class="line"><span class="xml">      var $wrap = $('<span class="tag">&lt;<span class="name">div</span>&gt;</span>').addClass('highlight-wrap')</span></span><br><span class="line"><span class="undefined">      $(e).after($wrap)</span></span><br><span class="line"><span class="xml">      $wrap.append($('<span class="tag">&lt;<span class="name">button</span>&gt;</span>').addClass('copy-btn').append('&#123;&#123;__("post.copy_button")&#125;&#125;').on('click', function (e) &#123;</span></span><br><span class="line"><span class="undefined">        var code = $(this).parent().find('.code').find('.line').map(function (i, e) &#123;</span></span><br><span class="line"><span class="undefined">          return $(e).text()</span></span><br><span class="line"><span class="undefined">        &#125;).toArray().join('\n')</span></span><br><span class="line"><span class="undefined">        var ta = document.createElement('textarea')</span></span><br><span class="line"><span class="undefined">        document.body.appendChild(ta)</span></span><br><span class="line"><span class="undefined">        ta.style.position = 'absolute'</span></span><br><span class="line"><span class="undefined">        ta.style.top = '0px'</span></span><br><span class="line"><span class="undefined">        ta.style.left = '0px'</span></span><br><span class="line"><span class="undefined">        ta.value = code</span></span><br><span class="line"><span class="undefined">        ta.select()</span></span><br><span class="line"><span class="undefined">        ta.focus()</span></span><br><span class="line"><span class="undefined">        var result = document.execCommand('copy')</span></span><br><span class="line"><span class="undefined">        document.body.removeChild(ta)</span></span><br><span class="line"><span class="undefined">        &#123;% if theme.codeblock.copy_button.show_result %&#125;</span></span><br><span class="line"><span class="undefined">          if(result)$(this).text('&#123;&#123;__("post.copy_success")&#125;&#125;')</span></span><br><span class="line"><span class="undefined">          else $(this).text('&#123;&#123;__("post.copy_failure")&#125;&#125;')</span></span><br><span class="line"><span class="undefined">        &#123;% endif %&#125;</span></span><br><span class="line"><span class="undefined">        $(this).blur()</span></span><br><span class="line"><span class="undefined">      &#125;)).on('mouseleave', function (e) &#123;</span></span><br><span class="line"><span class="undefined">        var $b = $(this).find('.copy-btn')</span></span><br><span class="line"><span class="undefined">        setTimeout(function () &#123;</span></span><br><span class="line"><span class="undefined">          $b.text('&#123;&#123;__("post.copy_button")&#125;&#125;')</span></span><br><span class="line"><span class="undefined">        &#125;, 300)</span></span><br><span class="line"><span class="undefined">      &#125;).append(e)</span></span><br><span class="line"><span class="undefined">    &#125;)</span></span><br><span class="line"><span class="undefined">  </span><span class="tag">&lt;/<span class="name">script</span>&gt;</span></span><br><span class="line">&#123;% endif %&#125;</span><br></pre></td></tr></table></figure><p>然后返回上一层目录，即<code>layout</code>文件夹下，编辑<code>_layout.swig</code>，如图：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fxg5nunai6j20hl0410st.jpg" alt=""></p><p>在图中位置添加：</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;% include '_third-party/copy-code.swig' %&#125;</span><br></pre></td></tr></table></figure><h1 id="2-添加按钮上显示的语言"><a href="#2-添加按钮上显示的语言" class="headerlink" title="2 添加按钮上显示的语言"></a>2 添加按钮上显示的语言</h1><p>进入<code>themes/next/languages/</code>目录下，</p><p>在<code>zh-CN.yml</code>中的<code>post</code>下添加：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">copy_button:</span> <span class="string">复制</span></span><br><span class="line"><span class="attr">copy_success:</span> <span class="string">复制成功</span></span><br><span class="line"><span class="attr">copy_failure:</span> <span class="string">复制失败</span></span><br></pre></td></tr></table></figure><p>如图：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fxgl0f5ok3j209u0ezjrz.jpg" alt=""></p><p>在<code>en.yml</code>中的<code>post</code>下添加：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">copy_button:</span> <span class="string">Copy</span></span><br><span class="line"><span class="attr">copy_success:</span> <span class="string">Copied</span></span><br><span class="line"><span class="attr">copy_failure:</span> <span class="string">Copy</span> <span class="string">failed</span></span><br></pre></td></tr></table></figure><h1 id="3-在主题配置文件中添加开关"><a href="#3-在主题配置文件中添加开关" class="headerlink" title="3 在主题配置文件中添加开关"></a>3 在主题配置文件中添加开关</h1><p>编辑<code>主题配置文件</code>（<code>themes/next/_config.yml</code>），在其中的<code>codeblock</code>中添加<code>copy_button</code>的开关，如图所示：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fxgl6vrtugj20dt060q30.jpg" alt=""></p><p>添加的内容为：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Add copy button on codeblock</span></span><br><span class="line"><span class="attr">copy_button:</span></span><br><span class="line"><span class="attr">  enable:</span> <span class="literal">true</span></span><br><span class="line">  <span class="comment"># Show text copy result</span></span><br><span class="line"><span class="attr">  show_result:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>好了，现在退到博客根目录，输入<code>hexo cl &amp;&amp; hexo g</code>重新生成一下来查看效果吧~</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HEXO </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow进一步优化神经网络</title>
      <link href="/TensorFlow%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BC%98%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/TensorFlow%E8%BF%9B%E4%B8%80%E6%AD%A5%E4%BC%98%E5%8C%96%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>在本站的这篇文章<a href="https://qiming.info/TensorFlow实现简单神经网络">《TensorFlow实现简单神经网络》</a>中，我们用TensorFlow实现了对MINST手写数字集的分类，分类的准确率达到了91%，本文中将优化此神经网络，将准确率提升至98%以上。</p><a id="more"></a><h1 id="1-优化思路"><a href="#1-优化思路" class="headerlink" title="1 优化思路"></a>1 优化思路</h1><p>对神经网络进行优化时，可以采取的思路主要有以下几种：</p><ul><li>合适的损失函数</li><li>合适的激活函数</li><li>合适的优化器</li><li>神经网络的层数</li><li>学习率的设置</li><li>处理过拟合问题</li><li>增大训练样本量、训练轮次</li></ul><p>本例中，交叉熵函数比二次代价函数更适合作为损失函数，激活函数采用了<code>tanh()</code>函数，优化器选用了Adam函数。</p><p>神经网络的层数并不是越多越好（太复杂的神经网络解决数据量较小的问题极易出现过拟合现象），本例中设置了两层中间层。</p><p>设置学习率时，学习率太大会导致参数的值不停摇摆，而不会收敛到一个极小值，太小又会大大降低优化速度，所以我们可以先使用一个较大的学习率来快速得到一个比较优的解，然后随着迭代的继续逐步减小学习率，使得模型在训练后期更加稳定。</p><p>为防止过拟合问题，本例中使用了dropout机制。</p><p>在深度学习中，增大训练样本量可以使很多问题迎刃而解，但在本例中并不适用，因为本例已经使用了MNIST的全部训练数据。但是可以增加训练轮次，本例中将上文的21次提升到了51次。</p><p>好了，来敲敲代码看疗效吧~</p><h1 id="2-代码及说明"><a href="#2-代码及说明" class="headerlink" title="2 代码及说明"></a>2 代码及说明</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个批次的大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># 计算一共有多少个批次</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义placeholder</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line"><span class="comment"># 定义dropout</span></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line"><span class="comment"># 定义一个可变的学习率变量</span></span><br><span class="line">lr = tf.Variable(<span class="number">0.001</span>,dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建神经网络</span></span><br><span class="line"><span class="comment"># 设置第一层中间层的节点数为1000个</span></span><br><span class="line">W1 = tf.Variable(tf.truncated_normal([<span class="number">784</span>,<span class="number">1000</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">1000</span>])+<span class="number">0.1</span>)</span><br><span class="line">L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)</span><br><span class="line">L1_drop = tf.nn.dropout(L1,keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置第二层中间层的节点数为500个</span></span><br><span class="line">W2 = tf.Variable(tf.truncated_normal([<span class="number">1000</span>,<span class="number">500</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">500</span>])+<span class="number">0.1</span>)</span><br><span class="line">L2 = tf.nn.tanh(tf.matmul(L1_drop,W2)+b2)</span><br><span class="line">L2_drop = tf.nn.dropout(L2,keep_prob)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出层</span></span><br><span class="line">W3 = tf.Variable(tf.truncated_normal([<span class="number">500</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">10</span>])+<span class="number">0.1</span>)</span><br><span class="line">prediction = tf.matmul(L2_drop,W3)+b3</span><br><span class="line"></span><br><span class="line"><span class="comment"># 交叉熵代价函数</span></span><br><span class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=prediction))</span><br><span class="line"><span class="comment"># 使用Adam作为优化器进行训练</span></span><br><span class="line">train_step = tf.train.AdamOptimizer(lr).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果存放在一个布尔型列表中</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(prediction,<span class="number">1</span>)) <span class="comment"># argmax返回一维张量中最大的值所在的位置</span></span><br><span class="line"><span class="comment"># 求准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">51</span>):</span><br><span class="line">        <span class="comment"># 每训练一轮 学习率降低 </span></span><br><span class="line">        sess.run(tf.assign(lr,<span class="number">0.001</span> * (<span class="number">0.95</span> ** epoch)))</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            batch_xs,batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train_step,feed_dict=&#123;x:batch_xs,y:batch_ys,keep_prob:<span class="number">0.7</span>&#125;)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 计算测试数据的准确率</span></span><br><span class="line">        test_acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels,keep_prob:<span class="number">1.0</span> &#125;)</span><br><span class="line">        <span class="comment"># 计算训练数据的准确率</span></span><br><span class="line">        train_acc = sess.run(accuracy,feed_dict=&#123;x:mnist.train.images,y:mnist.train.labels,keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">        <span class="comment"># 输出训练轮次、测试数据准确率、训练数据准确率</span></span><br><span class="line">        print(<span class="string">"Iter "</span>+str(epoch)+<span class="string">",Testing Accuracy "</span>+str(test_acc)+<span class="string">",Training Accuracy "</span> + str(train_acc) )</span><br></pre></td></tr></table></figure><h1 id="3-结果"><a href="#3-结果" class="headerlink" title="3 结果"></a>3 结果</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">Iter <span class="number">0</span>,Testing Accuracy <span class="number">0.956</span>,Training Accuracy <span class="number">0.95829093</span></span><br><span class="line">Iter <span class="number">1</span>,Testing Accuracy <span class="number">0.9665</span>,Training Accuracy <span class="number">0.97316366</span></span><br><span class="line">Iter <span class="number">2</span>,Testing Accuracy <span class="number">0.9704</span>,Training Accuracy <span class="number">0.9800182</span></span><br><span class="line">Iter <span class="number">3</span>,Testing Accuracy <span class="number">0.9741</span>,Training Accuracy <span class="number">0.98243636</span></span><br><span class="line">Iter <span class="number">4</span>,Testing Accuracy <span class="number">0.975</span>,Training Accuracy <span class="number">0.98547274</span></span><br><span class="line">Iter <span class="number">5</span>,Testing Accuracy <span class="number">0.9754</span>,Training Accuracy <span class="number">0.9882</span></span><br><span class="line">Iter <span class="number">6</span>,Testing Accuracy <span class="number">0.9773</span>,Training Accuracy <span class="number">0.9896909</span></span><br><span class="line">Iter <span class="number">7</span>,Testing Accuracy <span class="number">0.977</span>,Training Accuracy <span class="number">0.9915091</span></span><br><span class="line">Iter <span class="number">8</span>,Testing Accuracy <span class="number">0.9786</span>,Training Accuracy <span class="number">0.9924727</span></span><br><span class="line">Iter <span class="number">9</span>,Testing Accuracy <span class="number">0.9775</span>,Training Accuracy <span class="number">0.9947636</span></span><br><span class="line">Iter <span class="number">10</span>,Testing Accuracy <span class="number">0.979</span>,Training Accuracy <span class="number">0.9940909</span></span><br><span class="line">Iter <span class="number">11</span>,Testing Accuracy <span class="number">0.9797</span>,Training Accuracy <span class="number">0.99587274</span></span><br><span class="line">Iter <span class="number">12</span>,Testing Accuracy <span class="number">0.9803</span>,Training Accuracy <span class="number">0.99643636</span></span><br><span class="line">Iter <span class="number">13</span>,Testing Accuracy <span class="number">0.9818</span>,Training Accuracy <span class="number">0.9971273</span></span><br><span class="line">Iter <span class="number">14</span>,Testing Accuracy <span class="number">0.9801</span>,Training Accuracy <span class="number">0.99756366</span></span><br><span class="line">Iter <span class="number">15</span>,Testing Accuracy <span class="number">0.9821</span>,Training Accuracy <span class="number">0.9982727</span></span><br><span class="line">Iter <span class="number">16</span>,Testing Accuracy <span class="number">0.9816</span>,Training Accuracy <span class="number">0.9984546</span></span><br><span class="line">Iter <span class="number">17</span>,Testing Accuracy <span class="number">0.9818</span>,Training Accuracy <span class="number">0.99874544</span></span><br><span class="line">Iter <span class="number">18</span>,Testing Accuracy <span class="number">0.9814</span>,Training Accuracy <span class="number">0.99883634</span></span><br><span class="line">Iter <span class="number">19</span>,Testing Accuracy <span class="number">0.9828</span>,Training Accuracy <span class="number">0.9993273</span></span><br><span class="line">Iter <span class="number">20</span>,Testing Accuracy <span class="number">0.9816</span>,Training Accuracy <span class="number">0.9992545</span></span><br><span class="line">Iter <span class="number">21</span>,Testing Accuracy <span class="number">0.9838</span>,Training Accuracy <span class="number">0.9993273</span></span><br><span class="line">Iter <span class="number">22</span>,Testing Accuracy <span class="number">0.9824</span>,Training Accuracy <span class="number">0.99965453</span></span><br><span class="line">Iter <span class="number">23</span>,Testing Accuracy <span class="number">0.9829</span>,Training Accuracy <span class="number">0.9997454</span></span><br><span class="line">Iter <span class="number">24</span>,Testing Accuracy <span class="number">0.9836</span>,Training Accuracy <span class="number">0.99965453</span></span><br><span class="line">Iter <span class="number">25</span>,Testing Accuracy <span class="number">0.9828</span>,Training Accuracy <span class="number">0.9996727</span></span><br><span class="line">Iter <span class="number">26</span>,Testing Accuracy <span class="number">0.9841</span>,Training Accuracy <span class="number">0.99987274</span></span><br><span class="line">Iter <span class="number">27</span>,Testing Accuracy <span class="number">0.9823</span>,Training Accuracy <span class="number">0.9999091</span></span><br><span class="line">Iter <span class="number">28</span>,Testing Accuracy <span class="number">0.9837</span>,Training Accuracy <span class="number">0.9998909</span></span><br><span class="line">Iter <span class="number">29</span>,Testing Accuracy <span class="number">0.9846</span>,Training Accuracy <span class="number">0.99987274</span></span><br><span class="line">Iter <span class="number">30</span>,Testing Accuracy <span class="number">0.9835</span>,Training Accuracy <span class="number">0.9999273</span></span><br><span class="line">Iter <span class="number">31</span>,Testing Accuracy <span class="number">0.9829</span>,Training Accuracy <span class="number">0.9998909</span></span><br><span class="line">Iter <span class="number">32</span>,Testing Accuracy <span class="number">0.9835</span>,Training Accuracy <span class="number">0.9999818</span></span><br><span class="line">Iter <span class="number">33</span>,Testing Accuracy <span class="number">0.9843</span>,Training Accuracy <span class="number">0.9999818</span></span><br><span class="line">Iter <span class="number">34</span>,Testing Accuracy <span class="number">0.9836</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">35</span>,Testing Accuracy <span class="number">0.9831</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">36</span>,Testing Accuracy <span class="number">0.9841</span>,Training Accuracy <span class="number">0.9999818</span></span><br><span class="line">Iter <span class="number">37</span>,Testing Accuracy <span class="number">0.9835</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">38</span>,Testing Accuracy <span class="number">0.9847</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">39</span>,Testing Accuracy <span class="number">0.9836</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">40</span>,Testing Accuracy <span class="number">0.9844</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">41</span>,Testing Accuracy <span class="number">0.9844</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">42</span>,Testing Accuracy <span class="number">0.9843</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">43</span>,Testing Accuracy <span class="number">0.9847</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">44</span>,Testing Accuracy <span class="number">0.984</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">45</span>,Testing Accuracy <span class="number">0.9836</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">46</span>,Testing Accuracy <span class="number">0.9839</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">47</span>,Testing Accuracy <span class="number">0.9839</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">48</span>,Testing Accuracy <span class="number">0.9834</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">49</span>,Testing Accuracy <span class="number">0.9835</span>,Training Accuracy <span class="number">1.0</span></span><br><span class="line">Iter <span class="number">50</span>,Testing Accuracy <span class="number">0.9843</span>,Training Accuracy <span class="number">1.0</span></span><br></pre></td></tr></table></figure><p>可以看出，在训练了51轮后，测试数据的准确率已经达到了98.4%，训练数据的准确率达到了100% 。</p><h1 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4 参考资料"></a>4 参考资料</h1><p>[1]@Bilibili.<a href="https://www.bilibili.com/video/av20542427" target="_blank" rel="noopener">深度学习框架Tensorflow学习与应用</a>.2018-03<br>[2]郑泽宇,梁博文,顾思宇.TensorFlow:实战Goole深度学习框架(第2版)[M].北京:电子工业出版社.2018-02</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分类 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> Python </tag>
            
            <tag> MNIST </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow实现简单神经网络</title>
      <link href="/TensorFlow%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
      <url>/TensorFlow%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/</url>
      
        <content type="html"><![CDATA[<p>在上文（<a href="https://qiming.info/TensorFlow快速上手">《TensorFlow快速上手》</a>）中，我们介绍了TensorFlow中的一些基本概念，并实现了一个线性回归的例子。</p><p>本文我们趁热打铁，接着用TensorFlow实现一下神经网络吧。</p><p>TensorFlow中的神经网络可以用来实现回归算法和分类算法，本文将分别给出实现这两种算法的代码。除此之外，还将介绍一个TensorFlow中重要且常用的概念——placeholder（占位符），和一个著名的数据集：MINST数据集。</p><a id="more"></a><h1 id="1-placeholder"><a href="#1-placeholder" class="headerlink" title="1 placeholder"></a>1 placeholder</h1><p>在开始之前，先得说一下<code>placeholder</code>，中文翻译为<code>占位符</code>。</p><p>tensor不仅以常量或变量的形式存储，TensorFlow 还提供了<code>feed</code>机制，该机制可以临时替代计算图中的任意操作中的tensor，可以对图中任何操作提交补丁，直接插入一个<code>tensor</code>。具体方法即使用<code>tf.placeholder()</code>为这些操作创建占位符。简单使用如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建input1和input2这两个占位符</span></span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line">output = tf.multiply(input1,input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 通过字典的形式向input1和input2传值</span></span><br><span class="line">    print(sess.run(output,feed_dict=&#123;input1:[<span class="number">7.</span>],input2:[<span class="number">2.</span>]&#125;))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 输出结果为：[14.]</span></span><br></pre></td></tr></table></figure><h1 id="2-神经网络实现回归算法"><a href="#2-神经网络实现回归算法" class="headerlink" title="2 神经网络实现回归算法"></a>2 神经网络实现回归算法</h1><h2 id="2-1-代码及说明"><a href="#2-1-代码及说明" class="headerlink" title="2.1 代码及说明"></a>2.1 代码及说明</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numpy生成100个随机点作为假数据</span></span><br><span class="line">x_data = np.linspace(<span class="number">-0.5</span>,<span class="number">0.5</span>,<span class="number">200</span>)[:,np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>,<span class="number">0.02</span>,x_data.shape)</span><br><span class="line">y_data = np.square(x_data)+noise</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个placeholder</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>])</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义神经网络中间层</span></span><br><span class="line">Weights_L1 = tf.Variable(tf.random_normal([<span class="number">1</span>,<span class="number">10</span>]))</span><br><span class="line">biases_L1 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">10</span>]))</span><br><span class="line">Wx_plus_b_L1 = tf.matmul(x,Weights_L1) + biases_L1</span><br><span class="line">L1 = tf.nn.tanh(Wx_plus_b_L1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义神经网络输出层</span></span><br><span class="line">Weights_L2 = tf.Variable(tf.random_normal([<span class="number">10</span>,<span class="number">1</span>]))</span><br><span class="line">biases_L2 = tf.Variable(tf.zeros([<span class="number">1</span>,<span class="number">1</span>]))</span><br><span class="line">Wx_plus_b_L2 = tf.matmul(L1,Weights_L2)+biases_L2</span><br><span class="line">prediction = tf.nn.tanh(Wx_plus_b_L2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二次代价函数</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-prediction))</span><br><span class="line"><span class="comment"># 定义一个梯度下降法来进行训练的优化器 学习率0.1</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 变量初始化</span></span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="comment"># 训练2000次</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">2000</span>):</span><br><span class="line">        sess.run(train_step,feed_dict=&#123;x:x_data,y:y_data&#125;)</span><br><span class="line">    <span class="comment"># 获得预测值</span></span><br><span class="line">    prediction_value = sess.run(prediction,feed_dict=&#123;x:x_data&#125;) </span><br><span class="line">    <span class="comment"># 画图展示结果</span></span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.scatter(x_data,y_data)</span><br><span class="line">    plt.plot(x_data,prediction_value,<span class="string">'r-'</span>,lw=<span class="number">5</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure><h2 id="2-2-结果"><a href="#2-2-结果" class="headerlink" title="2.2 结果"></a>2.2 结果</h2><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fx33pjbrk4j20hs0dcmxq.jpg" alt=""></p><p>这个神经网络比较简单，使用了<code>tanh()</code>作为激活函数，梯度下降法为优化器，二次代价函数为损失函数。</p><p>拟合出的结果如上图红线所示，可以看出，大致是一个二次函数曲线。</p><h1 id="3-神经网络实现分类算法"><a href="#3-神经网络实现分类算法" class="headerlink" title="3 神经网络实现分类算法"></a>3 神经网络实现分类算法</h1><h2 id="3-1-MNIST数据集简介"><a href="#3-1-MNIST数据集简介" class="headerlink" title="3.1 MNIST数据集简介"></a>3.1 MNIST数据集简介</h2><p>MNIST是一个入门级的计算机视觉数据集，它包含各种手写数字图片，它也包含每一张图片对应的标签，告诉我们这个是数字几。比如，下面这四张图片的标签分别是5，0，4，1。</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fx359xhherj20ho04fjrm.jpg" alt=""></p><p>MNIST数据集有两部分组成：60000行的训练数据集（<code>mnist.train</code>）和10000行的测试数据集（<code>mnist.test</code>）。</p><p>每一个MNIST数据单元有两部分组成：一张包含手写数字的图片和一个对应的标签。我们把这些图片设为“xs”，把这些标签设为“ys”。训练数据集和测试数据集都包含xs和ys，比如训练数据集的图片是 <code>mnist.train.images</code> ，训练数据集的标签是 <code>mnist.train.labels</code>。</p><p>每一张图片包含28像素X28像素。我们可以用一个数字数组来表示这张图片：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fx35dej0yqj20ra0arq39.jpg" alt=""></p><p>我们把这个数组展开成一个向量，长度是 28x28 = 784。因此，在MNIST训练数据集中，<code>mnist.train.images</code> 是一个形状为 <code>[60000, 784]</code> 的张量，第一个维度数字用来索引图片，第二个维度数字用来索引每张图片中的像素点。相对应的MNIST数据集的标签是介于0到9的数字，用来描述给定图片里表示的数字。为了用于这个教程，我们使标签数据是”one-hot vectors”。 一个one-hot向量除了某一位的数字是1以外其余各维度数字都是0。所以在此教程中，数字n将表示成一个只有在第n维度（从0开始）数字为1的10维向量。比如，标签0将表示成([1,0,0,0,0,0,0,0,0,0,0])。因此， <code>mnist.train.labels</code> 是一个 <code>[60000, 10]</code> 的数字矩阵。</p><h2 id="3-2-代码及说明"><a href="#3-2-代码及说明" class="headerlink" title="3.2 代码及说明"></a>3.2 代码及说明</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line"><span class="comment"># 载入数据集</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">"MNIST_data"</span>,one_hot=<span class="keyword">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 每个批次的大小</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># 计算一共有多少个批次</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义两个placeholder</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="keyword">None</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个简单的神经网络（无中间层）</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(x,W)+b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二次代价函数 </span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-prediction))</span><br><span class="line"><span class="comment"># 定义一个梯度下降法来进行训练的优化器 学习率0.2</span></span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 结果存放在一个布尔型列表中</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(prediction,<span class="number">1</span>)) <span class="comment"># argmax返回一维张量中最大的值所在的位置</span></span><br><span class="line"><span class="comment"># 求准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="comment"># 训练21轮次</span></span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            batch_xs,batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train_step,feed_dict=&#123;x:batch_xs,y:batch_ys&#125;)</span><br><span class="line">        <span class="comment"># 用测试数据计算模型的准确率</span></span><br><span class="line">        acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">"Iter "</span>+str(epoch)+<span class="string">",Testing Accuracy "</span>+str(acc))</span><br></pre></td></tr></table></figure><h2 id="3-3-结果"><a href="#3-3-结果" class="headerlink" title="3.3 结果"></a>3.3 结果</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Iter <span class="number">0</span>,Testing Accuracy <span class="number">0.8349</span></span><br><span class="line">Iter <span class="number">1</span>,Testing Accuracy <span class="number">0.8719</span></span><br><span class="line">Iter <span class="number">2</span>,Testing Accuracy <span class="number">0.8824</span></span><br><span class="line">Iter <span class="number">3</span>,Testing Accuracy <span class="number">0.8882</span></span><br><span class="line">Iter <span class="number">4</span>,Testing Accuracy <span class="number">0.8937</span></span><br><span class="line">Iter <span class="number">5</span>,Testing Accuracy <span class="number">0.8968</span></span><br><span class="line">Iter <span class="number">6</span>,Testing Accuracy <span class="number">0.8993</span></span><br><span class="line">Iter <span class="number">7</span>,Testing Accuracy <span class="number">0.9033</span></span><br><span class="line">Iter <span class="number">8</span>,Testing Accuracy <span class="number">0.9033</span></span><br><span class="line">Iter <span class="number">9</span>,Testing Accuracy <span class="number">0.9054</span></span><br><span class="line">Iter <span class="number">10</span>,Testing Accuracy <span class="number">0.9064</span></span><br><span class="line">Iter <span class="number">11</span>,Testing Accuracy <span class="number">0.9067</span></span><br><span class="line">Iter <span class="number">12</span>,Testing Accuracy <span class="number">0.9089</span></span><br><span class="line">Iter <span class="number">13</span>,Testing Accuracy <span class="number">0.9089</span></span><br><span class="line">Iter <span class="number">14</span>,Testing Accuracy <span class="number">0.9098</span></span><br><span class="line">Iter <span class="number">15</span>,Testing Accuracy <span class="number">0.9107</span></span><br><span class="line">Iter <span class="number">16</span>,Testing Accuracy <span class="number">0.9121</span></span><br><span class="line">Iter <span class="number">17</span>,Testing Accuracy <span class="number">0.9121</span></span><br><span class="line">Iter <span class="number">18</span>,Testing Accuracy <span class="number">0.9126</span></span><br><span class="line">Iter <span class="number">19</span>,Testing Accuracy <span class="number">0.913</span></span><br><span class="line">Iter <span class="number">20</span>,Testing Accuracy <span class="number">0.914</span></span><br></pre></td></tr></table></figure><p>本例中神经网络的输出层用了<code>softmax()</code>函数进行分类，依旧使用了二次代价函数作为损失函数，梯度下降法作为优化器。</p><p>结果显示，在训练了21轮后，模型的准确率达到了91.4%，这个准确度不算高，所以还需要进行优化，优化方式下文（<a href="https://qiming.info/TensorFlow进一步优化神经网络">TensorFlow进一步优化神经网络</a>）将介绍。</p><h1 id="4-小结"><a href="#4-小结" class="headerlink" title="4 小结"></a>4 小结</h1><p>在本文中，分别实现了神经网络的回归算法和分类算法，其中提到的有关神经网络的一些概念，如激活函数、损失函数、优化器等，先请读者自行参考相关资料，本人后续可能会补充。</p><h1 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5 参考资料"></a>5 参考资料</h1><p>[1]@Bilibili.<a href="https://www.bilibili.com/video/av20542427" target="_blank" rel="noopener">深度学习框架Tensorflow学习与应用</a>.2018-03<br>[2]TensorFlow中文社区.<a href="http://www.tensorfly.cn/tfdoc/get_started/basic_usage.html" target="_blank" rel="noopener">基本用法 | TensorFlow 官方文档中文版</a></p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分类 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> Python </tag>
            
            <tag> 回归 </tag>
            
            <tag> MNIST </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlow快速上手</title>
      <link href="/TensorFlow%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/"/>
      <url>/TensorFlow%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B/</url>
      
        <content type="html"><![CDATA[<p>TensorFlow是目前很火的一款深度学习框架，其源码是用C++写的，保证了运行速度，其又提供了Python的接口，大大降低了程序猿们学习新语言的成本，所以在深度学习领域广为流行。</p><p>但是很多人在初学TensorFlow时会觉得有些难以入手，霎时间接触诸如张量、图、会话等概念会有点吃力，所以本文将介绍如何快速入门TensorFlow并上手写代码，一边实践一边理解概念，提升学习速度。</p><a id="more"></a><h1 id="1-安装"><a href="#1-安装" class="headerlink" title="1 安装"></a>1 安装</h1><p>安装TensorFlow有多种方式，为了快速上手写代码，这里介绍一种最为简单的方法，像安装其他Python库一样，直接用pip就好，即在命令行中输入：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install tensorflow</span><br></pre></td></tr></table></figure><blockquote><p>注1：还可以通过Docker安装或从源码安装。</p></blockquote><blockquote><p>注2：此处安装的是仅支持CPU版本的，支持GPU版本的将在后续文章中说明。</p></blockquote><h1 id="2-使用"><a href="#2-使用" class="headerlink" title="2 使用"></a>2 使用</h1><p>在使用的第一步，惯例我们先引入tensorflow库，为方便起见，将其用<code>tf</code>简写，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br></pre></td></tr></table></figure><h2 id="2-1-tensor"><a href="#2-1-tensor" class="headerlink" title="2.1 tensor"></a>2.1 tensor</h2><p>tensor即张量，是TensorFlow中所有数据的基本表现形式，TensorFlow中的常量、变量都属于张量。</p><h3 id="2-1-1-常量"><a href="#2-1-1-常量" class="headerlink" title="2.1.1 常量"></a>2.1.1 常量</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">a = tf.constant([[<span class="number">1.</span>,<span class="number">2.</span>],[<span class="number">3.</span>,<span class="number">4.</span>]],name=<span class="string">'const_a'</span>)</span><br><span class="line">print(a)</span><br></pre></td></tr></table></figure><p>这段代码创建了一个常量a，直接输出后的结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Tensor(<span class="string">"const_a:0"</span>, shape=(<span class="number">2</span>,<span class="number">2</span>), dtype=float32)</span><br></pre></td></tr></table></figure><p>可以看到直接输出的结果并不是我们给定的值，而是一个张量的结构。（输出值需要在会话中进行，下文会进行介绍）</p><p>其中<code>const_a:0</code>表示<code>a</code>是<code>const_a</code>的第一个值（也是唯一一个），shape代表维度，（2，2）表示此张量是个2x2的矩阵，第三个属性为数据类型。</p><p>常用的常数生成函数还有：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 产生全是0的2x3矩阵</span></span><br><span class="line">tf.zeros([<span class="number">2</span>,<span class="number">3</span>],int32)</span><br><span class="line"><span class="comment"># 产生全是1的2x3矩阵</span></span><br><span class="line">tf.ones([<span class="number">2</span>,<span class="number">3</span>],int32)</span><br><span class="line"><span class="comment"># 产生全是9的2x3矩阵</span></span><br><span class="line">tf.fill([<span class="number">2</span>,<span class="number">3</span>],<span class="number">9</span>)</span><br></pre></td></tr></table></figure><h3 id="2-1-2-变量"><a href="#2-1-2-变量" class="headerlink" title="2.1.2 变量"></a>2.1.2 变量</h3><p>变量在TensorFlow中十分重要，因其可以在计算中修改，所以神经网络的模型参数一般使用变量。</p><p>创建变量可以直接调用Variable函数，将值传入即可。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一个全1的2x2矩阵</span></span><br><span class="line">x = tf.Variable(tf.ones([<span class="number">2</span>,<span class="number">2</span>]),name=<span class="string">'var_x'</span>)</span><br></pre></td></tr></table></figure><p>需要注意的是，使用变量时，需要对其进行初始化：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">init = tf.global_variables_initializer()</span><br></pre></td></tr></table></figure><h2 id="2-2-Session"><a href="#2-2-Session" class="headerlink" title="2.2 Session"></a>2.2 Session</h2><p>Session即会话，TensorFlow中，所有操作都只能在会话中进行。</p><p>假如我们想求上文中创建的常量a和变量x的和，完整代码如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个2x2的矩阵常量a,值为[[1.0,2.0],[3.0,4.0]]</span></span><br><span class="line">a = tf.constant([[<span class="number">1.</span>,<span class="number">2.</span>],[<span class="number">3.</span>,<span class="number">4.</span>]],name=<span class="string">'const_a'</span>)</span><br><span class="line"><span class="comment"># 创建一个全1的2x2矩阵</span></span><br><span class="line">x = tf.Variable(tf.ones([<span class="number">2</span>,<span class="number">2</span>]),name=<span class="string">'var_x'</span>)</span><br><span class="line"><span class="comment"># 定义一个加法操作</span></span><br><span class="line">add = tf.add(a,x) <span class="comment"># 或 add = a + x</span></span><br><span class="line"><span class="comment"># 初始化所有变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"><span class="comment"># 利用Python上下文管理器创建Session，并在其中执行有关操作</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 执行初始化变量</span></span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="comment"># 执行加法运算并输出结果</span></span><br><span class="line">    print(sess.run(add))</span><br></pre></td></tr></table></figure><blockquote><p>注1：创建常量、变量时的name参数可省略</p></blockquote><blockquote><p>注2：创建Session的另一种方法：<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建会话</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line"><span class="comment"># 调用会话来执行节点的计算，假如是上例中的add</span></span><br><span class="line">sess.run(add)</span><br><span class="line"><span class="comment"># 执行结束后关闭会话</span></span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure></p></blockquote><blockquote><p>这种方式不好的地方在于当程序因为异常而退出时，Session.close()可能不会执行从而导致资源泄露。</p></blockquote><p>运行后输出如下：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[<span class="number">2.</span> <span class="number">3.</span>]</span><br><span class="line"> [<span class="number">4.</span> <span class="number">5.</span>]]</span><br></pre></td></tr></table></figure></p><h2 id="2-3-Graph"><a href="#2-3-Graph" class="headerlink" title="2.3 Graph"></a>2.3 Graph</h2><p>至此，你是否隐约感受到了TensorFlow在运行时的一点不同？</p><p>不同于一般的程序，TensorFlow程序有两个阶段：</p><ol><li>定义计算</li><li>执行计算</li></ol><p>也就是说TensorFlow会将所有运算都定义好后再在Session中执行，不像一般程序，可以一边定义一边执行。</p><p>事实上，TensorFlow在进行第一个阶段时就是将计算定义在了一个图（Graph）里，在上文中，是将操作放到了TensorFlow默认提供的一张计算图中了，当然，我们也可以自己新建一张图，如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建一张图g</span></span><br><span class="line">g = tf.Graph()</span><br><span class="line"><span class="keyword">with</span> g.as_default():</span><br><span class="line">    <span class="comment"># 在图中定义常量c为5.0</span></span><br><span class="line">    c = tf.constant(<span class="number">5.0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建一个Session，将图g作为参数传给它</span></span><br><span class="line"><span class="keyword">with</span> tf.Session(graph=g) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># 输出c</span></span><br><span class="line">    print(sess.run(c))</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 执行后，输出结果为：5.0</span></span><br></pre></td></tr></table></figure><h2 id="2-4-拟合线性回归"><a href="#2-4-拟合线性回归" class="headerlink" title="2.4 拟合线性回归"></a>2.4 拟合线性回归</h2><p>了解了上述基本概念和操作，接下来，我们来动手实践来拟合<code>y=0.1x+0.2</code>这个函数吧。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用numpy生成100个随机点</span></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>)</span><br><span class="line">y_data = x_data*<span class="number">0.1</span> + <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 给k随机赋初值2.2</span></span><br><span class="line">k = tf.Variable(<span class="number">2.2</span>)</span><br><span class="line"><span class="comment"># 给b随机赋初值1.1</span></span><br><span class="line">b = tf.Variable(<span class="number">1.1</span>)</span><br><span class="line"><span class="comment"># 构造一个线性模型</span></span><br><span class="line">y = k*x_data + b</span><br><span class="line"></span><br><span class="line"><span class="comment"># 二次代价函数的损失值</span></span><br><span class="line">loss = tf.reduce_mean(tf.square(y_data-y))</span><br><span class="line"><span class="comment"># 定义一个梯度下降法来进行训练的优化器</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>)</span><br><span class="line"><span class="comment"># 最小化代价函数</span></span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化变量</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="comment"># 训练201次</span></span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">201</span>):</span><br><span class="line">        sess.run(train)</span><br><span class="line">        <span class="comment"># 每训练20次 输出一下结果</span></span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">20</span> == <span class="number">0</span>:</span><br><span class="line">            print(step,sess.run([k,b]))</span><br></pre></td></tr></table></figure><p>训练结果如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">0</span> [<span class="number">1.7758392</span>, <span class="number">0.34141564</span>]</span><br><span class="line"><span class="number">20</span> [<span class="number">0.87541753</span>, <span class="number">-0.19211102</span>]</span><br><span class="line"><span class="number">40</span> [<span class="number">0.57061648</span>, <span class="number">-0.03798072</span>]</span><br><span class="line"><span class="number">60</span> [<span class="number">0.38562673</span>, <span class="number">0.055564649</span>]</span><br><span class="line"><span class="number">80</span> [<span class="number">0.27335268</span>, <span class="number">0.11233925</span>]</span><br><span class="line"><span class="number">100</span> [<span class="number">0.20521127</span>, <span class="number">0.14679691</span>]</span><br><span class="line"><span class="number">120</span> [<span class="number">0.16385485</span>, <span class="number">0.16770996</span>]</span><br><span class="line"><span class="number">140</span> [<span class="number">0.13875481</span>, <span class="number">0.18040252</span>]</span><br><span class="line"><span class="number">160</span> [<span class="number">0.12352109</span>, <span class="number">0.18810588</span>]</span><br><span class="line"><span class="number">180</span> [<span class="number">0.11427544</span>, <span class="number">0.19278121</span>]</span><br><span class="line"><span class="number">200</span> [<span class="number">0.10866406</span>, <span class="number">0.19561876</span>]</span><br></pre></td></tr></table></figure><p>可以看出，在训练了201次后，k值和b值都分别非常接近0.1和0.2了。</p><h1 id="3-参考资料"><a href="#3-参考资料" class="headerlink" title="3 参考资料"></a>3 参考资料</h1><p>[1]TensorFlow中文社区.<a href="http://www.tensorfly.cn/tfdoc/get_started/basic_usage.html" target="_blank" rel="noopener">基本用法 | TensorFlow 官方文档中文版</a><br>[2]郑泽宇,梁博文,顾思宇.TensorFlow:实战Goole深度学习框架(第2版)[M].北京:电子工业出版社.2018-02<br>[3]@Bilibili.<a href="https://www.bilibili.com/video/av20542427" target="_blank" rel="noopener">深度学习框架Tensorflow学习与应用</a>.2018-03</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 神经网络 </tag>
            
            <tag> TensorFlow </tag>
            
            <tag> Python </tag>
            
            <tag> 回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>校招作业之小型文本预处理器</title>
      <link href="/%E6%A0%A1%E6%8B%9B%E4%BD%9C%E4%B8%9A%E4%B9%8B%E5%B0%8F%E5%9E%8B%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E5%99%A8/"/>
      <url>/%E6%A0%A1%E6%8B%9B%E4%BD%9C%E4%B8%9A%E4%B9%8B%E5%B0%8F%E5%9E%8B%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86%E5%99%A8/</url>
      
        <content type="html"><![CDATA[<p>前段时间做了一道有趣的校园招聘的作业题，要求做一个小型文本预处理器，题目看似简单，实际做起来还是挺有挑战性的。现在早已经过了该公司的作业提交时间，所以将此文放出来，如果该公司认为侵权了，可联系本人，本人将删除文章。</p><a id="more"></a><h1 id="1-问题说明"><a href="#1-问题说明" class="headerlink" title="1 问题说明"></a>1 问题说明</h1><p>本次作业的题目是一个小型文本预处理器，输入文本内容及指定宽度以后，对文本进行预处理以便后续进行固定宽度的排版。其中定义了如下的概念：</p><ul><li>空白字符（white space）：指空格 ‘  ‘。</li><li>文本字符（character）：指大写或者小写的英文字母。</li><li>节（segment）：指一串（大于或者等于一个）连续的空白字符或者文本字符。</li></ul><p>当给定宽度后，大于这个宽度的字符会被折行。而折行不会显示任何连字符（例如 “-”），也无需对 空白字符 进行额外处理。作业要求编写一个函数，该函数的输入为两个参数：</p><ul><li>需要处理的文本</li><li>排版宽度。</li></ul><p>该函数的返回值为预处理后的文本。预处理后的文本为每一节，及其所在的行号。中间以分号隔开。若一个节跨越了多行，则行号用逗号隔开，并从小到大进行排列。例如，假设输入为：</p><blockquote><p>The main theme of education in engineering school is learning to teach yourself，排版宽度指定为 30，</p></blockquote><p>则输出为：</p><blockquote><p>The(1); (1);main(1); (1);theme(1); (1);of(1); (1);education(1); (1);in(1);(2);engineering(2); (2);school(2); (2);is(2); (2);learning(2,3); (3);to(3);(3);teach(3); (3);yourself(3);</p></blockquote><h1 id="2-构建代码"><a href="#2-构建代码" class="headerlink" title="2 构建代码"></a>2 构建代码</h1><h2 id="2-1-代码思想"><a href="#2-1-代码思想" class="headerlink" title="2.1 代码思想"></a>2.1 代码思想</h2><p>要给每一节都标上其所在的行数，本人的思想是：</p><ol><li>首先将所给文本分节；</li><li>然后需知道每一节的第一个和最后一个字符所在原文本中的位置；</li><li>根据排版宽度求出每一节第一个字符和最后一个字符在排版后的文本中的所在行；</li><li>根据每一节的首尾字符所在行得到此节所在的所有行；</li><li>将每个节的内容及其所在的所有行依次按要求输出。</li></ol><h2 id="2-2-将文本分节"><a href="#2-2-将文本分节" class="headerlink" title="2.2 将文本分节"></a>2.2 将文本分节</h2><h3 id="2-2-1-计算节数"><a href="#2-2-1-计算节数" class="headerlink" title="2.2.1 计算节数"></a>2.2.1 计算节数</h3><p>首先先得到一共有多少个节，在这里使用正则表达式将文本以任意个连续空格分节：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">String[] strArr = text.split(<span class="string">"\\s+"</span>);</span><br></pre></td></tr></table></figure><p>可得到有多少个字母字符节，再通过判断原始文本首尾是否为空白字符得到节数segmentNum。</p><h3 id="2-2-2-获取每一节的数据并存放"><a href="#2-2-2-获取每一节的数据并存放" class="headerlink" title="2.2.2 获取每一节的数据并存放"></a>2.2.2 获取每一节的数据并存放</h3><p>每一节的数据包括它的内容和尾字符在原始文本中的位置。在这里我定义了一个String[]类型的segmentArray用来存放每一个节的内容；定义了一个int[]类型的segmentLastCharNo用来记录每一节的尾字符在原始文本中的位置；定义segmentNo用来指示当前为第几个节。</p><p>遍历原始文本，若当前字符与下一个字符相比由 空白字符 变为 字母字符 或由 字母字符 变为 空白字符 时，认为当前字符为一个节的尾字符，下一个字符则为下一个节的开始，代码如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; text.length() - <span class="number">1</span>; i++) &#123;</span><br><span class="line"><span class="keyword">char</span> c1 = text.charAt(i);</span><br><span class="line"><span class="keyword">char</span> c2 = text.charAt(i + <span class="number">1</span>);</span><br><span class="line"><span class="keyword">if</span> ((c1 == <span class="string">' '</span> &amp;&amp; c2 != <span class="string">' '</span>) || (c1 != <span class="string">' '</span> &amp;&amp; c2 == <span class="string">' '</span>)) &#123;</span><br><span class="line">segmentArray[segmentNo] += c1;</span><br><span class="line">segmentLastCharNo[segmentNo] = i;</span><br><span class="line">segmentNo++;</span><br><span class="line">&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">segmentArray[segmentNo] += c1;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (i == text.length() - <span class="number">2</span>) &#123;</span><br><span class="line">segmentArray[segmentNo] += c2;</span><br><span class="line">segmentLastCharNo[segmentNo] = i + <span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-3-求每一节的首尾字符在原文本的位置"><a href="#2-3-求每一节的首尾字符在原文本的位置" class="headerlink" title="2.3 求每一节的首尾字符在原文本的位置"></a>2.3 求每一节的首尾字符在原文本的位置</h2><p>当知道每一节的内容及尾字符所在位置后，由内容长度可得该节首字符所在位置（用segmentFirstCharNo表示）：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span> segmentFirstCharNo = segmentLastCharNo[i] - segmentArray[i].length() + <span class="number">1</span>;</span><br></pre></td></tr></table></figure><h2 id="2-4-求每一节的首尾字符在排版后的文本中的行号"><a href="#2-4-求每一节的首尾字符在排版后的文本中的行号" class="headerlink" title="2.4 求每一节的首尾字符在排版后的文本中的行号"></a>2.4 求每一节的首尾字符在排版后的文本中的行号</h2><p>用原文本中字符的位置除以排版宽度并向下取整即为此字符在排版后文本中所在的行号。用此方法便可得到每一节的首尾字符的行号。</p><h2 id="2-5-求每一节的行号"><a href="#2-5-求每一节的行号" class="headerlink" title="2.5 求每一节的行号"></a>2.5 求每一节的行号</h2><p>因为有的节可能会不跨行或跨多行，即节所在的行号可能为一到多个，因此为每一个节定义一个存储行号的int型数组segmentlines，从首字符所在行遍历至尾字符所在行，将行号填入segmentlines中，即可得到此节所有的行号。</p><h2 id="2-6-输出结果"><a href="#2-6-输出结果" class="headerlink" title="2.6 输出结果"></a>2.6 输出结果</h2><p>按上文所说，现在已经得到了存放所有节的数组segmentArray及每个节的所有行号，那么遍历segmentArray的元素并将其所在行号拼接成一个字符串，最后输出此字符串即可。</p><h1 id="3-运行代码"><a href="#3-运行代码" class="headerlink" title="3 运行代码"></a>3 运行代码</h1><p>上文实现了TextProcessor类，为调用此类，另编写文件StartTextProcessor.java文件，在此文件中通过main函数调用TextProcessor类。</p><p>将本项目文件导入编译器Eclipse，java版本为1.8，右键src文件夹下的StartTextProcessor.java文件，选择<code>Run As –&gt; java application</code>，即可运行此代码。然后在控制台输入所要排版的文本与排版宽度，即可得到结果。</p><h1 id="4-正确性验证"><a href="#4-正确性验证" class="headerlink" title="4 正确性验证"></a>4 正确性验证</h1><p>为了验证本次所编写代码的正确性，本人使用了单元测试这一方法。本次单元测试使用编译器Eclipse提供的插件EclEmma进行。EclEmma是一个免费的用来测试Java代码覆盖率的Eclipse插件，可以用EclEmma直接在Eclipse工作区中测试Java程序，分析代码覆盖率，并且在Java编辑器中高亮显示源文件的代码覆盖情况。</p><h2 id="4-1-安装插件"><a href="#4-1-安装插件" class="headerlink" title="4.1 安装插件"></a>4.1 安装插件</h2><p>在Eclipse中点击菜单<code>help –&gt; Eclipse MarketPlace</code>，在对话框中搜索<code>EclEmma</code>后点击<code>Install</code>，按照提示下一步即可完成安装。安装完成后，出现图标如下图所示即为插件安装成功。</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fwlpdmxizkj204e00sq2q.jpg" alt="插件截图"></p><h2 id="4-2-编写测试用例"><a href="#4-2-编写测试用例" class="headerlink" title="4.2 编写测试用例"></a>4.2 编写测试用例</h2><p>在编写测试用例时，首先考虑异常输入，其次是正常输入能否返回正确的结果。为此，编写测试用例目录如下：</p><ul><li>当文本中出现 空白字符 或 文本字符 以外的字符时应输出相应错误信息；</li><li>当输入宽度小于10时或大于80时应输出相应错误信息；</li><li>当文本中有连续空格时仍能得到正确结果；</li><li>当文本以空白字符开头或结尾时仍能得到正确结果；</li><li>当文本中某一节可跨多行时仍能得到正确结果，即罗列出此节所在的所有行号；</li><li>当文本为纯文本字符或纯空白字符时仍能得到正确结果；</li></ul><h2 id="4-3-测试结果"><a href="#4-3-测试结果" class="headerlink" title="4.3 测试结果"></a>4.3 测试结果</h2><p>根据上文测试用例目录编写了14条测试用例，写在TextProcessorTest.java中，通过 EclEmma 运行后显示14条测试用例全部通过且代码覆盖率100%。</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fwlpe8m6bjj211s0gt43b.jpg" alt="测试截图"></p><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p>首先开心的是顺利完成此次作业，并且通过了所有的测试用例。在完成此作业中又复习了Java的基础知识，以及单元测试的基础操作。</p><p>其次是对完成本次作业的过程的一些思考：在软件开发中，分析问题、拆分问题，无论所做的是大项目还是小项目，都对理清思路很有帮助。</p><h1 id="附代码"><a href="#附代码" class="headerlink" title="附代码"></a>附代码</h1><p><a href="https://github.com/Scorpio-xu/TextProcessor/" target="_blank" rel="noopener">https://github.com/Scorpio-xu/TextProcessor/</a></p>]]></content>
      
      
      <categories>
          
          <category> 面试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Xv6学习小记（二）——多核启动</title>
      <link href="/Xv6%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%A12/"/>
      <url>/Xv6%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%A12/</url>
      
        <content type="html"><![CDATA[<p>在上文（<a href="https://qiming.info/Xv6学习小计1">Xv6学习小记（一）——编译与运行</a>）中，我们介绍了Linux下编译运行Xv6系统的方式。<br>本文将介绍Xv6是如何多核启动的，涉及到的内容有：Xv6多核启动的大致步骤、Xv6检测CPU个数的方法和Xv6发送中断的方法等。</p><a id="more"></a><h1 id="1-多核启动步骤说明"><a href="#1-多核启动步骤说明" class="headerlink" title="1 多核启动步骤说明"></a>1 多核启动步骤说明</h1><p>Xv6启动时先将系统放入BSP（<code>Bootstrapprocessor</code>，启动CPU）中启动，BSP进入<code>main()</code>方法后首先进行了一系列初始化，其中包括<code>mpinit()</code>，此方法目的是检测CPU个数并将检测到的CPU存入一个全局的数组中，之后进入<code>startothers()</code>方法通过向AP（<code>non-bootCPU</code>,非启动CPU）发送中断的方式来启动AP，最后执行<code>mpmain()</code>方法。</p><p><code>main()</code>方法代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">int</span></span><br><span class="line">main(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  kinit1(end, P2V(<span class="number">4</span>*<span class="number">1024</span>*<span class="number">1024</span>)); <span class="comment">// phys page allocator</span></span><br><span class="line">  kvmalloc();      <span class="comment">// kernel page table</span></span><br><span class="line">  mpinit();        <span class="comment">// collect info about this machine</span></span><br><span class="line">  lapicinit();</span><br><span class="line">  seginit();       <span class="comment">// set up segments</span></span><br><span class="line">  cprintf(<span class="string">"\ncpu%d: starting xv6\n\n"</span>, cpu-&gt;id);</span><br><span class="line">  picinit();       <span class="comment">// interrupt controller</span></span><br><span class="line">  ioapicinit();    <span class="comment">// another interrupt controller</span></span><br><span class="line">  consoleinit();   <span class="comment">// I/O devices &amp; their interrupts</span></span><br><span class="line">  uartinit();      <span class="comment">// serial port</span></span><br><span class="line">  pinit();         <span class="comment">// process table</span></span><br><span class="line">  tvinit();        <span class="comment">// trap vectors</span></span><br><span class="line">  binit();         <span class="comment">// buffer cache</span></span><br><span class="line">  fileinit();      <span class="comment">// file table</span></span><br><span class="line">  ideinit();       <span class="comment">// disk</span></span><br><span class="line">  <span class="keyword">if</span>(!ismp)</span><br><span class="line">    timerinit();   <span class="comment">// uniprocessor timer</span></span><br><span class="line">  startothers();   <span class="comment">// start other processors</span></span><br><span class="line">  kinit2(P2V(<span class="number">4</span>*<span class="number">1024</span>*<span class="number">1024</span>), P2V(PHYSTOP)); <span class="comment">// must come after startothers()</span></span><br><span class="line">  userinit();      <span class="comment">// first user process</span></span><br><span class="line">  <span class="comment">// Finish setting up this processor in mpmain.</span></span><br><span class="line">  mpmain();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>AP被BSP在<code>startothers()</code>方法里启动，启动后会进入<code>mpenter()</code>方法，<code>mpenter()</code>方法的代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Other CPUs jump here from entryother.S.</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">mpenter(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  switchkvm(); </span><br><span class="line">  seginit();</span><br><span class="line">  lapicinit();</span><br><span class="line">  mpmain();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以看出，AP在执行完一些初始化后最后也是执行了<code>mpmain()</code>方法。</p><p>即每个CPU启动后都会执行<code>mpmain()</code>方法，<code>mpmain()</code>方法代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">mpmain(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">  cprintf(<span class="string">"cpu%d: starting\n"</span>, cpu-&gt;id);</span><br><span class="line">  idtinit();              <span class="comment">// load idt register</span></span><br><span class="line">  xchg(&amp;cpu-&gt;started, <span class="number">1</span>); <span class="comment">// tell startothers() we're up</span></span><br><span class="line">  scheduler();            <span class="comment">// start running processes</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<code>mpmain()</code>中，会打印输出当前正在启动的CPU的ID及“<code>starting</code>”，然后初始化IDT，将CPU的已启动标志置1，最后开始进程调度。至此，多核启动完成。</p><blockquote><p>BSP和AP启动时执行的函数对比：<br>1.BSP和AP都需要执行的几个函数是：<br>seginit() //段初始化<br>lapicinit() //本地APIC初始化<br>mpmain()</p><p>2.BSP需要执行而AP不需要执行的主要函数有：（按执行顺序）<br>kinit1(end, P2V(4*1024*1024)); // phys page allocator<br>kvmalloc(); // kernel page table<br>mpinit(); // collect info about this machine<br>picinit(); // interrupt controller<br>ioapicinit(); // another interrupt controller<br>consoleinit(); // I/O devices &amp; their interrupts<br>uartinit(); // serial port<br>pinit(); // process table<br>tvinit(); // trap vectors<br>binit(); // buffer cache<br>fileinit(); // file table<br>ideinit(); // disk<br>if(!ismp)<br>timerinit(); // uniprocessor timer<br>startothers(); // start other processors<br>kinit2(P2V(4*1024*1024), P2V(PHYSTOP)); // must come after startothers()<br>userinit(); // first user process</p><p>3.AP需要执行而BSP不需要执行的函数有：<br>switchkvm();</p></blockquote><h1 id="2-检测CPU个数的方法"><a href="#2-检测CPU个数的方法" class="headerlink" title="2 检测CPU个数的方法"></a>2 检测CPU个数的方法</h1><h2 id="2-1-系统首先进行查找MP浮点结构："><a href="#2-1-系统首先进行查找MP浮点结构：" class="headerlink" title="2.1 系统首先进行查找MP浮点结构："></a>2.1 系统首先进行查找MP浮点结构：</h2><p>①.如果BIOS扩展资料区域（EBDA）已经定义，则在其中的第一K字节中进行查找，否则到②；</p><p>②.若EBDA未被定义，则在系统基本内存的最后一K字节中寻找；</p><p>③.在BIOS ROM里的0xF0000到0xFFFFF的地址空间中寻找。</p><p>注：关于如何判断是否定义EBDA、EBDA的地址、系统基本内存的地址参见<a href="#附录1-Xv6启动中有关BDA的相关说明">附录1（Xv6启动中有关BDA的相关说明）</a>。</p><p>在实模式下运行以下代码：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> struct mp *<span class="title">mpsearch</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    uchar *bda;</span><br><span class="line">    uint p;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">mp</span> *<span class="title">mp</span>;</span></span><br><span class="line">    bda = (uchar *) P2V(<span class="number">0x400</span>); <span class="comment">// 将0x400转换成虚拟地址,0x400为BIOS存放检测到的数据（即BDA）的物理地址       </span></span><br><span class="line">    <span class="keyword">if</span>((p = ((bda[<span class="number">0x0F</span>]&lt;&lt;<span class="number">8</span>)| bda[<span class="number">0x0E</span>]) &lt;&lt; <span class="number">4</span>))&#123; <span class="comment">// 判断ebda是否存在，如果存在，将ebda的起始指针赋给p</span></span><br><span class="line">        <span class="keyword">if</span>((mp = mpsearch1(p, <span class="number">1024</span>)))           <span class="comment">// 在EDBA的前1024个字节中查找</span></span><br><span class="line">            <span class="keyword">return</span> mp;                          <span class="comment">// 找到后返回指向mp浮点结构的指针</span></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;                                    <span class="comment">// 如果EDBA未被定义</span></span><br><span class="line">        p = ((bda[<span class="number">0x14</span>]&lt;&lt;<span class="number">8</span>)|bda[<span class="number">0x13</span>])*<span class="number">1024</span>;    <span class="comment">// 得到系统基本内存的末尾边界地址</span></span><br><span class="line">        <span class="keyword">if</span>((mp = mpsearch1(p<span class="number">-1024</span>, <span class="number">1024</span>)))      <span class="comment">// 在系统基本内存的最后1K中查找</span></span><br><span class="line">            <span class="keyword">return</span> mp;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> mpsearch1(<span class="number">0xF0000</span>, <span class="number">0x10000</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-2-mpsearch1-方法"><a href="#2-2-mpsearch1-方法" class="headerlink" title="2.2 mpsearch1()方法"></a>2.2 mpsearch1()方法</h2><p>在如上代码中，被多次调用的<code>mpsearch1()</code>方法即为查找MP浮点结构的具体方法，<code>mpsearch1()</code>的代码如下：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">mp</span>*</span></span><br><span class="line"><span class="class"><span class="title">mpsearch1</span>(<span class="title">uint</span> <span class="title">a</span>, <span class="title">intlen</span>)  </span></span><br><span class="line"><span class="class">    // 从内存地址<span class="title">a</span>开始，长度为<span class="title">len</span>的区域中搜索，返回指向<span class="title">MP</span>浮点结构的指针</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">    uchar *e, *p, *addr;</span><br><span class="line"></span><br><span class="line">    addr = p2v(a);</span><br><span class="line">    e = addr+len;</span><br><span class="line">    <span class="keyword">for</span>(p = addr; p &lt; e; p += <span class="keyword">sizeof</span>(struct mp))</span><br><span class="line">        <span class="keyword">if</span>(<span class="built_in">memcmp</span>(p, <span class="string">"_MP_"</span>, <span class="number">4</span>) == <span class="number">0</span> &amp;&amp; sum(p, <span class="keyword">sizeof</span>(struct mp)) == <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">return</span> (struct mp*)p;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>可以看出，此方法将“_MP_”字符串作为了MP浮点结构的标识，匹配到此字符串即找到了MP浮点结构，本函数返回指向该MP浮点结构的指针。</p><h2 id="2-3-mp浮点结构的结构体："><a href="#2-3-mp浮点结构的结构体：" class="headerlink" title="2.3 mp浮点结构的结构体："></a>2.3 mp浮点结构的结构体：</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mp</span> &#123;</span>             <span class="comment">// floating pointer</span></span><br><span class="line">  uchar signature[<span class="number">4</span>];   <span class="comment">// 标志，为"_MP_"时表示此为MP浮点结构</span></span><br><span class="line">  <span class="keyword">void</span> *physaddr;       <span class="comment">// MP配置表头的物理地址</span></span><br><span class="line">  uchar length;         <span class="comment">// 此MP浮点结构的长度</span></span><br><span class="line">  uchar specrev;        <span class="comment">// [14]</span></span><br><span class="line">  uchar checksum;       <span class="comment">// all bytes must add up to 0</span></span><br><span class="line">  uchar type;           <span class="comment">// MP system config type</span></span><br><span class="line">  uchar imcrp;</span><br><span class="line">  uchar reserved[<span class="number">3</span>];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>如上，紧跟在”_MP_”此标识后面的就是指向MP配置表头物理地址的指针。mp.c文件中的mpconfig()方法返回了MP配置表头的虚拟地址，代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">mpconf</span>*</span></span><br><span class="line"><span class="class"><span class="title">mpconfig</span>(<span class="title">struct</span> <span class="title">mp</span> **<span class="title">pmp</span>)</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">mpconf</span> *<span class="title">conf</span>;</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">mp</span> *<span class="title">mp</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>((mp = mpsearch()) == <span class="number">0</span> || mp-&gt;physaddr == <span class="number">0</span>)</span><br><span class="line">                           <span class="comment">//判断MP浮点结构或者MP配置表头是否存在</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;              <span class="comment">//两者中有一个不存在即返回0</span></span><br><span class="line">  conf = (struct mpconf*) p2v((uint) mp-&gt;physaddr);</span><br><span class="line">              <span class="comment">//将MP配置表头的物理地址转换成虚拟地址并将值赋给conf</span></span><br><span class="line">  <span class="comment">//以下代码为对此地址及结构进行一些合法性判定</span></span><br><span class="line">  <span class="keyword">if</span>(<span class="built_in">memcmp</span>(conf, <span class="string">"PCMP"</span>, <span class="number">4</span>) != <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span>(conf-&gt;version != <span class="number">1</span> &amp;&amp; conf-&gt;version != <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">if</span>(sum((uchar*)conf, conf-&gt;length) != <span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">  *pmp = mp;</span><br><span class="line">  <span class="keyword">return</span> conf;             <span class="comment">//返回MP配置表头的虚拟地址</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MP配置表头的结构体如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mpconf</span> &#123;</span>         <span class="comment">// configuration table header</span></span><br><span class="line">  uchar signature[<span class="number">4</span>];           <span class="comment">// 标志为"PCMP"</span></span><br><span class="line">  ushort length;                <span class="comment">// MP配置表的长度</span></span><br><span class="line">  uchar version;                <span class="comment">// [14]</span></span><br><span class="line">  uchar checksum;               <span class="comment">// all bytes must add up to 0</span></span><br><span class="line">  uchar product[<span class="number">20</span>];            <span class="comment">// product id</span></span><br><span class="line">  uint *oemtable;               <span class="comment">// OEM table pointer</span></span><br><span class="line">  ushort oemlength;             <span class="comment">// OEM table length</span></span><br><span class="line">  ushort entry;                 <span class="comment">// 入口数</span></span><br><span class="line">  uint *lapicaddr;              <span class="comment">// local APIC的地址</span></span><br><span class="line">  ushort xlength;               <span class="comment">// extended table length</span></span><br><span class="line">  uchar xchecksum;              <span class="comment">// extended table checksum</span></span><br><span class="line">  uchar reserved;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="2-4-MP配置表"><a href="#2-4-MP配置表" class="headerlink" title="2.4 MP配置表"></a>2.4 MP配置表</h2><p>MP浮点结构中包含指向MP配置表头的物理地址的指针， MP配置表由MP配置表头（基本部分）和扩展部分组成，基本部分就是MP配置基表即MP配置表头，扩展部分紧跟表头后面，扩展部分由5种不同类型的入口组成，分别为：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Table entry types</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MPPROC    0x00  <span class="comment">//入口类型为处理器</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MPBUS     0x01  <span class="comment">//入口类型为总线</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MPIOAPIC  0x02  <span class="comment">//入口类型为I/O APIC</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MPIOINTR  0x03  <span class="comment">//入口类型为I/O 中断分配</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> MPLINTR   0x04  <span class="comment">//入口类型为逻辑中断分配</span></span></span><br></pre></td></tr></table></figure><h2 id="2-5-mpinit-方法"><a href="#2-5-mpinit-方法" class="headerlink" title="2.5 mpinit()方法"></a>2.5 mpinit()方法</h2><p>程序在<code>mpinit()</code>方法中遍历MP扩展部分通过判断入口类型来进行相应操作，如判断入口类型为<code>MPPROC</code>时则将ncpu加1,部分代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">bcpu = &amp;cpus[<span class="number">0</span>];</span><br><span class="line"><span class="keyword">if</span>((conf = mpconfig(&amp;mp)) == <span class="number">0</span>)          <span class="comment">//调用mpconfig()方法以获取MP配置表头，将值赋给conf并判断其是否为0，若为0，说明MP配置表头不存在，返回</span></span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">ismp = <span class="number">1</span>;</span><br><span class="line">lapic = (uint*)conf-&gt;lapicaddr;          <span class="comment">//初始化lapic为表头中的lapic地址</span></span><br><span class="line"><span class="keyword">for</span>(p=(uchar*)(conf+<span class="number">1</span>), e=(uchar*)conf+conf-&gt;length; p&lt;e; )&#123;</span><br><span class="line">    <span class="keyword">switch</span>(*p)&#123;</span><br><span class="line">        <span class="keyword">case</span> MPPROC:                     <span class="comment">//入口类型为处理器</span></span><br><span class="line">            proc = (struct mpproc*)p;</span><br><span class="line">            <span class="keyword">if</span>(ncpu != proc-&gt;apicid)&#123;</span><br><span class="line">                cprintf(<span class="string">"mpinit: ncpu=%d apicid=%d\n"</span>, ncpu, proc-&gt;apicid);</span><br><span class="line">                ismp = <span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span>(proc-&gt;flags &amp; MPBOOT)     <span class="comment">//判断此CPU是否为主引导CPU（BSP）</span></span><br><span class="line">                bcpu = &amp;cpus[ncpu];      <span class="comment">//若是BSP，将此CPU设为第0个CPU</span></span><br><span class="line">            cpus[ncpu].id = ncpu;        <span class="comment">//给每个CPU设置ID并存入cpus数组中</span></span><br><span class="line">            ncpu++;                      <span class="comment">//CPU个数+1</span></span><br><span class="line">            p += <span class="keyword">sizeof</span>(struct mpproc);  <span class="comment">//给p加上此种类型的长度</span></span><br><span class="line">            <span class="keyword">continue</span>;                    <span class="comment">//继续循环</span></span><br><span class="line">        <span class="keyword">case</span> MPIOAPIC:                   <span class="comment">//入口类型为I/O APIC</span></span><br><span class="line">            ioapic = (struct mpioapic*)p;      </span><br><span class="line">            ioapicid = ioapic-&gt;apicno;   <span class="comment">//给全局变量ioapicid赋值</span></span><br><span class="line">            p += <span class="keyword">sizeof</span>(struct mpioapic);<span class="comment">//给p加上此种类型的长度</span></span><br><span class="line">            <span class="keyword">continue</span>;                    <span class="comment">//继续循环</span></span><br><span class="line">        <span class="keyword">case</span> MPBUS:                      <span class="comment">//入口类型为总线</span></span><br><span class="line">        <span class="keyword">case</span> MPIOINTR:                   <span class="comment">//入口类型为I/O 中断分配</span></span><br><span class="line">        <span class="keyword">case</span> MPLINTR:                    <span class="comment">//入口类型为逻辑中断分配 </span></span><br><span class="line">            p += <span class="number">8</span>;                      <span class="comment">//给p加上此种类型的长度：8</span></span><br><span class="line">            <span class="keyword">continue</span>;                    <span class="comment">//继续循环</span></span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            cprintf(<span class="string">"mpinit: unknown config type %x\n"</span>, *p);</span><br><span class="line">            ismp = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>以上代码中,<br><code>mpproc</code>和<code>mpioapic</code>分别是CPU入口结构和I/OAPIC入口结构，他们的结构体定义如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mpproc</span> &#123;</span>         <span class="comment">// processor table entry</span></span><br><span class="line">  uchar type;                 <span class="comment">// 入口类型(0)</span></span><br><span class="line">  uchar apicid;               <span class="comment">// local APIC id</span></span><br><span class="line">  uchar version;              <span class="comment">// local APIC verison</span></span><br><span class="line">  uchar flags;                <span class="comment">// CPU flags（CPU启动的标志）</span></span><br><span class="line">    <span class="meta">#<span class="meta-keyword">define</span> MPBOOT 0x02       <span class="comment">// This proc is the bootstrap processor.</span></span></span><br><span class="line">  uchar signature[<span class="number">4</span>];         <span class="comment">// CPU signature</span></span><br><span class="line">  uint feature;               <span class="comment">// feature flags from CPUID instruction</span></span><br><span class="line">  uchar reserved[<span class="number">8</span>];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">mpioapic</span> &#123;</span>       <span class="comment">// I/O APIC table entry</span></span><br><span class="line">  uchar type;                 <span class="comment">// entry type (2)</span></span><br><span class="line">  uchar apicno;               <span class="comment">// I/O APIC id</span></span><br><span class="line">  uchar version;              <span class="comment">// I/O APIC version</span></span><br><span class="line">  uchar flags;                <span class="comment">// I/O APIC flags</span></span><br><span class="line">  uint *addr;                 <span class="comment">// I/O APIC address</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><h2 id="2-6-系统执行完mpinit-方法后即将CPU个数存入了全局变量ncpu中。"><a href="#2-6-系统执行完mpinit-方法后即将CPU个数存入了全局变量ncpu中。" class="headerlink" title="2.6 系统执行完mpinit()方法后即将CPU个数存入了全局变量ncpu中。"></a>2.6 系统执行完mpinit()方法后即将CPU个数存入了全局变量ncpu中。</h2><h1 id="3-startothers-方法"><a href="#3-startothers-方法" class="headerlink" title="3 startothers()方法"></a>3 startothers()方法</h1><p>xv6通过一个结构体将每个CPU的信息保存起来，具体的cpu结构体如下：(在proc.h中)</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Per-CPU state</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cpu</span> &#123;</span></span><br><span class="line">uchar id;                    <span class="comment">// Local APIC ID; index into cpus[] below</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">context</span> *<span class="title">scheduler</span>;</span>   <span class="comment">// swtch() here to enter scheduler</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">taskstate</span> <span class="title">ts</span>;</span>         <span class="comment">// Used by x86 to find stack for interrupt</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">segdesc</span> <span class="title">gdt</span>[<span class="title">NSEGS</span>];</span>   <span class="comment">// x86 global descriptor table</span></span><br><span class="line"><span class="keyword">volatile</span> uint started;       <span class="comment">// Has the CPU started?</span></span><br><span class="line"><span class="keyword">int</span> ncli;                    <span class="comment">// Depth of pushcli nesting.</span></span><br><span class="line"><span class="keyword">int</span> intena;                  <span class="comment">// Were interrupts enabled before pushcli?</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// Cpu-local storage variables; see below</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">cpu</span> *<span class="title">cpu</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">proc</span> *<span class="title">proc</span>;</span>           <span class="comment">// The currently-running process.</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>xv6使用一个数组来保存这样的结构体，并用一个全局变量表示CPU数量：<br><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="class"><span class="keyword">struct</span> <span class="title">cpu</span> <span class="title">cpus</span>[<span class="title">NCPU</span>];</span></span><br><span class="line"><span class="keyword">extern</span> <span class="keyword">int</span> ncpu;</span><br></pre></td></tr></table></figure></p><p>xv6调用<code>mpinit()</code>方法初始化了cpus结构体数组，并确定了<code>lapic地址</code>、<code>ioapicid</code>，得到了每个CPU的id和CPU数量，接下来在<code>main()</code>函数中调用<code>startothers()</code>函数来启动其他CPU。</p><p>在<code>startothers()</code>函数中，首先把<code>entryother.S</code>的代码拷贝到以<code>0x7000</code>起始的这块内存（因为这段内存未被使用）里。然后在<code>0x7000-4</code>、<code>0x7000-8</code>两个内存单元记录下<code>entryother.S</code>中将要进行跳转的内核栈位置以及<code>mpmain</code>的入口地址（<code>mpenter</code>）。<br>这样当CPU运行完<code>entryother.S</code>中的代码之后将进入<code>mpmain</code>过程。在<code>mpmain</code>中，每个CPU将进行中断表和段表的初始化，然后打开中断进入<code>scheduler()</code>过程。</p><p>有关<code>entryother</code>这段启动代码的说明：<br>根据Makefile的102到106行：<br><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">102：entryother: entryother.S</span></span><br><span class="line">103：  <span class="variable">$(CC)</span> <span class="variable">$(CFLAGS)</span> -fno-pic -nostdinc -I. -c entryother.S</span><br><span class="line">104：  <span class="variable">$(LD)</span> <span class="variable">$(LDFLAGS)</span> -N -e start -Ttext 0x7000 -o bootblockother.o entryother.o</span><br><span class="line">105：  <span class="variable">$(OBJCOPY)</span> -S -O binary -j .text bootblockother.o entryother</span><br><span class="line">106：  <span class="variable">$(OBJDUMP)</span> -S bootblockother.o &gt; entryother.asm</span><br></pre></td></tr></table></figure></p><p>可以了解到：Makefile的103行是通过gcc把<code>entryother.S</code>编译成目标文件<code>entryother.o</code>。104行是通过LD把<code>entryother.o</code>进行地址重定位，设定其起始入口点为<code>start</code>，起始地址位<code>0x7000</code>，并生成文件<code>bootblockother.o</code>。105行是通过<code>objcopy</code>把<code>bootblockother.o</code>转变成二进制代码<code>entryother</code>。106行是通过<code>objdump</code>把<code>bootblockother.o</code>反汇编成<code>entryother.asm</code>。</p><p>将<code>entryothers</code>移动到物理地址<code>0x7000</code>处使其能正常运行。因为这是其他CPU最初运行的内核代码，所以没有开启保护模式和分页机制，<code>entryothers</code>将页表设置为<code>entrypgdir</code>，在设置页表前，虚拟地址等于物理地址。</p><p><code>startothers()</code>代码说明如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">void</span></span><br><span class="line">startothers(<span class="keyword">void</span>)</span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">extern</span> uchar _binary_entryother_start[], _binary_entryother_size[];</span><br><span class="line">    uchar *code;</span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">cpu</span> *<span class="title">c</span>;</span></span><br><span class="line">    <span class="keyword">char</span> *<span class="built_in">stack</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Write entry code to unused memory at 0x7000.</span></span><br><span class="line">    <span class="comment">// The linker has placed the image of entryother.S in</span></span><br><span class="line">    <span class="comment">// _binary_entryother_start.</span></span><br><span class="line">    code = p2v(<span class="number">0x7000</span>);  <span class="comment">// 将启动代码复制到0x7000处</span></span><br><span class="line">    memmove(code, _binary_entryother_start, (uint)_binary_entryother_size);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span>(c = cpus; c &lt;cpus+ncpu; c++)&#123;</span><br><span class="line">        <span class="comment">//逐个开启每个CPU让每个CPU从entryothers中start标号开始运行</span></span><br><span class="line">        <span class="keyword">if</span>(c == cpus+cpunum())  <span class="comment">// cpunum()返回当前CPU的ID，所以此处即判断c是否指向BSP，若是，跳过后续部分继续循环</span></span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 告诉entryother.S堆栈地址、mpenter方法的地址和页表的地址。</span></span><br><span class="line">        <span class="built_in">stack</span> = kalloc();</span><br><span class="line">        *(<span class="keyword">void</span>**)(code<span class="number">-4</span>) = <span class="built_in">stack</span> + KSTACKSIZE;</span><br><span class="line">        *(<span class="keyword">void</span>**)(code<span class="number">-8</span>) = mpenter;  </span><br><span class="line">        *(<span class="keyword">int</span>**)(code<span class="number">-12</span>) = (<span class="keyword">void</span> *) v2p(entrypgdir);</span><br><span class="line"></span><br><span class="line">        lapicstartap(c-&gt;id, v2p(code));<span class="comment">//向这个CPU发中断，让此CPU执行boot程序，此方法将在下文中详细介绍。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// wait for cpu to finish mpmain()</span></span><br><span class="line">        <span class="keyword">while</span>(c-&gt;started == <span class="number">0</span>)        <span class="comment">//cpu启动后会将started变为1 ，所以若started为0，则继续循环</span></span><br><span class="line">            ;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由上述代码可知，BSP启动AP时经过了以下步骤：</p><p>1.复制启动代码到0x7000处，这部分代码相当于boot CPU的启动扇区代码</p><p>2.为每个AP分配stack（每个CPU都一个自己的stack）</p><p>3.告诉每个AP，kernel入口在哪里(mpenter函数)</p><p>4.告诉每个AP，页目录在哪里(entrypgdir)</p><h1 id="4-Xv6中断"><a href="#4-Xv6中断" class="headerlink" title="4 Xv6中断"></a>4 Xv6中断</h1><h2 id="4-1-Xv6系统中断说明："><a href="#4-1-Xv6系统中断说明：" class="headerlink" title="4.1  Xv6系统中断说明："></a>4.1  Xv6系统中断说明：</h2><p>Xv6系统在单核处理器上使用8259A中断控制器来处理中断（代码在<code>picirq.c</code>，此处不表），在多核处理器上采用了<code>APIC（Advanced Programmable Interrupt Controller）</code>来处理中断。</p><p>APIC机制中，每一颗 CPU 都需要一个中断控制器来处理发送给它的中断，而且也得有一个方法来分发中断。 这一方式包括两个部分：一个部分是在 I/O系统中的(<code>IO APIC</code>，<code>ioapic.c</code>)，另一部分是关联在每一个处理器上的(本地APIC，<code>lapic.c</code>)，本小节主要讲解<code>lapic</code>。</p><h2 id="4-2-地址："><a href="#4-2-地址：" class="headerlink" title="4.2 地址："></a>4.2 地址：</h2><p><code>lapic</code>的物理地址为<code>0xFEE00000</code>（参考Intel官方手册）。</p><p>在xv6系统中，系统通过调用<code>mpinit()</code>方法中，读取MP配置表头获取到了<code>lapic</code>的物理地址。<img src="http://ws1.sinaimg.cn/large/b40cee9bly1fw7xxyrbojj20l50cmdgo.jpg" alt=""></p><h2 id="4-3-lapic-c中的主要函数："><a href="#4-3-lapic-c中的主要函数：" class="headerlink" title="4.3 lapic.c中的主要函数："></a>4.3 lapic.c中的主要函数：</h2><p><code>lapicw()</code>: 写<code>Local APIC</code>寄存器，此函数有两个参数，第一个参数为<code>lapic</code>的偏移地址，第二个参数为要写入的值；<br><code>cpunum()</code>：返回正在运行的CPU的ID；<br><code>lapiceoi()</code>：响应中断，即向EOI寄存器发送0；<br><code>lapicinit()</code>：初始化本CPU的<code>Local APIC</code>；<br><code>lapicstartap()</code>：通过写ICR寄存器的方式启动AP，此函数有两个参数，第一个参数为要启动的AP的ID，第二个参数为启动代码的物理地址。具体讲解见下文。</p><h2 id="4-4-lapicstartap-函数说明："><a href="#4-4-lapicstartap-函数说明：" class="headerlink" title="4.4 lapicstartap()函数说明："></a>4.4 lapicstartap()函数说明：</h2><p>BSP通过向AP逐个发送中断来启动AP，首先发送INIT中断来初始化AP，然后发送SIPI中断来启动AP，发送中断使用的是写ICR寄存器的方式，代码说明如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 发送INIT中断以重置AP</span></span><br><span class="line">lapicw(ICRHI, apicid&lt;&lt;<span class="number">24</span>);             <span class="comment">//将目标CPU的ID写入ICR寄存器的目的地址域中</span></span><br><span class="line">lapicw(ICRLO, INIT | LEVEL | ASSERT);  <span class="comment">//在ASSERT的情况下将INIT中断写入ICR寄存器</span></span><br><span class="line">microdelay(<span class="number">200</span>);                       <span class="comment">//等待200ms</span></span><br><span class="line">lapicw(ICRLO, INIT | LEVEL);           <span class="comment">//在非ASSERT的情况下将INIT中断写入ICR寄存器</span></span><br><span class="line">microdelay(<span class="number">100</span>); <span class="comment">// 等待100ms (INTEL官方手册规定的是10ms,但是由于Bochs运行较慢，此处改为100ms)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//INTEL官方规定发送两次startup IPI中断</span></span><br><span class="line"><span class="keyword">for</span>(i = <span class="number">0</span>; i &lt; <span class="number">2</span>; i++)&#123;</span><br><span class="line">    lapicw(ICRHI, apicid&lt;&lt;<span class="number">24</span>);          <span class="comment">//将目标CPU的ID写入ICR寄存器的目的地址域中</span></span><br><span class="line">    lapicw(ICRLO, STARTUP | (addr&gt;&gt;<span class="number">12</span>));<span class="comment">//将SIPI中断写入ICR寄存器的传送模式域中，将启动代码写入向量域中</span></span><br><span class="line">    microdelay(<span class="number">200</span>);                    <span class="comment">//等待200ms</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-5-ICR寄存器说明："><a href="#4-5-ICR寄存器说明：" class="headerlink" title="4.5 ICR寄存器说明："></a>4.5 ICR寄存器说明：</h2><p>中断命令寄存器（ICR）是一个 64 位本地 APIC寄存器，允许运行在处理器上的软件指定和发送处理器间中断（IPI）给系统中的其它处理器。发送IPI时，必须设置ICR 以指明将要发送的 IPI消息的类型和目的处理器或处理器组。一般情况下，ICR寄存器的物理地址为0xFEE00300,其结构图如下：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fw7y5no71wj20eb0cv3zt.jpg" alt=""><br>如图，一般在传送模式域中写各种传送类型，本例中用到了101INIT和110Start Up两种类型。Destination Mode域是0时表示Destination Field域中为一个CPU的ID，是1时表示Destination Field域中为一组CPU。</p><p>SIPI是一个特殊的IPI。典型情况下，在发送SIPI时，ICR的向量域中指向一个启动例程，本例中即将entryother的代码地址写入了ICR的向量域，以启动AP。</p><h1 id="附录1-Xv6启动中有关BDA的相关说明"><a href="#附录1-Xv6启动中有关BDA的相关说明" class="headerlink" title="附录1 Xv6启动中有关BDA的相关说明"></a>附录1 Xv6启动中有关BDA的相关说明</h1><p>当计算机通电时，BIOS数据区（BIOS Data Area）将在000400h处创建。它长度为256字节（000400h - 0004FFh），包含有关系统环境的信息。该信息可以被任何程序访问和更改。计算机的大部分操作由此数据控制。此数据在启动过程中由POST（BIOS开机自检）加载。</p><p>如果EBDA（Extended BIOS Data Area,扩展BIOS数据区）不存在，BDA[0x0E]和BDA[0x0F]的值为0；如果EBDA存在，其段地址被保存在BDA[0x0E]和BDA[0x0F]中，其中BDA[0x0E]保存EBDA段地址的低8位，BDA[0x0F]保存EDBA段地址的高8位，所以(BDA[0x0F]\&lt;\&lt;8) | BDA[0x0E]就表示了EDBA的段地址，将段地址左移4位即为EBDA的物理地址，如下图，BDA[0x0F]=0x9F，BDA[0x0E]=0xC0，所以xv6中EBDA存在且段地址为0x9FC0，物理地址为0x9FC00。<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fw7y6mw3vkj20nw0hcdl8.jpg" alt=""><br>BDA[0x13]和BDA[0x14]分别存放着系统基本内存的大小的低8位和高8位，如上图，BDA[0x14]=0x2，BDA[0x13]=0x7F，所以系统基本内存的大小为0x27F个KB，再乘1024即将单位转化为了B。因为系统基本内存的地址是从0开始的，所以将指针p指向其内存大小，就获得了其末尾边界的地址。</p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XV6 </tag>
            
            <tag> 多核 </tag>
            
            <tag> lapic </tag>
            
            <tag> 中断 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark ML中Pipeline、特征转换和决策树分类算法的使用</title>
      <link href="/Spark-ML%E4%B8%ADPipeline%E3%80%81%E7%89%B9%E5%BE%81%E8%BD%AC%E6%8D%A2%E5%92%8C%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/Spark-ML%E4%B8%ADPipeline%E3%80%81%E7%89%B9%E5%BE%81%E8%BD%AC%E6%8D%A2%E5%92%8C%E5%86%B3%E7%AD%96%E6%A0%91%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>Spark中有关机器学习的库已经在从MLlib往ML逐步迁移了，MLlib库也将在Spark 3.0后停止维护，所以我们需要尽快熟悉ML库。<br>在Spark ML库中，核心数据对象由RDD变为了DataFrame，同时，ML库中有一些特征转换的方法，并提供了Pipeline这一工具，可以使用户很方便的将对数据的不同处理组合起来，一次运行，从而使整个机器学习过程变得更加易用、简洁、规范和高效。<br>本文将介绍使用Pipeline对数据进行特征转换后运行决策树分类算法的小例子。<br><a id="more"></a></p><h1 id="1-Pipeline简介"><a href="#1-Pipeline简介" class="headerlink" title="1 Pipeline简介"></a>1 Pipeline简介</h1><p>Pipeline一般翻译为流水线，简单讲就是将多种算法组合成一个流水线或工作流程。</p><h2 id="1-1-结构"><a href="#1-1-结构" class="headerlink" title="1.1 结构"></a>1.1 结构</h2><p>在结构上，一个Pipline会包含一个或多个Stage，每一个Stage都会完成一个任务，如数据处理、数据转化、模型训练、预测数据等。</p><p>使用时，需将每个Stage定义好，然后拼成一个Array，传给Pipeline的setStages方法就好，如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>().setStages(<span class="type">Array</span>(tokenizer, hashingTF, lr))</span><br></pre></td></tr></table></figure></p><p>其中<code>tokenizer</code>、<code>hashingTF</code>和<code>lr</code>就是三个Stage。</p><h2 id="1-2-组件"><a href="#1-2-组件" class="headerlink" title="1.2 组件"></a>1.2 组件</h2><p>Stage有两种，分别为Transformer和Estimator。</p><h3 id="1-2-1-Transformer"><a href="#1-2-1-Transformer" class="headerlink" title="1.2.1 Transformer"></a>1.2.1 Transformer</h3><p>Transformer可以翻译为转换器，主要是通过调用 <strong><code>transform()</code></strong> 方法，在原始数据上增加一列或多列来将一个DataFrame转成另一个DataFrame。</p><p>转换器主要有以下两种用法：</p><ol><li>特征变化：一个特征转换器输入一个DataFrame，读取其中一个或多个文本列，将其映射为新的特征向量列。输出一个新的带有特征向量列的DataFrame。</li><li>学习模型：一个学习模型转换器输入一个DataFrame，读取其中包括特征向量的列，预测每一个特征向量的标签。输出一个新的带有预测标签列的DataFrame。</li></ol><h3 id="1-2-2-Estimator"><a href="#1-2-2-Estimator" class="headerlink" title="1.2.2 Estimator"></a>1.2.2 Estimator</h3><p>Estimator可以翻译为估计器，主要是通过调用 <strong><code>fit()</code></strong> 方法，训练特征数据从而得到一个模型，这个模型就是一个Transformer。</p><p>一个小例子：（注：以下为伪代码）<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> trainingData = <span class="type">Transformer</span>.transform(data) <span class="comment">//转换器的第一种用法</span></span><br><span class="line"><span class="keyword">val</span> model = <span class="type">Estimator</span>.fit(trainingData) <span class="comment">//训练数据 得到模型</span></span><br><span class="line"><span class="keyword">val</span> resultData = model.transform(testData) <span class="comment">//转换器的第二种用法</span></span><br></pre></td></tr></table></figure></p><h1 id="2-决策树简介"><a href="#2-决策树简介" class="headerlink" title="2 决策树简介"></a>2 决策树简介</h1><p>决策树是一种树形结构，由节点和有向边组成。节点有两种类型：内部节点和叶节点，内部节点代表一个特征或属性，叶节点代表一个类。每个非叶节点代表一个特征属性上的测试，每个分支代表这个特征属性在某个值域上的输出。使用决策树进行决策的过程就是从根节点开始，测试待分类项中的相应属性，按照其值选择输出分支，直到达到叶节点，将叶节点存放的类别作为决策结果。</p><p>决策树算法本质上是从训练数据集上归纳出一组分类规则，遵循局部最优原则。即每次选择分类特征时，都挑选当前条件下最优的那个特征作为划分规则。</p><p>具体原理介绍读者可自行参考机器学习类相关书籍资料。</p><p>主要参数有：</p><ul><li>impurity 信息增益的计算标准，默认为“gini”</li><li>maxBins 树的最大高度，默认为5</li><li>maxDepth 用于分裂特征的最大划分量，默认为32</li></ul><h1 id="3-相关特征转换方法简介"><a href="#3-相关特征转换方法简介" class="headerlink" title="3 相关特征转换方法简介"></a>3 相关特征转换方法简介</h1><h2 id="3-1-StringIndexer"><a href="#3-1-StringIndexer" class="headerlink" title="3.1 StringIndexer"></a>3.1 StringIndexer</h2><p>StringIndexer（字符串-索引变换）是一个估计器，是将字符串列编码为标签索引列。索引位于[0,numLabels),按标签频率排序，频率最高的排0，依次类推，因此最常见的标签获取索引是0。</p><h2 id="3-2-VectorIndexer"><a href="#3-2-VectorIndexer" class="headerlink" title="3.2 VectorIndexer"></a>3.2 VectorIndexer</h2><p>VectorIndexer（向量-索引变换）是一种估计器，能够提高决策树或随机森林等ML方法的分类效果，是对数据集特征向量中的类别（离散值）特征进行编号。它能够自动判断哪些特征是离散值型的特征，并对他们进行编号。</p><h2 id="3-3-IndexToString"><a href="#3-3-IndexToString" class="headerlink" title="3.3 IndexToString"></a>3.3 IndexToString</h2><p>IndexToString（索引-字符串变换）是一种转换器，与StringIndexer对应，能将指标标签映射回原始字符串标签。一个常见的用例（下文的例子就是如此）是使用StringIndexer从标签生成索引，使用这些索引训练模型，并从IndexToString的预测索引列中检索原始标签。</p><p>以上所述三种特征转换方法在下面代码中均有实例展示</p><h1 id="4-运行实例"><a href="#4-运行实例" class="headerlink" title="4 运行实例"></a>4 运行实例</h1><h2 id="4-1-数据说明"><a href="#4-1-数据说明" class="headerlink" title="4.1 数据说明"></a>4.1 数据说明</h2><p>数据为LIBSVM格式文本文件</p><p>数据格式为：标签 特征ID:特征值 特征ID:特征值…… </p><p>内容如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[xuqm@cu01 ML_Data]$ cat input/sample_libsvm_data.txt </span><br><span class="line">0 128:51 129:159 130:253 131:159 132:50 155:48 156:238 157:252 158:252 159:252 160:237 182:54 183:227 184:253 185:252 186:239 187:233 188:252 189:57 190:6 208:10 209:60 210:224 211:252 212:253 213:252 214:202 215:84 216:252 217:253 218:122 236:163 237:252 238:252 239:252 240:253 241:252 242:252 243:96 244:189 245:253 246:167 263:51 264:238 265:253 266:253 267:190 268:114 269:253 270:228 271:47 272:79 273:255 274:168 290:48 291:238 292:252 293:252 294:179 295:12 296:75 297:121 298:21 301:253 302:243 303:50 317:38 318:165 319:253 320:233 321:208 322:84 329:253 330:252 331:165 344:7 345:178 346:252 347:240 348:71 349:19 350:28 357:253 358:252 359:195 372:57 373:252 374:252 375:63 385:253 386:252 387:195 400:198 401:253 402:190 413:255 414:253 415:196 427:76 428:246 429:252 430:112 441:253 442:252 443:148 455:85 456:252 457:230 458:25 467:7 468:135 469:253 470:186 471:12 483:85 484:252 485:223 494:7 495:131 496:252 497:225 498:71 511:85 512:252 513:145 521:48 522:165 523:252 524:173 539:86 540:253 541:225 548:114 549:238 550:253 551:162 567:85 568:252 569:249 570:146 571:48 572:29 573:85 574:178 575:225 576:253 577:223 578:167 579:56 595:85 596:252 597:252 598:252 599:229 600:215 601:252 602:252 603:252 604:196 605:130 623:28 624:199 625:252 626:252 627:253 628:252 629:252 630:233 631:145 652:25 653:128 654:252 655:253 656:252 657:141 658:37</span><br><span class="line">1 159:124 160:253 161:255 162:63 186:96 187:244 188:251 189:253 190:62 214:127 215:251 216:251 217:253 218:62 241:68 242:236 243:251 244:211 245:31 246:8 268:60 269:228 270:251 271:251 272:94 296:155 297:253 298:253 299:189 323:20 324:253 325:251 326:235 327:66 350:32 351:205 352:253 353:251 354:126 378:104 379:251 380:253 381:184 382:15 405:80 406:240 407:251 408:193 409:23 432:32 433:253 434:253 435:253 436:159 460:151 461:251 462:251 463:251 464:39 487:48 488:221 489:251 490:251 491:172 515:234 516:251 517:251 518:196 519:12 543:253 544:251 545:251 546:89 570:159 571:255 572:253 573:253 574:31 597:48 598:228 599:253 600:247 601:140 602:8 625:64 626:251 627:253 628:220 653:64 654:251 655:253 656:220 681:24 682:193 683:253 684:220</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">1 130:218 131:170 132:108 157:32 158:227 159:252 160:232 185:129 186:252 187:252 188:252 212:1 213:253 214:252 215:252 216:168 240:144 241:253 242:252 243:236 244:62 268:144 269:253 270:252 271:215 296:144 297:253 298:252 299:112 323:21 324:206 325:253 326:252 327:71 351:99 352:253 353:255 354:119 378:63 379:242 380:252 381:253 382:35 406:94 407:252 408:252 409:154 410:10 433:145 434:237 435:252 436:252 461:255 462:253 463:253 464:108 487:11 488:155 489:253 490:252 491:179 492:15 514:11 515:150 516:252 517:253 518:200 519:20 542:73 543:252 544:252 545:253 546:97 569:47 570:233 571:253 572:253 596:1 597:149 598:252 599:252 600:252 624:1 625:252 626:252 627:246 628:132 652:1 653:169 654:252 655:132</span><br><span class="line">1 130:116 131:255 132:123 157:29 158:213 159:253 160:122 185:189 186:253 187:253 188:122 213:189 214:253 215:253 216:122 241:189 242:253 243:253 244:122 267:2 268:114 269:243 270:253 271:186 272:19 295:100 296:253 297:253 298:253 299:48 323:172 324:253 325:253 326:253 327:48 351:172 352:253 353:253 354:182 355:19 378:133 379:251 380:253 381:175 382:4 405:107 406:251 407:253 408:253 409:65 432:26 433:194 434:253 435:253 436:214 437:40 459:105 460:205 461:253 462:253 463:125 464:40 487:139 488:253 489:253 490:253 491:81 514:41 515:231 516:253 517:253 518:159 519:16 541:65 542:155 543:253 544:253 545:172 546:4 569:124 570:253 571:253 572:253 573:98 597:124 598:253 599:253 600:214 601:41 624:22 625:207 626:253 627:253 628:139 653:124 654:253 655:162 656:9</span><br></pre></td></tr></table></figure></p><h2 id="4-2-代码及相关说明"><a href="#4-2-代码及相关说明" class="headerlink" title="4.2 代码及相关说明"></a>4.2 代码及相关说明</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.ml.<span class="type">Pipeline</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">DecisionTreeClassificationModel</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">DecisionTreeClassifier</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.evaluation.<span class="type">MulticlassClassificationEvaluator</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.feature.&#123;<span class="type">IndexToString</span>, <span class="type">StringIndexer</span>, <span class="type">VectorIndexer</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">DecisionTreeClassificationExample</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 构建Spark对象</span></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.</span><br><span class="line">      builder.</span><br><span class="line">      appName(<span class="string">"DecisionTreeClassificationExample"</span>).</span><br><span class="line">      getOrCreate()</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 读取数据集</span></span><br><span class="line">    <span class="comment">// 读取LIBSVM格式文本文件并保存为DataFrame.</span></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"file:///home/xuqm/ML_Data/input/sample_libsvm_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用StringIndexer转换标签列</span></span><br><span class="line">    <span class="keyword">val</span> labelIndexer = <span class="keyword">new</span> <span class="type">StringIndexer</span>().</span><br><span class="line">      setInputCol(<span class="string">"label"</span>).</span><br><span class="line">      setOutputCol(<span class="string">"indexedLabel"</span>).</span><br><span class="line">      fit(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用VectorIndexer转换特征列</span></span><br><span class="line">    <span class="comment">// 设置最大分类特征数为4</span></span><br><span class="line">    <span class="keyword">val</span> featureIndexer = <span class="keyword">new</span> <span class="type">VectorIndexer</span>().</span><br><span class="line">      setInputCol(<span class="string">"features"</span>).</span><br><span class="line">      setOutputCol(<span class="string">"indexedFeatures"</span>).</span><br><span class="line">      setMaxCategories(<span class="number">4</span>).</span><br><span class="line">      fit(data)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拆分成训练集和测试集(70%训练集，30%测试集).</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Array</span>(trainingData, testData) = data.randomSplit(<span class="type">Array</span>(<span class="number">0.7</span>, <span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定执行决策树分类算法的转换器（使用默认参数）</span></span><br><span class="line">    <span class="keyword">val</span> dt = <span class="keyword">new</span> <span class="type">DecisionTreeClassifier</span>().</span><br><span class="line">      setLabelCol(<span class="string">"indexedLabel"</span>).</span><br><span class="line">      setFeaturesCol(<span class="string">"indexedFeatures"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用IndexToString把预测的索引列转换成原始标签列</span></span><br><span class="line">    <span class="keyword">val</span> labelConverter = <span class="keyword">new</span> <span class="type">IndexToString</span>().</span><br><span class="line">      setInputCol(<span class="string">"prediction"</span>).</span><br><span class="line">      setOutputCol(<span class="string">"predictedLabel"</span>).</span><br><span class="line">      setLabels(labelIndexer.labels)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 组装成Pipeline.</span></span><br><span class="line">    <span class="keyword">val</span> pipeline = <span class="keyword">new</span> <span class="type">Pipeline</span>().</span><br><span class="line">      setStages(<span class="type">Array</span>(labelIndexer, featureIndexer, dt, labelConverter))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 训练模型</span></span><br><span class="line">    <span class="keyword">val</span> model = pipeline.fit(trainingData)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用训练好的模型预测测试集的结果</span></span><br><span class="line">    <span class="keyword">val</span> predictions = model.transform(testData)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出前10条数据</span></span><br><span class="line">    predictions.select(<span class="string">"predictedLabel"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算精度和误差</span></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>().</span><br><span class="line">      setLabelCol(<span class="string">"indexedLabel"</span>).</span><br><span class="line">      setPredictionCol(<span class="string">"prediction"</span>).</span><br><span class="line">      setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line">    <span class="keyword">val</span> accuracy = evaluator.evaluate(predictions)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出误差</span></span><br><span class="line">    println(<span class="string">"Test Error = "</span> + (<span class="number">1.0</span> - accuracy))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 从PipelineModel中取出决策树模型treeModel</span></span><br><span class="line">    <span class="keyword">val</span> treeModel = model.stages(<span class="number">2</span>).asInstanceOf[<span class="type">DecisionTreeClassificationModel</span>]</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 输出treeModel的决策过程</span></span><br><span class="line">    println(<span class="string">"Learned classification tree model:\n"</span> + treeModel.toDebugString)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="4-3-结果展示"><a href="#4-3-结果展示" class="headerlink" title="4.3 结果展示"></a>4.3 结果展示</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 输出前10条数据</span></span><br><span class="line">predictions.select(<span class="string">"predictedLabel"</span>, <span class="string">"label"</span>, <span class="string">"features"</span>).show(<span class="number">10</span>)</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">|predictedLabel|label|            features|</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">98</span>,<span class="number">99</span>,<span class="number">100</span>,<span class="number">1.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">100</span>,<span class="number">101</span>,<span class="number">102.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">124</span>,<span class="number">125</span>,<span class="number">126.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">125</span>,<span class="number">126</span>,<span class="number">127.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">126</span>,<span class="number">127</span>,<span class="number">128.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">150</span>,<span class="number">151</span>,<span class="number">152.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">152</span>,<span class="number">153</span>,<span class="number">154.</span>..|</span><br><span class="line">|           <span class="number">0.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">153</span>,<span class="number">154</span>,<span class="number">155.</span>..|</span><br><span class="line">|           <span class="number">1.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|</span><br><span class="line">|           <span class="number">1.0</span>|  <span class="number">0.0</span>|(<span class="number">692</span>,[<span class="number">154</span>,<span class="number">155</span>,<span class="number">156.</span>..|</span><br><span class="line">+--------------+-----+--------------------+</span><br><span class="line">only showing top <span class="number">10</span> rows</span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出误差</span></span><br><span class="line"><span class="type">Test</span> <span class="type">Error</span> = <span class="number">0.07999999999999996</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 输出treeModel的决策过程</span></span><br><span class="line"><span class="type">Learned</span> classification tree model:</span><br><span class="line"><span class="type">DecisionTreeClassificationModel</span> (uid=dtc_bcf718ed2979) of depth <span class="number">1</span> <span class="keyword">with</span> <span class="number">3</span> nodes</span><br><span class="line">  <span class="type">If</span> (feature <span class="number">406</span> &lt;= <span class="number">0.0</span>)</span><br><span class="line">   <span class="type">Predict</span>: <span class="number">1.0</span></span><br><span class="line">  <span class="type">Else</span> (feature <span class="number">406</span> &gt; <span class="number">0.0</span>)</span><br><span class="line">   <span class="type">Predict</span>: <span class="number">0.0</span></span><br></pre></td></tr></table></figure><h1 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5 参考资料"></a>5 参考资料</h1><p>[1]吴茂贵.深度实践Spark机器学习[M].北京:机械工业出版社.2018:34-37,51-57</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 特征转换 </tag>
            
            <tag> Pipeline </tag>
            
            <tag> 分类 </tag>
            
            <tag> 决策树 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark读取文本文件并转换为DataFrame</title>
      <link href="/Spark%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%B9%B6%E8%BD%AC%E6%8D%A2%E4%B8%BADataFrame/"/>
      <url>/Spark%E8%AF%BB%E5%8F%96%E6%96%87%E6%9C%AC%E6%96%87%E4%BB%B6%E5%B9%B6%E8%BD%AC%E6%8D%A2%E4%B8%BADataFrame/</url>
      
        <content type="html"><![CDATA[<p>Spark ML里的核心API已经由基于RDD换成了基于DataFrame，为了使读取到的值成为DataFrame类型，我们可以直接使用读取CSV的方式来读取文本文件，可问题来了，当文本文件中每一行的各个数据被不定数目的空格所隔开时，我们无法将这些不定数目的空格当作CSV文件的分隔符（因为Spark读取CSV文件时，不支持正则表达式作为分隔符），一个常用方法是先将数据读取为rdd，然后用map方法构建元组，再用toDF方法转为DataFrame，但是如果列数很多的话，构建元组会很麻烦。本文将介绍spark读取多列txt文件后转成DataFrame以供一些数据源使用的三种方法。</p><a id="more"></a><h1 id="1-数据说明"><a href="#1-数据说明" class="headerlink" title="1 数据说明"></a>1 数据说明</h1><p>使用Synthetic Control Chart Time Series数据synthetic_control.data，数据包括600个数据点(行)，每个数据点有60个属性，详细信息见:<br><a href="http://archive.ics.uci.edu/ml/databases/synthetic_control/" target="_blank" rel="noopener">http://archive.ics.uci.edu/ml/databases/synthetic_control/</a><br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fu2o2zjvqnj20z40itgs2.jpg" alt=""></p><p>如图，每个数据点的不同属性用不定数量的空格隔开，为了解决这个问题，本文将介绍<del>两种方法</del>（现已更新为三种方法）。<br>18.08.17更新！今天发现了一个新的方法，比原来的第二种方法还简单了许多，请读者在<a href="#4-上策">上策</a>中查看。</p><h1 id="2-下策"><a href="#2-下策" class="headerlink" title="2 下策"></a>2 下策</h1><h2 id="2-1-基本思想"><a href="#2-1-基本思想" class="headerlink" title="2.1 基本思想"></a>2.1 基本思想</h2><p>本方法非常繁琐且效率较低，是我在没看到第二种方法时自己想的，本方法的思想是：</p><ol><li>直接读取数据，保存成一个String类型的RDD</li><li>将此RDD中每一行中的不定数量的空格用正则表达式匹配选出后替换成“，”</li><li>将处理过后的RDD保存到一个临时目录中</li><li>以CSV方式读取此临时目录中的数据，便可将读到的数据直接存成一个多列的DataFrame</li><li>最后将此DataFrame的数据类型转为Double</li></ol><h2 id="2-2-代码"><a href="#2-2-代码" class="headerlink" title="2.2 代码"></a>2.2 代码</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.<span class="type">Configuration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.&#123;<span class="type">FileSystem</span>, <span class="type">Path</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.functions.col</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.&#123;<span class="type">DataFrame</span>, <span class="type">Row</span>, <span class="type">SparkSession</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">readData</span></span>(spark: <span class="type">SparkSession</span>, path: <span class="type">String</span>): <span class="type">DataFrame</span> = &#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 读取数据并将其中的分隔符（不定个数的空格）都转为“，”</span></span><br><span class="line">  <span class="keyword">val</span> tmpRdd = spark.sparkContext.textFile(path).map(_.replaceAll(<span class="string">"\\s+"</span>, <span class="string">","</span>))</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 将转换过的数据保存到一个临时目录中</span></span><br><span class="line">  <span class="keyword">val</span> tmpPathStr = <span class="string">"file:///home/xuqm/ML_Data/input/tmp"</span></span><br><span class="line">  <span class="comment">// 判断此临时目录是否存在，若存在则删除</span></span><br><span class="line">  <span class="keyword">val</span> tmpPath: <span class="type">Path</span> = <span class="keyword">new</span> <span class="type">Path</span>(tmpPathStr)</span><br><span class="line">  <span class="keyword">val</span> fs: <span class="type">FileSystem</span> = tmpPath.getFileSystem(<span class="keyword">new</span> <span class="type">Configuration</span>())</span><br><span class="line">  <span class="keyword">if</span> (fs.exists(tmpPath)) &#123;</span><br><span class="line">    fs.delete(tmpPath, <span class="literal">true</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// 保存</span></span><br><span class="line">  tmpRdd.saveAsTextFile(tmpPathStr)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 从此临时目录中以CSV方式读取数据</span></span><br><span class="line">  <span class="keyword">val</span> df = spark.read.csv(tmpPathStr)</span><br><span class="line">  <span class="comment">// 将读取到的数据中的每一列都转为Double类型</span></span><br><span class="line">  <span class="keyword">val</span> cols = df.columns.map(f =&gt; col(f).cast(<span class="type">DoubleType</span>))</span><br><span class="line">  <span class="keyword">val</span> data = df.select(cols: _*)</span><br><span class="line">  </span><br><span class="line">  data</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-中策"><a href="#3-中策" class="headerlink" title="3 中策"></a>3 中策</h1><h2 id="3-1-代码及说明"><a href="#3-1-代码及说明" class="headerlink" title="3.1 代码及说明"></a>3.1 代码及说明</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.sql.types._</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">Row</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取数据 暂存为RDD</span></span><br><span class="line"><span class="keyword">val</span> rdd = sc.textFile(<span class="string">"file:///home/xuqm/ML_Data/input/synthetic_control.data"</span>)</span><br><span class="line"><span class="comment">// 从第一行数据中获取最后转成的DataFrame应该有多少列 并给每一列命名</span></span><br><span class="line"><span class="keyword">val</span> colsLength = rdd.first.split(<span class="string">"\\s+"</span>).length</span><br><span class="line"><span class="keyword">val</span> colNames = <span class="keyword">new</span> <span class="type">Array</span>[<span class="type">String</span>](colsLength)</span><br><span class="line"><span class="keyword">for</span> (i &lt;- <span class="number">0</span> until colsLength) &#123;</span><br><span class="line">  colNames(i) = <span class="string">"col"</span> + (i + <span class="number">1</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// 将RDD动态转为DataFrame</span></span><br><span class="line"><span class="comment">// 设置DataFrame的结构</span></span><br><span class="line"><span class="keyword">val</span> schema = <span class="type">StructType</span>(colNames.map(fieldName =&gt; <span class="type">StructField</span>(fieldName, <span class="type">DoubleType</span>)))</span><br><span class="line"><span class="comment">// 对每一行的数据进行处理</span></span><br><span class="line"><span class="keyword">val</span> rowRDD = rdd.map(_.split(<span class="string">"\\s+"</span>).map(_.toDouble)).map(p =&gt; <span class="type">Row</span>(p: _*))</span><br><span class="line"><span class="comment">// 将数据和结构合成，创建为DataFrame</span></span><br><span class="line"><span class="keyword">val</span> data = spark.createDataFrame(rowRDD, schema)</span><br></pre></td></tr></table></figure><h2 id="3-2-结果展示"><a href="#3-2-结果展示" class="headerlink" title="3.2 结果展示"></a>3.2 结果展示</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> data = spark.createDataFrame(rowRDD, schema)</span><br><span class="line">data: org.apache.spark.sql.<span class="type">DataFrame</span> = [col1: double, col2: double ... <span class="number">58</span> more fields]</span><br><span class="line">scala&gt; data.show(<span class="number">2</span>)</span><br><span class="line">+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+</span><br><span class="line">|   col1|   col2|   col3|   col4|   col5|   col6|   col7|   col8|   col9|  col10|  col11|  col12|  col13| col14|  col15|  col16|  col17|  col18|  col19|  col20|  col21|  col22|  col23|  col24|  col25|  col26|  col27|  col28|  col29|  col30|  col31|  col32|  col33|  col34|  col35|  col36|  col37|  col38|  col39|  col40|  col41|  col42|  col43|  col44|  col45|  col46|  col47|  col48|  col49|  col50|  col51|  col52|  col53|  col54|  col55|  col56|  col57|  col58|  col59|  col60|</span><br><span class="line">+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+</span><br><span class="line">|<span class="number">28.7812</span>|<span class="number">34.4632</span>|<span class="number">31.3381</span>|<span class="number">31.2834</span>|<span class="number">28.9207</span>|<span class="number">33.7596</span>|<span class="number">25.3969</span>|<span class="number">27.7849</span>|<span class="number">35.2479</span>|<span class="number">27.1159</span>|<span class="number">32.8717</span>|<span class="number">29.2171</span>|<span class="number">36.0253</span>|<span class="number">32.337</span>|<span class="number">34.5249</span>|<span class="number">32.8717</span>|<span class="number">34.1173</span>|<span class="number">26.5235</span>|<span class="number">27.6623</span>|<span class="number">26.3693</span>|<span class="number">25.7744</span>|  <span class="number">29.27</span>|<span class="number">30.7326</span>|<span class="number">29.5054</span>|<span class="number">33.0292</span>|  <span class="number">25.04</span>|<span class="number">28.9167</span>|<span class="number">24.3437</span>|<span class="number">26.1203</span>|<span class="number">34.9424</span>|<span class="number">25.0293</span>|<span class="number">26.6311</span>|<span class="number">35.6541</span>|<span class="number">28.4353</span>|<span class="number">29.1495</span>|<span class="number">28.1584</span>|<span class="number">26.1927</span>|<span class="number">33.3182</span>|<span class="number">30.9772</span>|<span class="number">27.0443</span>|<span class="number">35.5344</span>|<span class="number">26.2353</span>|<span class="number">28.9964</span>|<span class="number">32.0036</span>|<span class="number">31.0558</span>|<span class="number">34.2553</span>|<span class="number">28.0721</span>|<span class="number">28.9402</span>|<span class="number">35.4973</span>| <span class="number">29.747</span>|<span class="number">31.4333</span>|<span class="number">24.5556</span>|<span class="number">33.7431</span>|<span class="number">25.0466</span>|<span class="number">34.9318</span>|<span class="number">34.9879</span>|<span class="number">32.4721</span>|<span class="number">33.3759</span>|<span class="number">25.4652</span>|<span class="number">25.8717</span>|</span><br><span class="line">|<span class="number">24.8923</span>| <span class="number">25.741</span>|<span class="number">27.5532</span>|<span class="number">32.8217</span>|<span class="number">27.8789</span>|<span class="number">31.5926</span>|<span class="number">31.4861</span>|<span class="number">35.5469</span>|<span class="number">27.9516</span>|<span class="number">31.6595</span>|<span class="number">27.5415</span>|<span class="number">31.1887</span>|<span class="number">27.4867</span>|<span class="number">31.391</span>| <span class="number">27.811</span>| <span class="number">24.488</span>|<span class="number">27.5918</span>|<span class="number">35.6273</span>|<span class="number">35.4102</span>|<span class="number">31.4167</span>|<span class="number">30.7447</span>|<span class="number">24.1311</span>|<span class="number">35.1422</span>|<span class="number">30.4719</span>|<span class="number">31.9874</span>|<span class="number">33.6615</span>|<span class="number">25.5511</span>|<span class="number">30.4686</span>|<span class="number">33.6472</span>|<span class="number">25.0701</span>|<span class="number">34.0765</span>|<span class="number">32.5981</span>|<span class="number">28.3038</span>|<span class="number">26.1471</span>|<span class="number">26.9414</span>|<span class="number">31.5203</span>|<span class="number">33.1089</span>|<span class="number">24.1491</span>|<span class="number">28.5157</span>|<span class="number">25.7906</span>|<span class="number">35.9519</span>|<span class="number">26.5301</span>|<span class="number">24.8578</span>|<span class="number">25.9562</span>|<span class="number">32.8357</span>|<span class="number">28.5322</span>|<span class="number">26.3458</span>|<span class="number">30.6213</span>|<span class="number">28.9861</span>|<span class="number">29.4047</span>|<span class="number">32.5577</span>|<span class="number">31.0205</span>|<span class="number">26.6418</span>|<span class="number">28.4331</span>|<span class="number">33.6564</span>|<span class="number">26.4244</span>|<span class="number">28.4661</span>|<span class="number">34.2484</span>|<span class="number">32.1005</span>| <span class="number">26.691</span>|</span><br><span class="line">+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+-------+</span><br><span class="line">only showing top <span class="number">2</span> rows</span><br></pre></td></tr></table></figure><h1 id="4-上策"><a href="#4-上策" class="headerlink" title="4 上策"></a>4 上策</h1><h2 id="4-1-基本思想"><a href="#4-1-基本思想" class="headerlink" title="4.1 基本思想"></a>4.1 基本思想</h2><ol><li>读取原始文件，用正则表达式分割每个样本点的属性值，保存成Array[String]类型的RDD</li><li>利用Spark ML库中的LabeledPoint类将数据转换成LabeledPoint类型的RDD。<br>LabeledPoint类型包含label列和features列，label列即标签列，是Double类型的，因为本次数据未经训练还没有标签，所以可随意给定一个数字；features列即特征向量列，是向量类型的，本次数据均为特征点，所以用Vectors类全部转换为向量类型。</li><li>将LabeledPoint类型的RDD转换为DataFrame并只选择其features列，得到一个新的DataFrame，然后就可以在此df上进行一些机器学习算法（如：KMeans）了。</li></ol><h2 id="4-2-代码"><a href="#4-2-代码" class="headerlink" title="4.2 代码"></a>4.2 代码</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.ml.feature.<span class="type">LabeledPoint</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.linalg.<span class="type">Vectors</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// 读取数据并分割每个样本点的属性值 形成一个Array[String]类型的RDD</span></span><br><span class="line"><span class="keyword">val</span> rdd = sc.textFile(<span class="string">"file:///home/xuqm/ML_Data/input/synthetic_control.data"</span>).map(_.split(<span class="string">"\\s+"</span>))</span><br><span class="line"><span class="comment">// 将rdd转换成LabeledPoint类型的RDD</span></span><br><span class="line"><span class="keyword">val</span> <span class="type">LabeledPointRdd</span> = rdd.map(x=&gt;<span class="type">LabeledPoint</span>(<span class="number">0</span>,<span class="type">Vectors</span>.dense(x.map(_.toDouble))))</span><br><span class="line"><span class="comment">// 转成DataFrame并只取"features"列</span></span><br><span class="line"><span class="keyword">val</span> data = spark.createDataFrame(<span class="type">LabeledPointRdd</span>).select(<span class="string">"features"</span>)</span><br></pre></td></tr></table></figure><h2 id="4-3-结果展示"><a href="#4-3-结果展示" class="headerlink" title="4.3 结果展示"></a>4.3 结果展示</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">val</span> data = spark.createDataFrame(<span class="type">LabeledPointRdd</span>).select(<span class="string">"features"</span>)</span><br><span class="line">data: org.apache.spark.sql.<span class="type">DataFrame</span> = [features: vector]</span><br><span class="line"></span><br><span class="line">scala&gt; data.show(<span class="number">2</span>,<span class="literal">false</span>)</span><br><span class="line">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|features                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |</span><br><span class="line">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">|[<span class="number">28.7812</span>,<span class="number">34.4632</span>,<span class="number">31.3381</span>,<span class="number">31.2834</span>,<span class="number">28.9207</span>,<span class="number">33.7596</span>,<span class="number">25.3969</span>,<span class="number">27.7849</span>,<span class="number">35.2479</span>,<span class="number">27.1159</span>,<span class="number">32.8717</span>,<span class="number">29.2171</span>,<span class="number">36.0253</span>,<span class="number">32.337</span>,<span class="number">34.5249</span>,<span class="number">32.8717</span>,<span class="number">34.1173</span>,<span class="number">26.5235</span>,<span class="number">27.6623</span>,<span class="number">26.3693</span>,<span class="number">25.7744</span>,<span class="number">29.27</span>,<span class="number">30.7326</span>,<span class="number">29.5054</span>,<span class="number">33.0292</span>,<span class="number">25.04</span>,<span class="number">28.9167</span>,<span class="number">24.3437</span>,<span class="number">26.1203</span>,<span class="number">34.9424</span>,<span class="number">25.0293</span>,<span class="number">26.6311</span>,<span class="number">35.6541</span>,<span class="number">28.4353</span>,<span class="number">29.1495</span>,<span class="number">28.1584</span>,<span class="number">26.1927</span>,<span class="number">33.3182</span>,<span class="number">30.9772</span>,<span class="number">27.0443</span>,<span class="number">35.5344</span>,<span class="number">26.2353</span>,<span class="number">28.9964</span>,<span class="number">32.0036</span>,<span class="number">31.0558</span>,<span class="number">34.2553</span>,<span class="number">28.0721</span>,<span class="number">28.9402</span>,<span class="number">35.4973</span>,<span class="number">29.747</span>,<span class="number">31.4333</span>,<span class="number">24.5556</span>,<span class="number">33.7431</span>,<span class="number">25.0466</span>,<span class="number">34.9318</span>,<span class="number">34.9879</span>,<span class="number">32.4721</span>,<span class="number">33.3759</span>,<span class="number">25.4652</span>,<span class="number">25.8717</span>] |</span><br><span class="line">|[<span class="number">24.8923</span>,<span class="number">25.741</span>,<span class="number">27.5532</span>,<span class="number">32.8217</span>,<span class="number">27.8789</span>,<span class="number">31.5926</span>,<span class="number">31.4861</span>,<span class="number">35.5469</span>,<span class="number">27.9516</span>,<span class="number">31.6595</span>,<span class="number">27.5415</span>,<span class="number">31.1887</span>,<span class="number">27.4867</span>,<span class="number">31.391</span>,<span class="number">27.811</span>,<span class="number">24.488</span>,<span class="number">27.5918</span>,<span class="number">35.6273</span>,<span class="number">35.4102</span>,<span class="number">31.4167</span>,<span class="number">30.7447</span>,<span class="number">24.1311</span>,<span class="number">35.1422</span>,<span class="number">30.4719</span>,<span class="number">31.9874</span>,<span class="number">33.6615</span>,<span class="number">25.5511</span>,<span class="number">30.4686</span>,<span class="number">33.6472</span>,<span class="number">25.0701</span>,<span class="number">34.0765</span>,<span class="number">32.5981</span>,<span class="number">28.3038</span>,<span class="number">26.1471</span>,<span class="number">26.9414</span>,<span class="number">31.5203</span>,<span class="number">33.1089</span>,<span class="number">24.1491</span>,<span class="number">28.5157</span>,<span class="number">25.7906</span>,<span class="number">35.9519</span>,<span class="number">26.5301</span>,<span class="number">24.8578</span>,<span class="number">25.9562</span>,<span class="number">32.8357</span>,<span class="number">28.5322</span>,<span class="number">26.3458</span>,<span class="number">30.6213</span>,<span class="number">28.9861</span>,<span class="number">29.4047</span>,<span class="number">32.5577</span>,<span class="number">31.0205</span>,<span class="number">26.6418</span>,<span class="number">28.4331</span>,<span class="number">33.6564</span>,<span class="number">26.4244</span>,<span class="number">28.4661</span>,<span class="number">34.2484</span>,<span class="number">32.1005</span>,<span class="number">26.691</span>]|</span><br><span class="line">+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+</span><br><span class="line">only showing top <span class="number">2</span> rows</span><br></pre></td></tr></table></figure><h1 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5 参考资料"></a>5 参考资料</h1><p>[1]董克伦.<a href="https://dongkelun.com/2018/04/27/dfChangeAllColDatatypes/" target="_blank" rel="noopener">spark 将DataFrame所有的列类型改为double</a>[OL].2018-04-27/2018-08-08<br>[2]董克伦.<a href="https://dongkelun.com/2018/05/11/rdd2df/" target="_blank" rel="noopener">旧版spark（1.6版本） 将rdd动态转为dataframe</a>[OL].2018-05-11/2018-08-08<br>[3]吴茂贵.深度实践Spark机器学习[M].北京:机械工业出版社.2018:104-106</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> RDD </tag>
            
            <tag> DataFrame </tag>
            
            <tag> CSV </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark中基于神经网络的MLPC(多层感知器分类器)的使用</title>
      <link href="/Spark%E4%B8%AD%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84MLPC-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8%E5%88%86%E7%B1%BB%E5%99%A8-%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/Spark%E4%B8%AD%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84MLPC-%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E5%99%A8%E5%88%86%E7%B1%BB%E5%99%A8-%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><code>MLPC(Multilayer Perceptron Classifier)</code>，多层感知器分类器，是一种基于前馈人工神经网络（ANN）的分类器。Spark中目前仅支持此种与神经网络有关的算法，在<code>ord.apache.spark.ml</code>中（并非<code>mllib</code>）。本文通过代码来演示用Spark运行MLPC的一个小例子。<br><a id="more"></a></p><h1 id="1-算法简介"><a href="#1-算法简介" class="headerlink" title="1 算法简介"></a>1 算法简介</h1><p>多层感知器是一种多层的前馈神经网络模型。</p><p>所谓前馈型神经网络，指其从输入层开始只接收前一层的输入，并把计算结果输出到后一层，并不会给前一层有所反馈，整个过程可以使用有向无环图来表示。该类型的神经网络由三层组成，分别是输入层<code>(Input Layer)</code>，一个或多个隐层<code>(Hidden Layer)</code>，输出层<code>(Output Layer)</code>，如图所示：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fu04y9jfgzj20dy083gm8.jpg" alt=""></p><p>MLPC采用了BP(反向传播，<code>Back Propagation</code>) 算法，BP算法的学习目的是对网络的连接权值进行调整，使得调整后的网络对任一输入都能得到所期望的输出。BP 算法名称里的反向传播指的是该算法在训练网络的过程中逐层反向传递误差，逐一修改神经元间的连接权值，以使网络对输入信息经过计算后所得到的输出能达到期望的误差。</p><p>Spark的多层感知器隐层神经元使用<code>sigmoid</code>函数作为激活函数，输出层使用的是<code>softmax</code>函数。</p><p>MLPC可调的几个重要参数:</p><ul><li>featuresCol：输入数据 DataFrame 中指标特征列的名称。</li><li>labelCol：输入数据 DataFrame 中标签列的名称。</li><li>layers：这个参数是一个整型数组类型，第一个元素需要和特征向量的维度相等，最后一个元素需要训练数据的标签数相等，如 2 分类问题就写 2。中间的元素有多少个就代表神经网络有多少个隐层，元素的取值代表了该层的神经元的个数。例如val layers = (5,6,5,2)。</li><li>maxIter：优化算法求解的最大迭代次数。默认值是 100。</li><li>predictionCol:预测结果的列名称。</li></ul><h1 id="2-运行步骤"><a href="#2-运行步骤" class="headerlink" title="2 运行步骤"></a>2 运行步骤</h1><h2 id="2-1-数据说明"><a href="#2-1-数据说明" class="headerlink" title="2.1 数据说明"></a>2.1 数据说明</h2><p>MLPC对数据源有严格要求，只能是以下两种：</p><ul><li>DataFrame<br>使用DataFrame作为数据源时必须指定DataFrame中的标签列和特征列；</li><li>LIBSVM格式文本文件<br>数据格式为：标签 特征ID:特征值 特征ID:特征值……</li></ul><p>本例中采用了LIBSVM格式文本文件，数据如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[xuqm@cu01 ML_Data]$ cat input/sample_multiclass_classification_data.txt </span><br><span class="line">1 1:-0.222222 2:0.5 3:-0.762712 4:-0.833333 </span><br><span class="line">1 1:-0.555556 2:0.25 3:-0.864407 4:-0.916667 </span><br><span class="line">1 1:-0.722222 2:-0.166667 3:-0.864407 4:-0.833333 </span><br><span class="line">1 1:-0.722222 2:0.166667 3:-0.694915 4:-0.916667 </span><br><span class="line">0 1:0.166667 2:-0.416667 3:0.457627 4:0.5 </span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">……</span><br><span class="line">2 1:-0.388889 2:-0.166667 3:0.186441 4:0.166667 </span><br><span class="line">0 1:-0.222222 2:-0.583333 3:0.355932 4:0.583333 </span><br><span class="line">1 1:-0.611111 2:-0.166667 3:-0.79661 4:-0.916667 </span><br><span class="line">1 1:-0.944444 2:-0.25 3:-0.864407 4:-0.916667 </span><br><span class="line">1 1:-0.388889 2:0.166667 3:-0.830508 4:-0.75</span><br></pre></td></tr></table></figure></p><h2 id="2-2-代码及说明"><a href="#2-2-代码及说明" class="headerlink" title="2.2 代码及说明"></a>2.2 代码及说明</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.spark.ml.classification.<span class="type">MultilayerPerceptronClassifier</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.ml.evaluation.<span class="type">MulticlassClassificationEvaluator</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">MLPCTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 构建spark对象</span></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="type">SparkSession</span>.builder.appName(<span class="string">"MLPCTest"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 读取以LIBSVM格式存储的数据</span></span><br><span class="line">    <span class="keyword">val</span> data = spark.read.format(<span class="string">"libsvm"</span>).load(<span class="string">"file:///home/xuqm/ML_Data/input/sample_multiclass_classification_data.txt"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 拆分成训练集和测试集</span></span><br><span class="line">    <span class="keyword">val</span> splits = data.randomSplit(<span class="type">Array</span>(<span class="number">0.6</span>, <span class="number">0.4</span>), seed = <span class="number">1234</span>L)</span><br><span class="line">    <span class="keyword">val</span> train = splits(<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">val</span> test = splits(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 指定神经网络的图层：</span></span><br><span class="line">    <span class="comment">// 输入层4个结点(即4个特征)；两个隐藏层，隐藏结点数分别为5和4；输出层3个结点(即分为3类)</span></span><br><span class="line">    <span class="keyword">val</span> layers = <span class="type">Array</span>[<span class="type">Int</span>](<span class="number">4</span>, <span class="number">5</span>, <span class="number">4</span>, <span class="number">3</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 建立MLPC训练器并设置参数</span></span><br><span class="line">    <span class="keyword">val</span> trainer = <span class="keyword">new</span> <span class="type">MultilayerPerceptronClassifier</span>()</span><br><span class="line">      .setLayers(layers)</span><br><span class="line">      .setBlockSize(<span class="number">128</span>)</span><br><span class="line">      .setSeed(<span class="number">1234</span>L)</span><br><span class="line">      .setMaxIter(<span class="number">100</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 训练模型</span></span><br><span class="line">    <span class="keyword">val</span> model = trainer.fit(train)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用训练好的模型预测测试集的结果</span></span><br><span class="line">    <span class="keyword">val</span> result = model.transform(test)</span><br><span class="line">    <span class="keyword">val</span> predictionAndLabels = result.select(<span class="string">"prediction"</span>, <span class="string">"label"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 计算精度并输出</span></span><br><span class="line">    <span class="keyword">val</span> evaluator = <span class="keyword">new</span> <span class="type">MulticlassClassificationEvaluator</span>().setMetricName(<span class="string">"accuracy"</span>)</span><br><span class="line">    println(<span class="string">"Test set accuracy = "</span> + evaluator.evaluate(predictionAndLabels))</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 输出结果</span></span><br><span class="line">    result.show(<span class="number">60</span>,<span class="literal">false</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-结果展示"><a href="#3-结果展示" class="headerlink" title="3 结果展示"></a>3 结果展示</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">// 计算精度并输出</span><br><span class="line">Test <span class="built_in">set</span> accuracy = 0.9019607843137255</span><br><span class="line"></span><br><span class="line">// 输出结果</span><br><span class="line">result.show(60,<span class="literal">false</span>)</span><br><span class="line">+-----+---------------------------------------------------------+----------+</span><br><span class="line">|label|features                                                 |prediction|</span><br><span class="line">+-----+---------------------------------------------------------+----------+</span><br><span class="line">|0.0  |(4,[0,1,2,3],[-0.666667,-0.583333,0.186441,0.333333])    |2.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[-0.277778,-0.333333,0.322034,0.583333])    |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[-0.222222,-0.583333,0.355932,0.583333])    |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[-0.0555556,-0.833333,0.355932,0.166667])   |2.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[-0.0555556,-0.166667,0.288136,0.416667])   |2.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[-1.32455E-7,-0.166667,0.322034,0.416667])  |2.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.111111,-0.583333,0.355932,0.5])          |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.222222,-0.166667,0.627119,0.75])         |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.333333,-0.583333,0.627119,0.416667])     |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.333333,-0.166667,0.423729,0.833333])     |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.388889,-0.166667,0.525424,0.666667])     |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.444444,-0.0833334,0.38983,0.833333])     |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.555555,-0.166667,0.661017,0.666667])     |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.722222,-0.333333,0.728813,0.5])          |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[0.888889,-0.333333,0.932203,0.583333])     |0.0       |</span><br><span class="line">|0.0  |(4,[0,1,2,3],[1.0,0.5,0.830508,0.583333])                |0.0       |</span><br><span class="line">|0.0  |(4,[0,2,3],[0.166667,0.457627,0.833333])                 |0.0       |</span><br><span class="line">|0.0  |(4,[0,2,3],[0.388889,0.661017,0.833333])                 |0.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.944444,-0.166667,-0.898305,-0.916667])  |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.722222,-0.166667,-0.864407,-0.833333])  |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.666667,-0.166667,-0.864407,-0.916667])  |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.666667,-0.0833334,-0.830508,-1.0])      |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.611111,0.166667,-0.79661,-0.75])        |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.555556,0.166667,-0.830508,-0.916667])   |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.555556,0.5,-0.830508,-0.833333])        |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.555556,0.5,-0.79661,-0.916667])         |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.5,0.166667,-0.864407,-0.916667])        |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.5,0.75,-0.830508,-1.0])                 |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.388889,0.166667,-0.830508,-0.75])       |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.388889,0.166667,-0.762712,-0.916667])   |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.388889,0.583333,-0.898305,-0.75])       |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.388889,0.583333,-0.762712,-0.75])       |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.333333,0.25,-0.898305,-0.916667])       |1.0       |</span><br><span class="line">|1.0  |(4,[0,1,2,3],[-0.166667,0.666667,-0.932203,-0.916667])   |1.0       |</span><br><span class="line">|1.0  |(4,[0,2,3],[-0.833333,-0.864407,-0.916667])              |1.0       |</span><br><span class="line">|1.0  |(4,[0,2,3],[-0.777778,-0.898305,-0.916667])              |1.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.611111,-1.0,-0.152542,-0.25])           |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.555556,-0.583333,-0.322034,-0.166667])  |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.388889,-0.166667,0.186441,0.166667])    |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.333333,-0.666667,-0.0847458,-0.25])     |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.333333,-0.666667,-0.0508475,-0.166667]) |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.277778,-0.166667,0.186441,0.166667])    |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.222222,-0.5,-0.152542,-0.25])           |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.222222,-0.333333,0.0508474,-4.03573E-8])|2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.111111,-0.166667,0.0847457,0.166667])   |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-0.0555556,-0.25,0.186441,0.166667])       |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[-1.32455E-7,-0.25,0.254237,0.0833333])     |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[0.0555554,-0.833333,0.186441,0.166667])    |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[0.0555554,-0.25,0.118644,-4.03573E-8])     |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[0.111111,0.0833333,0.254237,0.25])         |2.0       |</span><br><span class="line">|2.0  |(4,[0,1,2,3],[0.333333,-0.166667,0.355932,0.333333])     |0.0       |</span><br><span class="line">+-----+---------------------------------------------------------+----------+</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> 分类 </tag>
            
            <tag> 神经网络 </tag>
            
            <tag> MLPC </tag>
            
            <tag> 多层感知器 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>浪潮集群上使用Hadoop和Spark</title>
      <link href="/%E6%B5%AA%E6%BD%AE%E9%9B%86%E7%BE%A4%E4%B8%8A%E4%BD%BF%E7%94%A8Hadoop%E5%92%8CSpark/"/>
      <url>/%E6%B5%AA%E6%BD%AE%E9%9B%86%E7%BE%A4%E4%B8%8A%E4%BD%BF%E7%94%A8Hadoop%E5%92%8CSpark/</url>
      
        <content type="html"><![CDATA[<p>忙活了半天，终于在实验室的浪潮集群中配置好了hadoop和spark，以后能用配置这么高的服务器了，想想就好开心~<br><a id="more"></a></p><h1 id="1-环境简介"><a href="#1-环境简介" class="headerlink" title="1 环境简介"></a>1 环境简介</h1><h2 id="1-1-软件版本"><a href="#1-1-软件版本" class="headerlink" title="1.1 软件版本"></a>1.1 软件版本</h2><ul><li>Hadoop版本号：2.7.4</li><li>Spark版本号：2.1.1</li></ul><h2 id="1-2-运行环境"><a href="#1-2-运行环境" class="headerlink" title="1.2 运行环境"></a>1.2 运行环境</h2><p>部署于西北工业大学高性能计算中心的浪潮集群服务器，master节点为cu01，slaves节点为cu02、cu03、cu04。</p><p>Hadoop安装目录为<code>/opt/software/hadoop/hadoop-2.7.4</code></p><p>Spark安装目录为<code>/opt/software/hadoop/spark-2.1.1</code></p><h1 id="2-使用说明"><a href="#2-使用说明" class="headerlink" title="2 使用说明"></a>2 使用说明</h1><h2 id="2-1-登录"><a href="#2-1-登录" class="headerlink" title="2.1 登录"></a>2.1 登录</h2><p>可使用xshell等软件用ssh方式连接到cu01（仅限西工大校园网内网，IP地址：<code>202.***.***.29</code>），登录账号：<code>xuqm</code>，密码：<code>********</code>。</p><h2 id="2-2-启动Hadoop"><a href="#2-2-启动Hadoop" class="headerlink" title="2.2 启动Hadoop"></a>2.2 启动Hadoop</h2><p>进入hadoop的安装目录，输入<code>sbin/start-dfs.sh</code>,如图：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvg6346wzj20vm04vgm1.jpg" alt=""></p><p>之后可输入<code>hdfs dfsadmin -report</code>查看节点状态以确定是否启动成功，如下图：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvg7tovcwj20cm10jq4v.jpg" alt=""></p><p>所有节点都正常运行，表示启动成功。也可进入网页查看，地址：<code>http://202.***.***.29:50070</code>。</p><h2 id="2-3-启动Spark"><a href="#2-3-启动Spark" class="headerlink" title="2.3 启动Spark"></a>2.3 启动Spark</h2><p>在本集群中，要使用spark必须先启动hadoop（即进行上一步2.2）。之后进入Spark的安装目录，通过输入<code>sbin/start-master.sh</code>和<code>sbin/start-slaves.sh</code>来启动spark的主、从节点：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvgb81dr1j213b07d3ze.jpg" alt=""></p><p>在主节点上和从节点上输入<code>jps</code>查看当前进程以确定是否启动成功：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvgbougksj20ek094aae.jpg" alt=""></p><p>若观察到主节点上有Master进程，从节点上有Worker进程，则表示启动成功。</p><h2 id="2-4-使用Hadoop"><a href="#2-4-使用Hadoop" class="headerlink" title="2.4 使用Hadoop"></a>2.4 使用Hadoop</h2><p>这里演示一个hadoop自带的词频统计的例子：</p><h3 id="2-4-1-准备数据"><a href="#2-4-1-准备数据" class="headerlink" title="2.4.1 准备数据"></a>2.4.1 准备数据</h3><p>创建一个文件，给其中写入几句话，并将此文件上传至HDFS上。例如：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvh3ztwr2j20kw02xweb.jpg" alt=""></p><h3 id="2-4-2-运行"><a href="#2-4-2-运行" class="headerlink" title="2.4.2 运行"></a>2.4.2 运行</h3><p>进入hadoop的安装目录，输入如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xuqm@cu01 hadoop-2.7.4]$ hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.4.jar wordcount /user/xuqm/hadoop_test/input /user/xuqm/hadoop_test/output</span><br></pre></td></tr></table></figure></p><p>其中，<code>wordcount</code>是jar包中的一个类，后两个参数分别为原始数据的存放路径和经处理后结果的存放路径。</p><h3 id="2-4-3-查看结果"><a href="#2-4-3-查看结果" class="headerlink" title="2.4.3 查看结果"></a>2.4.3 查看结果</h3><p>查看存放结果的目录，如下图，发现有_SUCCESS文件，表示处理成功：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvhd4ikl8j20sg02e746.jpg" alt=""></p><p>查看另一个文件的内容即为最终结果：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvhg95xjaj20n805p3yd.jpg" alt=""></p><h2 id="2-5-使用Spark"><a href="#2-5-使用Spark" class="headerlink" title="2.5 使用Spark"></a>2.5 使用Spark</h2><p>正常运行完上述启动步骤后，便可使用spark了。可以通过<code>spark-shell</code>（使用Scala语言）或<code>pyspark</code>（使用Python语言）进行交互式编程，或者使用<code>spark-submit</code>提交已写好的程序到集群上运行。需要注意的是，在执行上述命令时，需加上参数<code>--master spark://cu01:7077</code>,否则spark将会以local模式运行。</p><blockquote><p>注：<code>spark-shell</code>、<code>pyspark</code>、<code>spark-submit</code>都在bin文件夹下</p></blockquote><p>举个例子：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvgew1zugj21160caaan.jpg" alt=""></p><p>再如，用submit提交运行一个ALS最小二乘法的推荐算法小例子（代码详见<a href="https://qiming.info/Spark-MLlib%E4%B8%ADALS%E4%BA%A4%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/">Spark MLlib中ALS交替最小二乘法推荐算法的使用</a>），输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[xuqm@cu01 spark-2.1.1]$ ./bin/spark-submit --master spark://cu01:7077 /home/xuqm/spark_mllib_test.jar</span><br></pre></td></tr></table></figure></p><p>输出如下：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvggv2tkhj20ao02q3yd.jpg" alt=""></p><p>可以进入网页查看spark各节点的运行状态，地址：<code>http://202.***.***.29:8080/</code>，在spark运行时，可进入<code>http://202.***.***.29:4040/</code> 查看作业运行情况。</p><h2 id="2-6-关闭"><a href="#2-6-关闭" class="headerlink" title="2.6 关闭"></a>2.6 关闭</h2><p>程序运行结束，关闭spark和hadoop时应按照一定顺序，即和启动顺序相反：先关spark，再关hadoop。关闭方式和启动方式类似，将对应的start都改为stop即可。</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvgjfiyilj20dh09jt8u.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Hadoop </tag>
            
            <tag> 集群 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark MLlib中ALS交替最小二乘法推荐算法的使用</title>
      <link href="/Spark-MLlib%E4%B8%ADALS%E4%BA%A4%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/Spark-MLlib%E4%B8%ADALS%E4%BA%A4%E6%9B%BF%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%B3%95%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p><code>ALS(Alternating Least Square)</code>，交替最小二乘法。在机器学习中，特指使用最小二乘法的一种协同推荐算法。本文通过代码来演示用spark运行ALS算法的一个小例子。<br><a id="more"></a></p><h1 id="1-算法简介"><a href="#1-算法简介" class="headerlink" title="1 算法简介"></a>1 算法简介</h1><p>ALS算法通过观察到的所有用户给商品的打分，来推断每个用户的喜好并向用户推荐适合的商品。</p><p>其原理简单说就是假设用户评分矩阵是用户特征矩阵乘以物品特征矩阵得到的，即：<code>A(m*n)=U(m*k)*V(k*n)</code>，然后得到一个评分矩阵。具体原理请自行查阅，本文主要为使用。</p><p>通常，调用ALS算法进行训练时有4个重要参数，分别是<code>ratings</code>，<code>rank</code>，<code>iterations</code>，和<code>lambda</code>。</p><ul><li><code>ratings</code>指用户提供的训练数据，它包括用户id集、商品id集以及相应的打分集；</li><li><code>rank</code>表示隐含因素的数量，即特征的数量，也就是分解矩阵的k值。</li><li><code>iterations</code>表示最大迭代次数；</li><li><code>lambda</code>表示正则因子，可省略，默认为0.01。</li></ul><h1 id="2-运行步骤"><a href="#2-运行步骤" class="headerlink" title="2 运行步骤"></a>2 运行步骤</h1><h2 id="2-1-数据说明"><a href="#2-1-数据说明" class="headerlink" title="2.1 数据说明"></a>2.1 数据说明</h2><p>数据格式为：用户id，物品id，评分<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[xuqm@cu01 ML_Data]$ cat input/test.data </span><br><span class="line">1,1,5.0</span><br><span class="line">1,2,1.0</span><br><span class="line">1,3,5.0</span><br><span class="line">1,4,1.0</span><br><span class="line">2,1,5.0</span><br><span class="line">2,2,1.0</span><br><span class="line">2,3,5.0</span><br><span class="line">2,4,1.0</span><br><span class="line">3,1,1.0</span><br><span class="line">3,2,5.0</span><br><span class="line">3,3,1.0</span><br><span class="line">3,4,5.0</span><br><span class="line">4,1,1.0</span><br><span class="line">4,2,5.0</span><br><span class="line">4,3,1.0</span><br><span class="line">4,4,5.0</span><br></pre></td></tr></table></figure></p><h2 id="2-2-代码及说明"><a href="#2-2-代码及说明" class="headerlink" title="2.2 代码及说明"></a>2.2 代码及说明</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">package</span> nwpuhpc.antirisk.ml</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.recommendation.&#123;<span class="type">ALS</span>, <span class="type">Rating</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ALSTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构建Spark对象</span></span><br><span class="line">  <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"ALSTest"</span>)</span><br><span class="line">  <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">  <span class="type">Logger</span>.getRootLogger.setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 读取样本数据</span></span><br><span class="line">  <span class="keyword">val</span> data = sc.textFile(<span class="string">"/home/xuqm/ML_Data/input/test.data"</span>)</span><br><span class="line">  <span class="keyword">val</span> ratings = data.map(_.split(',') <span class="keyword">match</span> &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Array</span>(user, item, rate) =&gt;</span><br><span class="line">      <span class="type">Rating</span>(user.toInt, item.toInt, rate.toDouble)</span><br><span class="line">  &#125;)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 拆分成训练集和测试集</span></span><br><span class="line">  <span class="keyword">val</span> dataParts = ratings.randomSplit(<span class="type">Array</span>(<span class="number">0.8</span>, <span class="number">0.2</span>))</span><br><span class="line">  <span class="keyword">val</span> trainingRDD = dataParts(<span class="number">0</span>).cache()</span><br><span class="line">  <span class="keyword">val</span> testRDD = dataParts(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 建立ALS交替最小二乘算法模型并训练</span></span><br><span class="line">  <span class="keyword">val</span> rank = <span class="number">10</span></span><br><span class="line">  <span class="keyword">val</span> numIterations = <span class="number">20</span></span><br><span class="line">  <span class="keyword">val</span> model = <span class="type">ALS</span>.train(trainingRDD, rank, numIterations, <span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 取出测试集中的用户id和商品id</span></span><br><span class="line">  <span class="keyword">val</span> usersProducts = testRDD.map &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Rating</span>(user, product, rate) =&gt;</span><br><span class="line">      (user, product)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 用训练好的模型预测测试集的结果</span></span><br><span class="line">  <span class="keyword">val</span> predictions = model.predict(usersProducts).map &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Rating</span>(user, product, rate) =&gt;</span><br><span class="line">      ((user, product), rate)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">val</span> ratesAndPreds = testRDD.map &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">Rating</span>(user, product, rate) =&gt;</span><br><span class="line">      ((user, product), rate)</span><br><span class="line">  &#125;.join(predictions)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 输出误差</span></span><br><span class="line">  <span class="keyword">val</span> <span class="type">MSE</span> = ratesAndPreds.map &#123;</span><br><span class="line">    <span class="keyword">case</span> ((user, product), (r1, r2)) =&gt;</span><br><span class="line">      <span class="keyword">val</span> err = (r1 - r2)</span><br><span class="line">      err * err</span><br><span class="line">  &#125;.mean()</span><br><span class="line">  println(<span class="string">"Mean Squared Error = "</span> + <span class="type">MSE</span>)</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 打印输出预测值</span></span><br><span class="line">  println(<span class="string">"User"</span> + <span class="string">"\t"</span> + <span class="string">"Products"</span> + <span class="string">"\t"</span> + <span class="string">"Rate"</span> + <span class="string">"\t"</span> + <span class="string">"Prediction"</span>)</span><br><span class="line">  ratesAndPreds.collect.foreach(</span><br><span class="line">    rating =&gt; &#123;</span><br><span class="line">      println(rating._1._1 + <span class="string">"\t"</span> + rating._1._2 + <span class="string">"\t"</span> + rating._2._1 + <span class="string">"\t"</span> + rating._2._2)</span><br><span class="line">    &#125;</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-结果展示"><a href="#3-结果展示" class="headerlink" title="3 结果展示"></a>3 结果展示</h1><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvedb2smsj20c602xq2r.jpg" alt=""></p><p>可以看出，误差不是很大。</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> ALS </tag>
            
            <tag> 协同过滤 </tag>
            
            <tag> 推荐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark MLlib中FPGrowth关联规则算法的使用</title>
      <link href="/Spark-MLlib%E4%B8%ADFPGrowth%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/Spark-MLlib%E4%B8%ADFPGrowth%E5%85%B3%E8%81%94%E8%A7%84%E5%88%99%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>FPGrowth（频繁模式增长）是一种关联规则分析算法，本文通过代码演示用spark运行FPGrowth算法的一个小例子。<br><a id="more"></a></p><h1 id="1-关联规则简介"><a href="#1-关联规则简介" class="headerlink" title="1 关联规则简介"></a>1 关联规则简介</h1><p>举例说明：假如10000个消费者购买了商品，购买尿布1000个，购买啤酒2000个，购买面包500个，同时购买了尿布和啤酒800个，同时购买了尿布和面包100个。 </p><ol><li><p>支持度：在所有项集中出现的可能性，即项集同时含有x与y的概率。是第一道门槛，衡量量是多少，可以理解为“出镜率”，一般通过设定最小支持度，过滤掉“出镜率”较低的无意义规则。<br>如设定最小阈值为5%，尿布和啤酒的支持度为：800/10000=8% ，保留；尿布和面包的支持度为100/10000=1%，剔除。</p></li><li><p>置信度：在X发生的条件下，Y发生的概率。这是第二道门槛，衡量的是“质”，设置最小的置信度筛选可靠的规则。<br>如设定最小阈值为70%，尿布-&gt;啤酒的置信度为:800/1000=80%，保留；啤酒-&gt;尿布的置信度为：800/2000=40%，剔除。</p></li></ol><h1 id="2-运行步骤"><a href="#2-运行步骤" class="headerlink" title="2 运行步骤"></a>2 运行步骤</h1><h2 id="2-1-数据说明"><a href="#2-1-数据说明" class="headerlink" title="2.1 数据说明"></a>2.1 数据说明</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[xuqm@cu01 mllib]$ cat sample_fpgrowth.txt </span><br><span class="line">r z h k p</span><br><span class="line">z y x w v u t s</span><br><span class="line">s x o n r</span><br><span class="line">x z y m t s q e</span><br><span class="line">z</span><br><span class="line">x z y r q t p</span><br></pre></td></tr></table></figure><h2 id="2-2-代码及说明"><a href="#2-2-代码及说明" class="headerlink" title="2.2 代码及说明"></a>2.2 代码及说明</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> nwpuhpc.antirisk.ml</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123;<span class="type">Level</span>, <span class="type">Logger</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.&#123;<span class="type">SparkConf</span>, <span class="type">SparkContext</span>&#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.fpm.<span class="type">FPGrowth</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">FPGrowthTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]) &#123;</span><br><span class="line">    <span class="comment">// 0 构建Spark对象</span></span><br><span class="line">    <span class="keyword">val</span> conf = <span class="keyword">new</span> <span class="type">SparkConf</span>().setAppName(<span class="string">"fpg"</span>)</span><br><span class="line">    <span class="keyword">val</span> sc = <span class="keyword">new</span> <span class="type">SparkContext</span>(conf)</span><br><span class="line">    <span class="type">Logger</span>.getRootLogger.setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 1 读取样本数据</span></span><br><span class="line">    <span class="keyword">val</span> data_path = <span class="string">"/home/hadoop/ML_Data/input/sample_fpgrowth.txt"</span></span><br><span class="line">    <span class="keyword">val</span> data = sc.textFile(data_path)</span><br><span class="line">    <span class="keyword">val</span> examples = data.map(_.split(<span class="string">" "</span>)).cache()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 2 建立模型</span></span><br><span class="line">    <span class="comment">//设置最小支持度</span></span><br><span class="line">    <span class="keyword">val</span> minSupport = <span class="number">0.2</span></span><br><span class="line">    <span class="comment">//设置并行分区数</span></span><br><span class="line">    <span class="keyword">val</span> numPartition = <span class="number">10</span></span><br><span class="line">    <span class="keyword">val</span> model = <span class="keyword">new</span> <span class="type">FPGrowth</span>().</span><br><span class="line">      setMinSupport(minSupport).</span><br><span class="line">      setNumPartitions(numPartition).</span><br><span class="line">      run(examples)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 3 查看所有的频繁项集，并且列出它出现的次数</span></span><br><span class="line">    println(<span class="string">s"Number of frequent itemsets: <span class="subst">$&#123;model.freqItemsets.count()&#125;</span>"</span>)</span><br><span class="line">    model.freqItemsets.collect().foreach &#123; itemset =&gt;</span><br><span class="line">      println(itemset.items.mkString(<span class="string">"["</span>, <span class="string">","</span>, <span class="string">"]"</span>) + <span class="string">", "</span> + itemset.freq)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 4 通过置信度筛选出推荐规则</span></span><br><span class="line">    <span class="comment">//antecedent表示前项</span></span><br><span class="line">    <span class="comment">//consequent表示后项</span></span><br><span class="line">    <span class="comment">//confidence表示规则的置信度</span></span><br><span class="line">    <span class="keyword">val</span> minConfidence = <span class="number">0.8</span></span><br><span class="line">    model.generateAssociationRules(minConfidence).collect().foreach(rule=&gt;&#123;</span><br><span class="line">      println(rule.antecedent.mkString(<span class="string">","</span>)+<span class="string">"--&gt;"</span>+</span><br><span class="line">        rule.consequent.mkString(<span class="string">","</span>)+<span class="string">"--&gt;"</span>+ rule.confidence)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//查看规则生成的数量</span></span><br><span class="line">    println(model.generateAssociationRules(minConfidence).collect().length)  </span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-结果展示"><a href="#3-结果展示" class="headerlink" title="3 结果展示"></a>3 结果展示</h1><p>频繁项集及次数：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvf70fvhgj206w0no3yn.jpg" alt=""></p><p>推荐规则：</p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftvf822eq7j20530fkq2y.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> FPGrowth </tag>
            
            <tag> 关联规则 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark MLlib中KMeans聚类算法的使用</title>
      <link href="/Spark-MLlib%E4%B8%ADKMeans%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/Spark-MLlib%E4%B8%ADKMeans%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>KMeans是一种典型的聚类算法，本文通过代码来演示用spark运行KMeans算法的一个小例子。<br><a id="more"></a></p><h1 id="1-算法简介"><a href="#1-算法简介" class="headerlink" title="1 算法简介"></a>1 算法简介</h1><p>KMeans算法的基本思想是初始随机给定K个簇中心，按照最邻近原则把无标签样本点分到各个簇。然后按平均法重新计算各个簇的质心，从而确定新的簇心。一直迭代，直到簇心的移动距离小于某个给定的值或迭代次数达到阈值。</p><h1 id="2-运行步骤"><a href="#2-运行步骤" class="headerlink" title="2 运行步骤"></a>2 运行步骤</h1><h2 id="2-1-数据说明"><a href="#2-1-数据说明" class="headerlink" title="2.1 数据说明"></a>2.1 数据说明</h2><p>数据格式为：特征1 特征2 特征3<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">0.0 0.0 0.0</span><br><span class="line">0.1 0.1 0.1</span><br><span class="line">0.2 0.2 0.2</span><br><span class="line">9.0 9.0 9.0</span><br><span class="line">9.1 9.1 9.1</span><br><span class="line">9.2 9.2 9.2</span><br></pre></td></tr></table></figure></p><h2 id="2-2-代码及说明"><a href="#2-2-代码及说明" class="headerlink" title="2.2 代码及说明"></a>2.2 代码及说明</h2><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.log4j.&#123; <span class="type">Level</span>, <span class="type">Logger</span> &#125;</span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.clustering.<span class="type">KMeans</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">KMeansTest</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="comment">// 生成SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="keyword">new</span> <span class="type">SparkSession</span>.<span class="type">Builder</span>().appName(<span class="string">"KMeansTest"</span>).getOrCreate()</span><br><span class="line">    <span class="comment">//生成SparkContext对象</span></span><br><span class="line">    <span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line">    <span class="comment">//设置日志输出级别</span></span><br><span class="line">    <span class="type">Logger</span>.getRootLogger.setLevel(<span class="type">Level</span>.<span class="type">WARN</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">// 装载数据集</span></span><br><span class="line">    <span class="keyword">val</span> data = sc.textFile(<span class="string">"/home/hadoop/ML_Data/input/kmeans_data.txt"</span>)</span><br><span class="line">    <span class="keyword">val</span> parsedData = data.map(s =&gt; <span class="type">Vectors</span>.dense(s.split(<span class="string">"\\s+"</span>).map(_.toDouble))).cache()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将数据集聚类，4个类，50次迭代，进行模型训练形成数据模型</span></span><br><span class="line">    <span class="keyword">val</span> numClusters = <span class="number">4</span></span><br><span class="line">    <span class="keyword">val</span> numIterations = <span class="number">50</span></span><br><span class="line">    <span class="keyword">val</span> runs = <span class="number">20</span>        <span class="comment">// 执行20次取最优</span></span><br><span class="line">    <span class="keyword">val</span> model = <span class="type">KMeans</span>.train(parsedData, numClusters, numIterations, runs)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//打印输出中心点坐标</span></span><br><span class="line">    <span class="keyword">val</span> centers = model.clusterCenters</span><br><span class="line">    println(<span class="string">"centers"</span>)</span><br><span class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">0</span> to centers.length - <span class="number">1</span>) &#123;</span><br><span class="line">      println(centers(i)(<span class="number">0</span>) + <span class="string">"\t"</span> + centers(i)(<span class="number">1</span>))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 误差计算</span></span><br><span class="line">    <span class="keyword">val</span> <span class="type">WSSSE</span> = model.computeCost(parsedData)</span><br><span class="line">    println(<span class="string">"Within Set Sum of Squared Errors = "</span> + <span class="type">WSSSE</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//给每个数据点进行标号，zippedData格式为(数据的类别号，数据)</span></span><br><span class="line">    <span class="keyword">val</span> c = parsedData.map(x =&gt; model.predict(x))</span><br><span class="line">    c.persist()</span><br><span class="line">    <span class="keyword">val</span> zippedData = c.zip(parsedData)</span><br><span class="line"></span><br><span class="line">    <span class="comment">//保存zippedData到本地</span></span><br><span class="line">    zippedData.saveAsTextFile(<span class="string">"/home/hadoop/ML_Data/output/KMeans_data"</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="3-结果展示"><a href="#3-结果展示" class="headerlink" title="3 结果展示"></a>3 结果展示</h1><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftamz4cckjj20ed048zka.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftamzc5mk6j20oa0bbaaj.jpg" alt=""><br>将结果合成到一个文件中，方便查看：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ftamzjntlej20jr04m0su.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> KMeans </tag>
            
            <tag> 聚类 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Spark的学生成绩分析系统</title>
      <link href="/%E5%9F%BA%E4%BA%8ESpark%E7%9A%84%E5%AD%A6%E7%94%9F%E6%88%90%E7%BB%A9%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/"/>
      <url>/%E5%9F%BA%E4%BA%8ESpark%E7%9A%84%E5%AD%A6%E7%94%9F%E6%88%90%E7%BB%A9%E5%88%86%E6%9E%90%E7%B3%BB%E7%BB%9F/</url>
      
        <content type="html"><![CDATA[<p>本文是本人硕士期间云计算课程的一次大作业，所以可能部分内容有充字数的嫌疑，还望各位看官无视。。。但是也正因为此，本文对一些基础概念描述的也挺详细，包括但不限于Spark简介、Spark与Hadoop对比、Spark架构介绍、Pearson相关系数简介、Spark中的<code>combineByKey</code>函数详解、Spark集群中提交并运行作业的方法等。<br><a id="more"></a></p><h1 id="1-问题说明"><a href="#1-问题说明" class="headerlink" title="1 问题说明"></a>1 问题说明</h1><h2 id="1-1-提出问题及目标"><a href="#1-1-提出问题及目标" class="headerlink" title="1.1 提出问题及目标"></a>1.1 提出问题及目标</h2><p>学生成绩是评价学生学习效果和老师教学效果的重要指标，如何充分利用已有的学生成绩数据，发现其中的规律，提高教学质量是广大教育工作者普遍关注的问题。</p><p>一般而言，学生各科成绩之间或多或少都存在联系，例如一个学习好的学生各科成绩普遍都比较高。研究者们对此进行了大量的数据采集、统计工作，从他们的研究结果来看，学生各科成绩之间的确存在一定的相关性，只是不同课程之间相关性的强弱不同而已。</p><p>通过对学生成绩进行统计分析，可以发现学生成绩中隐藏的课程关联规则和模式，这些知识可以帮助老师更加合理地安排教学内容，从而对教学起到促进作用。</p><p>现有西工大某学院2006级至2015级学生的全部成绩，我们想利用这些数据统计出：①各学科的整体情况;②各课程之间的相关性</p><h2 id="1-2-目标细化及难点"><a href="#1-2-目标细化及难点" class="headerlink" title="1.2 目标细化及难点"></a>1.2 目标细化及难点</h2><p>经过讨论，我们决定用每个年级的各科平均成绩来反映该学科的整体情况，并分年级计算各个课程之间的Pearson相关系数以反映各课程间的相关性。并最后将分析的结果保存在HDFS上。</p><p>要做到这些工作，我们需要解决以下难点：<br>① 2006至2015学生人数众多，且课程种类多，为分析带来了极大困难<br>② 用单机运行处理大量数据需要大量的时间<br>所以我们便考虑使用分布式计算引擎Spark来克服这些难点。</p><h1 id="2-背景"><a href="#2-背景" class="headerlink" title="2 背景"></a>2 背景</h1><h2 id="2-1-Spark简介"><a href="#2-1-Spark简介" class="headerlink" title="2.1 Spark简介"></a>2.1 Spark简介</h2><p>Spark是专为大规模数据处理而设计的快速通用的计算引擎，最初在2009年由加州大学伯克利分校的AMP实验室用Scala语言开发，并于2010年成为Apache的开源项目。</p><p>Spark是基于MapReduce算法实现的分布式计算，拥有Hadoop MapReduce所具有的优点；但不同于MapReduce的是中间过程的输出和结果可以保存在内存中，从而不再需要读写HDFS，大大提高了速度。</p><p>Spark和Hadoop的关系图如下：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvktlt8f5j20dz07xq66.jpg" alt=""><br>官方资料介绍，和Hadoop相比，Spark可以让你的程序在内存中运行时速度提升100倍，就算在硬盘上，运行速度也能提升10倍。</p><h2 id="2-2-Spark架构"><a href="#2-2-Spark架构" class="headerlink" title="2.2 Spark架构"></a>2.2 Spark架构</h2><p>Spark的架构示意图如下：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvkv55747j20b008h78g.jpg" alt=""><br>如图可见，Spark主要有以下模块：<br>① Spark Core：包含Spark的基本功能；尤其是定义RDD的API、操作以及这两者上的动作。其他Spark的库都是构建在RDD和Spark Core之上的。<br>② Spark SQL：提供通过Apache Hive的SQL变体Hive查询语言（HiveQL）与Spark进行交互的API。每个数据库表被当做一个RDD，Spark SQL查询被转换为Spark操作。<br>③ Spark Streaming：对实时数据流进行处理和控制。Spark Streaming允许程序能够像普通RDD一样处理实时数据<br>④ MLlib：一个常用机器学习算法库，算法被实现为对RDD的Spark操作。这个库包含可扩展的学习算法，比如分类、回归等需要对大量数据集进行迭代的操作。<br>⑤ GraphX：控制图、并行图操作和计算的一组算法和工具的集合。GraphX扩展了RDD API，包含控制图、创建子图、访问路径上所有顶点的操作。</p><h2 id="2-3-Spark-RDD简介"><a href="#2-3-Spark-RDD简介" class="headerlink" title="2.3 Spark RDD简介"></a>2.3 Spark RDD简介</h2><p>RDD(<code>Resilient Distributed Dataset</code>)即弹性分布式数据集。</p><p>RDD是Spark的核心，在Spark中，对数据的所有操作不外乎创建RDD、转化已有RDD以及调用RDD操作进行求值。每个RDD都被分为多个分区，这些分区运行在集群中的不同节点上。RDD可以包含Python、Java、Scala中任意类型的对象，甚至可以包含用户自定义的对象。</p><p>RDD是Spark中的抽象数据结构类型，任何数据在Spark中都被表示为RDD。从编程的角度来看，RDD可以简单看成是一个数组。和普通数组的区别是，RDD中的数据是分区存储的，这样不同分区的数据就可以分布在不同的机器上，同时可以被并行处理。因此，Spark应用程序所做的无非是把需要处理的数据转换为RDD，然后对RDD进行一系列的变换和操作从而得到结果。</p><blockquote><p>更多内容可参考本站的这篇文章<a href="https://qiming.info/Spark-RDD%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/">Spark RDD的简单使用</a></p></blockquote><h2 id="2-4-Pearson相关系数简介"><a href="#2-4-Pearson相关系数简介" class="headerlink" title="2.4 Pearson相关系数简介"></a>2.4 Pearson相关系数简介</h2><p>Pearson相关系数 （<code>Pearson Correlation Coefficient</code>）是用来衡量两个数据集合是否在一条线上面，它用来衡量定距变量间的线性关系。Pearson是一个介于-1和1之间的值，用来描述两组线性的数据一同变化移动的趋势。</p><p>Pearson系数的计算公式如下：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvl9dr8eqj20je02ut8p.jpg" alt=""></p><blockquote><p>注：<code>Cov(X,Y)</code>表示X和Y的协方差，<code>E(X )</code> 表示X的平均值。</p></blockquote><p>Pearson 相关系数大小的含义如下表所示：</p><table><thead><tr><th style="text-align:center">相关性</th><th style="text-align:center">负相关</th><th style="text-align:center">正相关</th></tr></thead><tbody><tr><td style="text-align:center">无</td><td style="text-align:center">-0.09 至 0.0</td><td style="text-align:center">0.0 至 0.09</td></tr><tr><td style="text-align:center">弱</td><td style="text-align:center">-0.3 至 -0.1</td><td style="text-align:center">0.1 至 0.3</td></tr><tr><td style="text-align:center">中</td><td style="text-align:center">-0.5 至 -0.3</td><td style="text-align:center">0.3 至 0.5</td></tr><tr><td style="text-align:center">强</td><td style="text-align:center">-1.0 至 -0.5</td><td style="text-align:center">0.5 至 1.0</td></tr></tbody></table><h1 id="3-实现步骤"><a href="#3-实现步骤" class="headerlink" title="3 实现步骤"></a>3 实现步骤</h1><p>源数据是在MySQL数据库中存储的，所以在进行统计分析工作前要先将数据从MySQL数据库中读取出来。</p><h2 id="3-1-平均成绩分析"><a href="#3-1-平均成绩分析" class="headerlink" title="3.1 平均成绩分析"></a>3.1 平均成绩分析</h2><h3 id="3-1-1-取数据"><a href="#3-1-1-取数据" class="headerlink" title="3.1.1 取数据"></a>3.1.1 取数据</h3><p>根据课程id取出每个年级的各个学生此门课程的成绩，SQL语句如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">def sqlStr(courseId: Int): String = &#123;</span><br><span class="line">  s"""<span class="keyword">SELECT</span> c.gradeId,sc.score <span class="keyword">FROM</span> tb_student st</span><br><span class="line">      <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tb_score sc <span class="keyword">ON</span> st.studentId = sc.studentId</span><br><span class="line">      <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tb_class c  <span class="keyword">ON</span> st.classId = c.classId</span><br><span class="line">      <span class="keyword">WHERE</span> sc.courseId = $courseId</span><br><span class="line">      <span class="keyword">ORDER</span> <span class="keyword">BY</span> sc.studentId<span class="string">"""</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></p><h3 id="3-1-2-转化数据"><a href="#3-1-2-转化数据" class="headerlink" title="3.1.2 转化数据"></a>3.1.2 转化数据</h3><p>从MySQL中取得的数据在Spark中是DataFrame类型的，为了方便计算，我们需要将其转化为一个键值对RDD，键为“科目+年级”，值为每个学生成绩，如（ C语言2006级，89.0），代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> scoreRdd = scoreDataFrame.map(x =&gt; (courseStr(courseId) + gradeStr(x.getLong(<span class="number">0</span>).toInt), x.getDecimal(<span class="number">1</span>).doubleValue)).rdd</span><br></pre></td></tr></table></figure></p><h3 id="3-1-3-计算平均成绩"><a href="#3-1-3-计算平均成绩" class="headerlink" title="3.1.3 计算平均成绩"></a>3.1.3 计算平均成绩</h3><p>调用RDD的<code>combineByKey()</code>方法来计算平均数，此方法先将相同键的值加起来，之后除以这个键的个数，得到这个键对应的平均成绩，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> averageScoreRdd = scoreRdd.combineByKey(</span><br><span class="line">  createCombiner = (v: <span class="type">Double</span>) =&gt; (v: <span class="type">Double</span>, <span class="number">1</span>),</span><br><span class="line">  mergeValue = (c: (<span class="type">Double</span>, <span class="type">Int</span>), v: <span class="type">Double</span>) =&gt; (c._1 + v, c._2 + <span class="number">1</span>),</span><br><span class="line">  mergeCombiners = (c1: (<span class="type">Double</span>, <span class="type">Int</span>), c2: (<span class="type">Double</span>, <span class="type">Int</span>)) =&gt; (c1._1 + c2._1, c1._2 + c2._2),</span><br><span class="line">  numPartitions = <span class="number">3</span></span><br><span class="line">).map &#123; <span class="keyword">case</span> (k, v) =&gt; (k, v._1 / v._2) &#125;</span><br></pre></td></tr></table></figure></p><p>代码说明：</p><ul><li><code>createCombiner</code>即当遇到一个新键时，创建一个此键对应的累加器，如第一次遇到（C语言2006级，89.0）时，创建（C语言2006级，（89.0，1））；</li><li><code>mergeValue</code>即当遇到之前已遇到过的键时，将该键的累加器与当前值合并，如再遇到（C语言2006级，90.5）时，合并为（C语言2006级，（179.5，2））；</li><li><code>mergeCombiners</code>即将各个分区的结果进行合并，得到每门课程对应不同年级的总成绩和总人数，如（C语言2006级，（19173.7,241））；</li><li><code>numPartitions</code>即表示Spark分了3个分区来并行处理数据；</li></ul><p>代码最后一行的map即为将每个键的累加器的总成绩除以总人数，得到一个值为平均成绩的RDD，如（C语言2006级，79.559）。</p><h3 id="3-1-4-保存结果"><a href="#3-1-4-保存结果" class="headerlink" title="3.1.4 保存结果"></a>3.1.4 保存结果</h3><p>调用saveAsTextFile()方法将计算出的平均成绩存储在HDFS中，每个科目的平均成绩保存在用该科目名命名的文件夹中，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">averageScoreRdd.sortByKey().saveAsTextFile(<span class="string">"hdfs://localhost:9000/user/hadoop/output/score-avg/"</span> + courseStr(courseId))</span><br></pre></td></tr></table></figure></p><h2 id="3-2-相关性分析"><a href="#3-2-相关性分析" class="headerlink" title="3.2 相关性分析"></a>3.2 相关性分析</h2><h3 id="3-2-1-取数据"><a href="#3-2-1-取数据" class="headerlink" title="3.2.1 取数据"></a>3.2.1 取数据</h3><p>根据年级id取出当前年级每个学生所有科目的成绩，SQL语句如下：<br><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">def allScoreSqlStr(gradeId: Int): String = &#123;</span><br><span class="line">  s"""<span class="keyword">SELECT</span></span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'1'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'高等数学'</span>,</span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'2'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'外语'</span>,</span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'3'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'离散数学'</span>,</span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'4'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'C语言'</span> ,</span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'5'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'数据结构'</span>,</span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'6'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'组成原理'</span>,</span><br><span class="line">        <span class="keyword">MAX</span>(<span class="keyword">case</span> cou.courseId <span class="keyword">when</span> <span class="string">'7'</span> <span class="keyword">THEN</span> <span class="keyword">IFNULL</span>(sc.score, <span class="number">0</span>) <span class="keyword">END</span>) <span class="string">'操作系统'</span></span><br><span class="line">      <span class="keyword">FROM</span>  tb_student st</span><br><span class="line">      <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tb_score sc <span class="keyword">on</span> st.studentId = sc.studentId</span><br><span class="line">      <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tb_course cou <span class="keyword">on</span> cou.courseId = sc.courseId</span><br><span class="line">      <span class="keyword">LEFT</span> <span class="keyword">JOIN</span> tb_class cla <span class="keyword">ON</span>  st.classId = cla.classId</span><br><span class="line">      <span class="keyword">WHERE</span> cla.gradeId = $gradeId</span><br><span class="line">      <span class="keyword">GROUP</span> <span class="keyword">BY</span> st.studentId</span><br><span class="line">      <span class="keyword">ORDER</span> <span class="keyword">BY</span> st.studentId<span class="string">"""</span></span><br><span class="line"><span class="string">&#125;</span></span><br></pre></td></tr></table></figure></p><h3 id="3-2-2-转化数据"><a href="#3-2-2-转化数据" class="headerlink" title="3.2.2 转化数据"></a>3.2.2 转化数据</h3><p>先将此DataFrame类型的数据转化成数值类型的RDD：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data = scoreDataFrame.map(x =&gt; x.toString).rdd.</span><br><span class="line">  map(x =&gt; x.substring(<span class="number">1</span>, x.length - <span class="number">1</span>).split(<span class="string">","</span>)).</span><br><span class="line">  map(x =&gt; x.map(x =&gt; x.toDouble))</span><br></pre></td></tr></table></figure></p><p>计算Pearson相关系数可以调用Spark MLlib库中的方法，但是该方法要求RDD为向量类型的RDD，所以继续转化：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> data1 = data.map(x =&gt; <span class="type">Vectors</span>.dense(x))</span><br></pre></td></tr></table></figure></p><h3 id="3-2-3-计算Pearson相关系数"><a href="#3-2-3-计算Pearson相关系数" class="headerlink" title="3.2.3 计算Pearson相关系数"></a>3.2.3 计算Pearson相关系数</h3><p>直接调用Spark MLlib库中的Statistics.corr方法进行计算：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> corr = <span class="type">Statistics</span>.corr(data1, <span class="string">"pearson"</span>)</span><br></pre></td></tr></table></figure></p><h3 id="3-2-4-保存结果"><a href="#3-2-4-保存结果" class="headerlink" title="3.2.4 保存结果"></a>3.2.4 保存结果</h3><p>经过上述计算，得到的corr是一个矩阵，我们想将结果保存成CSV以便于查看，所以应先将corr转化成一个数值类型的RDD，再将RDD转化成DataFrame以便于保存为CSV文件，最后将结果保存到HDFS上，每个年级的各科相关系数保存在以该年级命名的文件夹中，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> tmpRdd = sc.parallelize(corr.rowIter.toArray.map(x =&gt; x.toArray)).map(x =&gt; (x(<span class="number">0</span>), x(<span class="number">1</span>), x(<span class="number">2</span>), x(<span class="number">3</span>), x(<span class="number">4</span>), x(<span class="number">5</span>), x(<span class="number">6</span>)))</span><br><span class="line"><span class="keyword">val</span> tmpDF = tmpRdd.toDF(<span class="string">"高等数学"</span>, <span class="string">"外语"</span>, <span class="string">"离散数学"</span>, <span class="string">"C语言"</span>, <span class="string">"数据结构"</span>, <span class="string">"组成原理"</span>, <span class="string">"操作系统"</span>)</span><br><span class="line">tmpDF.write.format(<span class="string">"csv"</span>).save(<span class="string">"hdfs://localhost:9000/user/hadoop/output/score-pearson/"</span> + gradeStr(gradeId))</span><br></pre></td></tr></table></figure></p><h2 id="3-3-提交运行"><a href="#3-3-提交运行" class="headerlink" title="3.3 提交运行"></a>3.3 提交运行</h2><p>代码编写完成后，我们需要将代码打包成jar文件（打包过程略），然后提交到spark集群上运行，有以下三步：</p><h3 id="3-3-1-启动master"><a href="#3-3-1-启动master" class="headerlink" title="3.3.1 启动master"></a>3.3.1 启动master</h3><p>进入spark的安装目录，输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/start-master.sh</span><br></pre></td></tr></table></figure></p><h3 id="3-3-2-启动worker"><a href="#3-3-2-启动worker" class="headerlink" title="3.3.2 启动worker"></a>3.3.2 启动worker</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-class org.apache.spark.deploy.worker.Worker spark://localhost:7077</span><br></pre></td></tr></table></figure><p>这里的地址为：启动master后,在浏览器输入localhost:8080,查看到的master地址：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ft04mmtd83j20p009nmy2.jpg" alt=""><br>启动成功后，用jps查看进程：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ft04pglmwhj208l028t8j.jpg" alt=""><br>因本实验中还用到了HDFS，所以也必须启动它（使用<code>start-dfs.sh</code>）,启动后再用jps查看一下进程：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ft053dituzj208i0483yg.jpg" alt=""></p><h3 id="3-3-3-提交作业"><a href="#3-3-3-提交作业" class="headerlink" title="3.3.3 提交作业"></a>3.3.3 提交作业</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./bin/spark-submit --master spark://localhost:7077 --class ScoreAnalysis /home/hadoop/scoreanalysis.jar</span><br></pre></td></tr></table></figure><blockquote><p>注：这里将打包好的jar包放在了<code>/home/hadoop/</code>目录下</p></blockquote><p>可以在4040端口查看作业进度：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ft056vdy9zj21hc0sm446.jpg" alt=""></p><h1 id="4-结果展示"><a href="#4-结果展示" class="headerlink" title="4 结果展示"></a>4 结果展示</h1><p>上文说过，我们将结果保存在了HDFS中，所以当程序运行完成后，要查看结果，必须用<code>Hadoop HDFS</code>提供的命令或者进入namenode管理页面进行查看。</p><p>在控制台上输入以下命令：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs –ls /user/hadoop/output/</span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvn3nmem5j211a02pmx9.jpg" alt=""><br>为了便于查看，我们也可以进入namenode管理页面。<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvn4c8e0cj217b0j7760.jpg" alt=""></p><h2 id="4-1-查看平均成绩"><a href="#4-1-查看平均成绩" class="headerlink" title="4.1 查看平均成绩"></a>4.1 查看平均成绩</h2><p>进入<code>score-avg</code>文件夹，可以看到每个科目创建了一个文件夹。<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvn66fm5tj217b0j740s.jpg" alt=""><br>进入外语文件夹，可以看到有四个文件，_SUCCESS表示文件存储成功，其他三个文件即Spark保存时有三个分区，分别进行了保存。<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvn6v8g5xj217e0lpjth.jpg" alt=""><br>为了方便查看，我们使用cat命令，将所有文件内容整合到一个本地文件中，如下图所示：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvn7g7kz0j20qy0lignm.jpg" alt=""></p><h2 id="4-2-查看Pearson相关系数"><a href="#4-2-查看Pearson相关系数" class="headerlink" title="4.2 查看Pearson相关系数"></a>4.2 查看Pearson相关系数</h2><p>进入<code>score-pearson</code>文件夹，可以看到，我们将不同课程的相关性按年级分成了不同的文件夹。<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvnacisuwj217b0qetbs.jpg" alt=""><br>以2006级为例说明，进入2006级文件夹，看到5个文件，_SUCCSESS说明保存成功，其余四个文件即Spark保存时有四个分区，分别进行了保存。<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvnavmi8jj217b0qe770.jpg" alt=""><br>同样，我们用cat命令将其合并到一个文件中，即在控制台中输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hadoop fs -cat /user/hadoop/output/score-pearson/2006级/part-* &gt;  //home/hadoop/score-pearson/2006级.csv</span><br></pre></td></tr></table></figure></p><p>之后打开2006级.csv，便能清晰的看到2006级学生成绩各科的pearson相关系数了：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fsvnchuzimj20zj0bt0v0.jpg" alt=""><br>从图中可以看出，组成原理和操作系统的Pearson相关系数最高，达到了0.62，说明组成原理和操作系统的相关性较强。</p><h1 id="5-总结"><a href="#5-总结" class="headerlink" title="5 总结"></a>5 总结</h1><p>在本次实验中，我们小组共同合作，完成了用Spark进行对西工大某学院学生2006级至2015级各课程的成绩统计与分析。</p><p>在这个过程中，我们学习到了Hadoop、Spark环境的搭建，Spark RDD的使用，Scala语言的用法，以及分布式开发的思想，并成功得出了各课程的平均成绩与相关性。</p><p>这次实践我们收获到了很多，但由于能力与时间有限，本实验还有很多可以改进的地方。以后还有很多值得学习与研究的地方，我们会再接再厉，努力做得更好。</p><h1 id="6-附完整代码"><a href="#6-附完整代码" class="headerlink" title="6 附完整代码"></a>6 附完整代码</h1><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.util.<span class="type">Properties</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.linalg.<span class="type">Vectors</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.mllib.stat.<span class="type">Statistics</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.sql.<span class="type">SparkSession</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">  * xu qi ming</span></span><br><span class="line"><span class="comment">  * 2018.06.15</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">ScoreAnalysis</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 根据课程id查找每个学生的成绩和所在年级的SQL语句</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">sqlStr</span></span>(courseId: <span class="type">Int</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="string">s""</span><span class="string">"SELECT c.gradeId,sc.score FROM tb_student st</span></span><br><span class="line"><span class="string">          LEFT JOIN tb_score sc ON st.studentId = sc.studentId</span></span><br><span class="line"><span class="string">          LEFT JOIN tb_class c ON  st.classId = c.classId</span></span><br><span class="line"><span class="string">          WHERE sc.courseId = $courseId</span></span><br><span class="line"><span class="string">          ORDER BY sc.studentId"</span><span class="string">""</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 查找当前年级每个学生所有科目的成绩的SQL语句</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">allScoreSqlStr</span></span>(gradeId: <span class="type">Int</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    <span class="string">s""</span><span class="string">"SELECT</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '1' THEN IFNULL(sc.score, 0) END) '高等数学',</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '2' THEN IFNULL(sc.score, 0) END) '外语',</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '3' THEN IFNULL(sc.score, 0) END) '离散数学',</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '4' THEN IFNULL(sc.score, 0) END) 'C语言' ,</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '5' THEN IFNULL(sc.score, 0) END) '数据结构',</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '6' THEN IFNULL(sc.score, 0) END) '组成原理',</span></span><br><span class="line"><span class="string">          MAX(case cou.courseId when '7' THEN IFNULL(sc.score, 0) END) '操作系统'</span></span><br><span class="line"><span class="string">        FROM  tb_student st</span></span><br><span class="line"><span class="string">        LEFT JOIN tb_score sc on st.studentId = sc.studentId</span></span><br><span class="line"><span class="string">        LEFT JOIN tb_course cou on cou.courseId = sc.courseId</span></span><br><span class="line"><span class="string">        LEFT JOIN tb_class cla ON  st.classId = cla.classId</span></span><br><span class="line"><span class="string">        WHERE cla.gradeId = $gradeId</span></span><br><span class="line"><span class="string">        GROUP BY st.studentId</span></span><br><span class="line"><span class="string">        ORDER BY st.studentId"</span><span class="string">""</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将年级id转换成字符串</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">gradeStr</span></span>(gradeId: <span class="type">Int</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    gradeId <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span> =&gt; <span class="string">"2006级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">2</span> =&gt; <span class="string">"2007级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">3</span> =&gt; <span class="string">"2008级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">4</span> =&gt; <span class="string">"2009级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">5</span> =&gt; <span class="string">"2010级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">6</span> =&gt; <span class="string">"2011级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">7</span> =&gt; <span class="string">"2012级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">8</span> =&gt; <span class="string">"2013级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">9</span> =&gt; <span class="string">"2014级"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">10</span> =&gt; <span class="string">"2015级"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * 将课程id转换成相应课程名字符串</span></span><br><span class="line"><span class="comment">    *</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">courseStr</span></span>(corseId: <span class="type">Int</span>): <span class="type">String</span> = &#123;</span><br><span class="line">    corseId <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="number">1</span> =&gt; <span class="string">"高等数学"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">2</span> =&gt; <span class="string">"外语"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">3</span> =&gt; <span class="string">"离散数学"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">4</span> =&gt; <span class="string">"C语言"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">5</span> =&gt; <span class="string">"数据结构"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">6</span> =&gt; <span class="string">"组成原理"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="number">7</span> =&gt; <span class="string">"操作系统"</span></span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 生成SparkSession对象</span></span><br><span class="line">    <span class="keyword">val</span> spark = <span class="keyword">new</span> <span class="type">SparkSession</span>.<span class="type">Builder</span>().appName(<span class="string">"ScoreAnalysis"</span>).getOrCreate()</span><br><span class="line">    <span class="comment">//生成SparkContext对象</span></span><br><span class="line">    <span class="keyword">val</span> sc = spark.sparkContext</span><br><span class="line"></span><br><span class="line">    <span class="comment">//建立与mysql数据库的连接</span></span><br><span class="line">    <span class="keyword">val</span> connProperties = <span class="keyword">new</span> <span class="type">Properties</span>()</span><br><span class="line">    connProperties.put(<span class="string">"driver"</span>, <span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">    connProperties.put(<span class="string">"user"</span>, <span class="string">"root"</span>)</span><br><span class="line">    connProperties.put(<span class="string">"password"</span>, <span class="string">"Root_1234"</span>)</span><br><span class="line">    connProperties.put(<span class="string">"fetchsize"</span>, <span class="string">"100"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 计算指定课程的每个年级的平均成绩</span></span><br><span class="line"><span class="comment">      *</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">averageScore</span></span>(courseId: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//连接数据库，将取得的成绩保存成DataFrame</span></span><br><span class="line">      <span class="keyword">val</span> scoreDataFrame = spark.read.jdbc(</span><br><span class="line">        <span class="string">"jdbc:mysql://localhost:3306/db_score"</span>,</span><br><span class="line">        <span class="string">s"(<span class="subst">$&#123;sqlStr(courseId)&#125;</span>) as table01"</span>,</span><br><span class="line">        connProperties)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//将DataFrame转化成一个键值对RDD，键是科目+年级，值是每个学生的成绩</span></span><br><span class="line">      <span class="keyword">val</span> scoreRdd = scoreDataFrame.map(x =&gt; (courseStr(courseId) + gradeStr(x.getLong(<span class="number">0</span>).toInt), x.getDecimal(<span class="number">1</span>).doubleValue)).rdd</span><br><span class="line"></span><br><span class="line">      <span class="comment">//计算每个年级的平均成绩</span></span><br><span class="line">      <span class="keyword">val</span> averageScoreRdd = scoreRdd.combineByKey(</span><br><span class="line">        createCombiner = (v: <span class="type">Double</span>) =&gt; (v: <span class="type">Double</span>, <span class="number">1</span>),</span><br><span class="line">        mergeValue = (c: (<span class="type">Double</span>, <span class="type">Int</span>), v: <span class="type">Double</span>) =&gt; (c._1 + v, c._2 + <span class="number">1</span>),</span><br><span class="line">        mergeCombiners = (c1: (<span class="type">Double</span>, <span class="type">Int</span>), c2: (<span class="type">Double</span>, <span class="type">Int</span>)) =&gt; (c1._1 + c2._1, c1._2 + c2._2),</span><br><span class="line">        numPartitions = <span class="number">3</span></span><br><span class="line">      ).map &#123; <span class="keyword">case</span> (k, v) =&gt; (k, v._1 / v._2) &#125;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存到HDFS中</span></span><br><span class="line">      averageScoreRdd.sortByKey().saveAsTextFile(<span class="string">"hdfs://localhost:9000/user/hadoop/output/score-avg/"</span> + courseStr(courseId))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//循环这7门课，求每个课程每个年级的平均成绩</span></span><br><span class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">7</span>) &#123;</span><br><span class="line">      averageScore(i)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">      * 计算指定年级的所有科目的pearson相关系数</span></span><br><span class="line"><span class="comment">      *</span></span><br><span class="line"><span class="comment">      */</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">pearsonCorr</span></span>(gradeId: <span class="type">Int</span>): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">      <span class="comment">//连接数据库，将取得的成绩保存成DataFrame</span></span><br><span class="line">      <span class="keyword">val</span> scoreDataFrame = spark.read.jdbc(</span><br><span class="line">        <span class="string">"jdbc:mysql://localhost:3306/db_score"</span>,</span><br><span class="line">        <span class="string">s"(<span class="subst">$&#123;allScoreSqlStr(gradeId)&#125;</span>) as table01"</span>,</span><br><span class="line">        connProperties)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//将DataFrame转成数值类型的RDD</span></span><br><span class="line">      <span class="keyword">val</span> data = scoreDataFrame.map(x =&gt; x.toString).rdd.</span><br><span class="line">        map(x =&gt; x.substring(<span class="number">1</span>, x.length - <span class="number">1</span>).split(<span class="string">","</span>)).</span><br><span class="line">        map(x =&gt; x.map(x =&gt; x.toDouble))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//将数值RDD转为Vector类型的RDD</span></span><br><span class="line">      <span class="keyword">val</span> data1 = data.map(x =&gt; <span class="type">Vectors</span>.dense(x))</span><br><span class="line"></span><br><span class="line">      <span class="comment">//调用机器学习库的统计学习中的算法计算pearson相关系数</span></span><br><span class="line">      <span class="comment">//将结果返回成一个矩阵</span></span><br><span class="line">      <span class="keyword">val</span> corr = <span class="type">Statistics</span>.corr(data1, <span class="string">"pearson"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="comment">//保存计算的结果到HDFS</span></span><br><span class="line">      <span class="keyword">val</span> tmpRdd = sc.parallelize(corr.rowIter.toArray.map(x =&gt; x.toArray)).map(x =&gt; (x(<span class="number">0</span>), x(<span class="number">1</span>), x(<span class="number">2</span>), x(<span class="number">3</span>), x(<span class="number">4</span>), x(<span class="number">5</span>), x(<span class="number">6</span>)))</span><br><span class="line">      <span class="keyword">val</span> tmpDF = tmpRdd.toDF(<span class="string">"高等数学"</span>, <span class="string">"外语"</span>, <span class="string">"离散数学"</span>, <span class="string">"C语言"</span>, <span class="string">"数据结构"</span>, <span class="string">"组成原理"</span>, <span class="string">"操作系统"</span>)</span><br><span class="line">      tmpDF.write.format(<span class="string">"csv"</span>).save(<span class="string">"hdfs://localhost:9000/user/hadoop/output/score-pearson/"</span> + gradeStr(gradeId))</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//循环这10个年级，求每个年级的各科相关系数情况</span></span><br><span class="line">    <span class="keyword">for</span> (i &lt;- <span class="number">1</span> to <span class="number">10</span>) &#123;</span><br><span class="line">      pearsonCorr(i)</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> HDFS </tag>
            
            <tag> RDD </tag>
            
            <tag> Pearson </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark RDD的简单使用</title>
      <link href="/Spark-RDD%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/"/>
      <url>/Spark-RDD%E7%9A%84%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<p>RDD(Resilient Distributed Dataset)即弹性分布式数据集。</p><p>RDD是Spark的核心，在Spark中，对数据的所有操作不外乎创建RDD、转化已有RDD以及调用RDD操作进行求值。而在这一切的背后，Spark会自动将RDD中的数据分发到集群上，并将操作并行化执行。</p><a id="more"></a><h1 id="1-RDD的创建"><a href="#1-RDD的创建" class="headerlink" title="1 RDD的创建"></a>1 RDD的创建</h1><p>创建RDD有两种方式，一种为读取外部数据集，<a href="https://qiming.info/Spark从外部数据集中读取数据">Spark从外部数据集中读取数据</a>一文中提到的各种方式都属于此种；另一种较为简单，直接调用parallelize()方法对一个集合进行并行化即可，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.parallelize(<span class="type">List</span>(<span class="string">"spark"</span>,<span class="string">"hello spark"</span>))</span><br></pre></td></tr></table></figure></p><p>即用此List创建了一个rdd，打印输出此rdd：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd.collect().foreach(println)</span><br><span class="line">spark</span><br><span class="line">hello spark</span><br></pre></td></tr></table></figure></p><h1 id="2-RDD的转化操作"><a href="#2-RDD的转化操作" class="headerlink" title="2 RDD的转化操作"></a>2 RDD的转化操作</h1><p>RDD的转化操作即为将1个或多个RDD转化成一个新的RDD，常见操作有：</p><ul><li>map():将函数应用于RDD中的每个元素，将返回值构成新的RDD</li><li>flatMap():将函数应用于RDD中的每个元素，将返回的迭代器的所有内容构成新的RDD。通常用来切分单词。</li><li>filter():返回一个由通过传给filter()的函数的元素组成的RDD（即起筛选作用）</li></ul><p>我们选取<a href="https://qiming.info/Spark从外部数据集中读取数据">Spark从外部数据集中读取数据</a>一文中从HDFS中取出的RDD进行举例说明：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszcryqj20g3040glj.jpg" alt="hdfsresult"><br>如图，从HDFS中读取的文本文件是按行存储在rdd中的，即一行为rdd的一个元素。<br>现在我们要将此rdd中的所有数字都存成元素以便后续操作，即1个元素变为多个元素则应使用flatMap()方法：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> newRdd = rdd.flatMap(x=&gt;x.split(<span class="string">" "</span>))</span><br></pre></td></tr></table></figure></p><p>然后输出：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1ft05o2tuo3j20a101ndgb.jpg" alt=""><br>可以看出，newRdd有8个元素。<br>然后用map()将每个元素转成int类型的并加1：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> newIntRdd = newRdd.map(x=&gt;x.toInt).map(x=&gt;x+<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>打印输出：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs50j8v2izj20al01d3yb.jpg" alt=""><br>再举一个关于filter()的例子，假如我们要找出上述的所有奇数，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> oddNumRdd = newIntRdd.filter(x=&gt;x%<span class="number">2</span>==<span class="number">1</span>)</span><br></pre></td></tr></table></figure></p><p>（下文将对此<code>oddNumRdd</code>的操作进行举例说明）</p><h1 id="3-RDD的行动操作"><a href="#3-RDD的行动操作" class="headerlink" title="3 RDD的行动操作"></a>3 RDD的行动操作</h1><p>RDD的行动操作即对RDD进行实际的计算，并将结果打印输出或保存到外部存储系统中，常见操作有：</p><ul><li>collect():返回RDD中的所有元素</li><li>count():返回RDD中的元素个数</li><li>take(n):返回RDD中前n个元素</li><li>reduce(func):并行整合RDD中所有数据（例如sum）</li><li>foreach(func):让RDD中的每个元素使用func</li></ul><p>collect()、count()和take()较为简单，举例如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; oddNumRdd.collect()</span><br><span class="line">res3: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">79</span>, <span class="number">23</span>, <span class="number">33</span>, <span class="number">5</span>, <span class="number">51</span>)</span><br><span class="line"></span><br><span class="line">scala&gt; oddNumRdd.count()</span><br><span class="line">res4: <span class="type">Long</span> = <span class="number">5</span></span><br><span class="line"></span><br><span class="line">scala&gt; oddNumRdd.take(<span class="number">3</span>)</span><br><span class="line">res5: <span class="type">Array</span>[<span class="type">Int</span>] = <span class="type">Array</span>(<span class="number">79</span>, <span class="number">23</span>, <span class="number">33</span>)</span><br></pre></td></tr></table></figure></p><blockquote><p>注：需要说明的是，collect()会将RDD中的所有元素都存放在内存中，所以不适合大规模数据集。</p></blockquote><p>上文已多次用过foreach(println)，即对RDD中的每个元素都进行打印输出操作。<br>reduce()经常用来求和，如：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">oddNumRdd.reduce((x,y)=&gt;x+y)</span><br><span class="line">res6: <span class="type">Int</span> = <span class="number">191</span></span><br></pre></td></tr></table></figure></p><h1 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4 参考资料"></a>4 参考资料</h1><p>[1]Karau,H.&amp;A.Konwinski.Spark快速大数据分析[M].王道远译.北京:人民邮电出版社.2015-09:30-37</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> HDFS </tag>
            
            <tag> RDD </tag>
            
            <tag> mapreduce </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark从外部数据集中读取数据</title>
      <link href="/Spark%E4%BB%8E%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE/"/>
      <url>/Spark%E4%BB%8E%E5%A4%96%E9%83%A8%E6%95%B0%E6%8D%AE%E9%9B%86%E4%B8%AD%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<p>本文将介绍几种从Spark中读取数据存入RDD的方式，分别是</p><ul><li>从HDFS中读数据</li><li>从MySQL数据库中读数据</li><li>从HBase数据库中读数据</li></ul><a id="more"></a><p>本文中涉及到的工具版本如下：</p><ul><li>Hadoop：2.7.4</li><li>Spark：2.1.1</li><li>HBase：1.2.6</li><li>MySQL：5.7.22</li><li>JDK：1.8.0_171</li><li>Scala：2.11.8</li></ul><h1 id="1-从HDFS中读数据"><a href="#1-从HDFS中读数据" class="headerlink" title="1 从HDFS中读数据"></a>1 从HDFS中读数据</h1><h2 id="1-1-准备数据"><a href="#1-1-准备数据" class="headerlink" title="1.1 准备数据"></a>1.1 准备数据</h2><p>首先启动Hadoop（使用<code>start-dfs.sh</code>），在HDFS上创建一个目录：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -mkdir -p /user/hadoop/input</span><br></pre></td></tr></table></figure></p><p>新建一个文件<code>input.txt</code>，内容如下：<br><figure class="highlight tex"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">15 78 89 22</span><br><span class="line">777 32 4 50</span><br></pre></td></tr></table></figure></p><p>将<code>input.txt</code>上传到HDFS上：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop fs -put input.txt /user/hadoop/input</span><br></pre></td></tr></table></figure></p><p>用ls命令查看是否上传成功：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszcqyej20ie01oa9y.jpg" alt="ls"></p><h2 id="1-2-读取数据"><a href="#1-2-读取数据" class="headerlink" title="1.2 读取数据"></a>1.2 读取数据</h2><p>Spark将读取到的数据会保存在RDD中，关于RDD的介绍可以参考本站的这篇文章<a href="https://qiming.info/Spark-RDD的简单使用">Spark-RDD的简单使用</a>。<br>在Spark中从HDFS读取文本文件可以使用<code>sc.textFile</code>方法，将此方法的参数设为<code>hdfs://master:port/path</code>即可。<br>所以本例中的读取步骤如下：<br>进入spark的安装目录，使用<code>bin/spark-shell</code>来启动<code>spark</code>命令行编程（语言为<code>scala</code>）。<br>输入以下代码：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">val</span> rdd = sc.textFile(<span class="string">"hdfs://localhost:9000/user/hadoop/input/input.txt"</span>)</span><br><span class="line">rdd.count()           <span class="comment">// 输出行数</span></span><br><span class="line">rdd.foreach(println)  <span class="comment">// 将所有内容打印出来</span></span><br></pre></td></tr></table></figure></p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszcryqj20g3040glj.jpg" alt="hdfsresult"></p><h1 id="2-从MySQL数据库中读数据"><a href="#2-从MySQL数据库中读数据" class="headerlink" title="2 从MySQL数据库中读数据"></a>2 从MySQL数据库中读数据</h1><h2 id="2-1-数据来源"><a href="#2-1-数据来源" class="headerlink" title="2.1 数据来源"></a>2.1 数据来源</h2><p>将db_score数据库中的tb_course表作为数据来源，表中内容如下图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszdh2kj20dm0deaah.jpg" alt="mysql"></p><h2 id="2-2-读取数据"><a href="#2-2-读取数据" class="headerlink" title="2.2 读取数据"></a>2.2 读取数据</h2><p>Spark可以用JDBC来连接关系型数据库，包括MySQL、Oracle、Postgre等系统。<br>在执行<code>spark-shell</code>或者<code>spark-submit</code>命令的时候，需在<code>--driver-class-path</code>配置对应数据库的JDBC驱动的路径。<br>本例中，使用以下命令启动spark-shell：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/spark-shell --driver-class-path /home/hadoop/mysql-connector-java-5.1.21-bin.jar</span><br></pre></td></tr></table></figure></p><h3 id="2-2-1-方法一：使用org-apache-spark-rdd-JdbcRDD"><a href="#2-2-1-方法一：使用org-apache-spark-rdd-JdbcRDD" class="headerlink" title="2.2.1 方法一：使用org.apache.spark.rdd.JdbcRDD"></a>2.2.1 方法一：使用org.apache.spark.rdd.JdbcRDD</h3><p>代码及说明如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> java.sql.<span class="type">DriverManager</span></span><br><span class="line"><span class="keyword">import</span> java.sql.<span class="type">ResultSet</span></span><br><span class="line"><span class="keyword">import</span> org.apache.spark.rdd.<span class="type">JdbcRDD</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createConnection</span></span>() = &#123;              <span class="comment">//创建连接</span></span><br><span class="line">  <span class="type">Class</span>.forName(<span class="string">"com.mysql.jdbc.Driver"</span>).newInstance()</span><br><span class="line"><span class="type">DriverManager</span>.getConnection(<span class="string">"jdbc:mysql://localhost:3306/db_score"</span>,<span class="string">"root"</span>,<span class="string">"passwd"</span>)</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">extractValues</span></span>(r:<span class="type">ResultSet</span>) = &#123;      <span class="comment">//从数据库中取得数据后转换格式</span></span><br><span class="line">  (r.getInt(<span class="number">1</span>),r.getString(<span class="number">2</span>))</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">val</span> courseRdd = <span class="keyword">new</span> <span class="type">JdbcRDD</span>(            <span class="comment">// 调用JdbcRDD类</span></span><br><span class="line">  sc,                                   <span class="comment">// SparkContext对象</span></span><br><span class="line">  createConnection,                     <span class="comment">// 与数据库的连接</span></span><br><span class="line">  <span class="string">"select * from tb_course where ? &lt;= courseid and courseid &lt;= ?"</span>, <span class="comment">// SQL语句</span></span><br><span class="line">  <span class="number">1</span>,                                    <span class="comment">// 查询的下界</span></span><br><span class="line">  <span class="number">7</span>,                                    <span class="comment">// 查询的上界</span></span><br><span class="line">  <span class="number">2</span>,                                    <span class="comment">// partition的个数(即分为几部分查询)</span></span><br><span class="line">  extractValues                         <span class="comment">// 将数据转换成需要的格式</span></span><br><span class="line">)</span><br><span class="line">courseRdd.collect.foreach(println)           <span class="comment">// 打印输出</span></span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszfc11j208p03rt8l.jpg" alt="courseRDD"></p><blockquote><p>注：从上例中可以看出，使用JdbcRDD时，SQL查询语句必须有类似<code>ID &gt;= ? AND ID &lt;= ?</code>这样的where语句（经测试，直接去掉会报错），而且上界和下界的类型必须是Long，这样使得JdbcRDD的使用场景比较局限。不过参照JdbcRDD的源代码，用户可以修改源代码以写出符合自己需求的JdbcRDD。</p></blockquote><h3 id="2-2-2-方法二：使用Spark-SQL来返回一个DataFrame"><a href="#2-2-2-方法二：使用Spark-SQL来返回一个DataFrame" class="headerlink" title="2.2.2 方法二：使用Spark SQL来返回一个DataFrame"></a>2.2.2 方法二：使用Spark SQL来返回一个DataFrame</h3><p>代码及说明如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">import org.apache.spark.sql.SQLContext</span><br><span class="line"></span><br><span class="line">val sqlContext = new SQLContext(sc)               // 生成SQLContext对象</span><br><span class="line">val sql = <span class="string">"select * from tb_course"</span>               // SQL查询语句</span><br><span class="line"></span><br><span class="line">val courseDF = sqlContext.read.format(<span class="string">"jdbc"</span>).options(</span><br><span class="line">  Map(<span class="string">"url"</span>-&gt;<span class="string">"jdbc:mysql://localhost:3306/db_score"</span>,</span><br><span class="line">    <span class="string">"dbtable"</span>-&gt;s<span class="string">"(<span class="variable">$&#123;sql&#125;</span>) as table01"</span>,            // SQL查询并对结果起别名</span><br><span class="line">    <span class="string">"driver"</span>-&gt;<span class="string">"com.mysql.jdbc.Driver"</span>,            // 驱动</span><br><span class="line">    <span class="string">"user"</span>-&gt; <span class="string">"root"</span>,                              // 用户名</span><br><span class="line">    <span class="string">"password"</span>-&gt;<span class="string">"passwd"</span>)                         // 密码</span><br><span class="line">).load()</span><br><span class="line"></span><br><span class="line">courseDF.collect().foreach(println)               // 打印输出</span><br></pre></td></tr></table></figure></p><p>结果如下图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszgge9j208h03pwed.jpg" alt="courseDF"></p><h1 id="3-从HBase数据库中读数据"><a href="#3-从HBase数据库中读数据" class="headerlink" title="3 从HBase数据库中读数据"></a>3 从HBase数据库中读数据</h1><h2 id="3-1-准备数据"><a href="#3-1-准备数据" class="headerlink" title="3.1 准备数据"></a>3.1 准备数据</h2><p>首先启动HDFS（<code>start-dfs.sh</code>）和HBase（<code>start-hbase.sh</code>）<br>输入<code>hbase shell</code>进入HBase的命令行模式<br>使用create命令创建一张有f1、f2两个列族的表：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hbase(main) &gt; create <span class="string">'test1'</span>,&#123;NAME =&gt; <span class="string">'f1'</span>&#125;,&#123;NAME =&gt; <span class="string">'f2'</span>&#125;</span><br></pre></td></tr></table></figure></p><p>使用put命令给表<code>test1</code>添加一些测试数据：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hbase(main) &gt; put <span class="string">'test1'</span>,<span class="string">'row01'</span>,<span class="string">'f1:data'</span>,<span class="string">'10001'</span> </span><br><span class="line">hbase(main) &gt; put <span class="string">'test1'</span>,<span class="string">'row01'</span>,<span class="string">'f2:data'</span>,<span class="string">'10002'</span></span><br><span class="line">hbase(main) &gt; put <span class="string">'test1'</span>,<span class="string">'row02'</span>,<span class="string">'f2:data'</span>,<span class="string">'10003'</span></span><br></pre></td></tr></table></figure></p><p>查看添加的数据：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszck52j20kh02lq2w.jpg" alt="scantest1"></p><h2 id="3-2-读取数据"><a href="#3-2-读取数据" class="headerlink" title="3.2 读取数据"></a>3.2 读取数据</h2><p>Spark连接HBase时需要一些必要的jar包，可在HBase安装目录下的lib文件夹中找到，将它们复制到一个自定义文件夹中（本例中在Spark安装目录下新建了名为hbase-lib的文件夹），这些jar包清单如下：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszd8wyj20ka03y0su.jpg" alt="sparkhbasejars"><br>即metrics-core-2.2.0.jar、protobuf-java-2.5.0.jar、htrace-core-3.1.0-incubating.jar、guava-12.0.1.jar这四个jar包加上所有hbase-开头的所有jar包。（注：spark的环境中有metrics的jar包，但是可能是版本不匹配的问题，如果不加入此2.2.0版本的，程序会报错）<br>然后在Spark安装目录下的conf文件夹中找到<code>spark-env.sh</code>,在其中添加：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> SPARK_CLASSPATH=/opt/software/spark/hbase-lib/*</span><br></pre></td></tr></table></figure></p><h3 id="3-2-1-方法一：调用newAPIHadoopRDD"><a href="#3-2-1-方法一：调用newAPIHadoopRDD" class="headerlink" title="3.2.1 方法一：调用newAPIHadoopRDD"></a>3.2.1 方法一：调用<code>newAPIHadoopRDD</code></h3><p>代码及相关说明如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.<span class="type">HBaseConfiguration</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.<span class="type">Result</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.io.<span class="type">ImmutableBytesWritable</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.mapreduce.<span class="type">TableInputFormat</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> conf = <span class="type">HBaseConfiguration</span>.create()</span><br><span class="line">conf.set(<span class="type">TableInputFormat</span>.<span class="type">INPUT_TABLE</span>,<span class="string">"test1"</span>)   <span class="comment">//设置需要扫描的表(test1)</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">val</span> rdd = sc.newAPIHadoopRDD(conf,</span><br><span class="line">classOf[<span class="type">TableInputFormat</span>],classOf[<span class="type">ImmutableBytesWritable</span>],classOf[<span class="type">Result</span>])</span><br></pre></td></tr></table></figure></p><p>由于<code>TableInputFormat</code>类的实现，Spark可以用Hadoop输入格式访问HBase，即调用<code>sc.newAPIHadoopRDD</code>，此方法返回一个键值对类型的RDD，其中键的类型为<code>ImmutableBytesWritable</code>，值的类型为<code>Result</code>（分别是此方法的后两个参数）。<br>因此，遍历此键值对RDD中的值即可取得想要的数据，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">rdd.foreach&#123;<span class="keyword">case</span> (_,result) =&gt;&#123;              <span class="comment">//逐行遍历</span></span><br><span class="line">  <span class="keyword">val</span> row = <span class="type">Bytes</span>.toString(result.getRow)    <span class="comment">//获取当前行的Row key</span></span><br><span class="line">  <span class="keyword">val</span> value = <span class="type">Bytes</span>.toString(result.getValue(<span class="string">"f2"</span>.getBytes,<span class="string">"data"</span>.getBytes))</span><br><span class="line">                            <span class="comment">//根据列族名(f2)和列名(data)取当前行的数据</span></span><br><span class="line">  println(<span class="string">"Row:"</span>+row+<span class="string">" f2, data:"</span>+value)     <span class="comment">//打印输出</span></span><br><span class="line">&#125;&#125;</span><br></pre></td></tr></table></figure></p><p>运行结果如下：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fs1aszcqjlj20gw03fgli.jpg" alt=""></p><h3 id="3-2-2-方法二：用org-apache-hadoop-hbase中提供的方法"><a href="#3-2-2-方法二：用org-apache-hadoop-hbase中提供的方法" class="headerlink" title="3.2.2 方法二：用org.apache.hadoop.hbase中提供的方法"></a>3.2.2 方法二：用<code>org.apache.hadoop.hbase</code>中提供的方法</h3><p>以下代码改编自《Hadoop+Spark生态系统操作与实战指南》，利用此代码可以实现对HBase的CRUD操作，代码如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client._</span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.<span class="type">Bytes</span></span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.&#123;<span class="type">HBaseConfiguration</span>, <span class="type">HColumnDescriptor</span>,</span><br><span class="line"><span class="type">HTableDescriptor</span>, <span class="type">TableName</span>&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">createHTable</span></span>(connection: <span class="type">Connection</span>,tablename: <span class="type">String</span>): <span class="type">Unit</span>=</span><br><span class="line">&#123;</span><br><span class="line">  <span class="comment">//Hbase表模式管理器</span></span><br><span class="line">  <span class="keyword">val</span> admin = connection.getAdmin</span><br><span class="line">  <span class="comment">//本例将操作的表名</span></span><br><span class="line">  <span class="keyword">val</span> tableName = <span class="type">TableName</span>.valueOf(tablename)</span><br><span class="line">  <span class="comment">//如果需要创建表</span></span><br><span class="line">  <span class="keyword">if</span> (!admin.tableExists(tableName)) &#123;</span><br><span class="line">    <span class="comment">//创建Hbase表模式</span></span><br><span class="line">    <span class="keyword">val</span> tableDescriptor = <span class="keyword">new</span> <span class="type">HTableDescriptor</span>(tableName)</span><br><span class="line">    <span class="comment">//创建列簇1    artitle</span></span><br><span class="line">    tableDescriptor.addFamily(<span class="keyword">new</span> <span class="type">HColumnDescriptor</span>(<span class="string">"artitle"</span>.getBytes()))</span><br><span class="line">    <span class="comment">//创建列簇2    author</span></span><br><span class="line">    tableDescriptor.addFamily(<span class="keyword">new</span> <span class="type">HColumnDescriptor</span>(<span class="string">"author"</span>.getBytes()))</span><br><span class="line">    <span class="comment">//创建表</span></span><br><span class="line">    admin.createTable(tableDescriptor)</span><br><span class="line">    println(<span class="string">"create done."</span>)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">//删除表</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deleteHTable</span></span>(connection:<span class="type">Connection</span>,tablename:<span class="type">String</span>):<span class="type">Unit</span>=&#123;</span><br><span class="line">  <span class="comment">//本例将操作的表名</span></span><br><span class="line">  <span class="keyword">val</span> tableName = <span class="type">TableName</span>.valueOf(tablename)</span><br><span class="line">  <span class="comment">//Hbase表模式管理器</span></span><br><span class="line">  <span class="keyword">val</span> admin = connection.getAdmin</span><br><span class="line">  <span class="keyword">if</span> (admin.tableExists(tableName))&#123;</span><br><span class="line">    admin.disableTable(tableName)</span><br><span class="line">    admin.deleteTable(tableName)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//插入记录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">insertHTable</span></span>(connection:<span class="type">Connection</span>,tablename:<span class="type">String</span>,family:<span class="type">String</span>,column:<span class="type">String</span>,</span><br><span class="line">key:<span class="type">String</span>,value:<span class="type">String</span>):<span class="type">Unit</span>=&#123;</span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="keyword">val</span> userTable = <span class="type">TableName</span>.valueOf(tablename)</span><br><span class="line">    <span class="keyword">val</span> table=connection.getTable(userTable)</span><br><span class="line">    <span class="comment">//准备key 的数据</span></span><br><span class="line">    <span class="keyword">val</span> p=<span class="keyword">new</span> <span class="type">Put</span>(key.getBytes)</span><br><span class="line">    <span class="comment">//为put操作指定 column 和 value</span></span><br><span class="line">    p.addColumn(family.getBytes,column.getBytes,value.getBytes())</span><br><span class="line">    <span class="comment">//提交一行</span></span><br><span class="line">    table.put(p)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//基于KEY查询某条数据</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">getAResult</span></span>(connection:<span class="type">Connection</span>,tablename:<span class="type">String</span>,family:<span class="type">String</span>,column:<span class="type">String</span>,</span><br><span class="line">key:<span class="type">String</span>):<span class="type">Unit</span>=&#123;</span><br><span class="line">  <span class="keyword">var</span> table:<span class="type">Table</span>=<span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="keyword">val</span> userTable = <span class="type">TableName</span>.valueOf(tablename)</span><br><span class="line">    table=connection.getTable(userTable)</span><br><span class="line">    <span class="keyword">val</span> g=<span class="keyword">new</span> <span class="type">Get</span>(key.getBytes())</span><br><span class="line">    <span class="keyword">val</span> result=table.get(g)</span><br><span class="line">    <span class="keyword">val</span> value=<span class="type">Bytes</span>.toString(result.getValue(family.getBytes(),column.getBytes()))</span><br><span class="line">    println(<span class="string">"value:"</span>+value)</span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(table!=<span class="literal">null</span>)table.close()</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除某条记录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">deleteRecord</span></span>(connection:<span class="type">Connection</span>,tablename:<span class="type">String</span>,family:<span class="type">String</span>,column:<span class="type">String</span>,</span><br><span class="line">key:<span class="type">String</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">  <span class="keyword">var</span> table:<span class="type">Table</span>=<span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="keyword">val</span> userTable=<span class="type">TableName</span>.valueOf(tablename)</span><br><span class="line">    table=connection.getTable(userTable)</span><br><span class="line">    <span class="keyword">val</span> d=<span class="keyword">new</span> <span class="type">Delete</span>(key.getBytes())</span><br><span class="line">    d.addColumn(family.getBytes(),column.getBytes())</span><br><span class="line">    table.delete(d)</span><br><span class="line">    println(<span class="string">"delete record done."</span>)</span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(table!=<span class="literal">null</span>)table.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//扫描记录</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">scanRecord</span></span>(connection:<span class="type">Connection</span>,tablename:<span class="type">String</span>,family:<span class="type">String</span>,column:<span class="type">String</span>): <span class="type">Unit</span> =&#123;</span><br><span class="line">  <span class="keyword">var</span> table:<span class="type">Table</span>=<span class="literal">null</span></span><br><span class="line">  <span class="keyword">var</span> scanner:<span class="type">ResultScanner</span>=<span class="literal">null</span></span><br><span class="line">  <span class="keyword">try</span>&#123;</span><br><span class="line">    <span class="keyword">val</span> userTable=<span class="type">TableName</span>.valueOf(tablename)</span><br><span class="line">    table=connection.getTable(userTable)</span><br><span class="line">    <span class="keyword">val</span> s=<span class="keyword">new</span> <span class="type">Scan</span>()</span><br><span class="line">    s.addColumn(family.getBytes(),column.getBytes())</span><br><span class="line">    scanner=table.getScanner(s)</span><br><span class="line">    println(<span class="string">"scan...for..."</span>)</span><br><span class="line">    <span class="keyword">var</span> result:<span class="type">Result</span>=scanner.next()</span><br><span class="line">    <span class="keyword">while</span>(result!=<span class="literal">null</span>)&#123;</span><br><span class="line">      println(<span class="string">"Found row:"</span> + result)</span><br><span class="line">      println(<span class="string">"Found value: "</span>+</span><br><span class="line"><span class="type">Bytes</span>.toString(result.getValue(family.getBytes(),column.getBytes())))</span><br><span class="line">      result=scanner.next()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;<span class="keyword">finally</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(table!=<span class="literal">null</span>)</span><br><span class="line">      table.close()</span><br><span class="line">    scanner.close()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p><p>（注：以上代码中的Key均代表<code>Row Key</code>）<br>以上代码将在HBase中创建表、删除表、插入记录、根据行号查询数据、删除记录、扫描记录等操作都写成了函数，将以上代码在spark-shell中运行后，对HBase的操作直接调用相关函数即可，如下：<br><figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//创建一个配置，采用的是工厂方法</span></span><br><span class="line"><span class="keyword">val</span> conf = <span class="type">HBaseConfiguration</span>.create</span><br><span class="line"><span class="comment">//Connection 的创建是个重量级的工作，线程安全，是操作hbase的入口</span></span><br><span class="line"><span class="keyword">val</span> connection= <span class="type">ConnectionFactory</span>.createConnection(conf)</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建表测试</span></span><br><span class="line">createHTable(connection, <span class="string">"HadoopAndSpark"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//插入数据,重复执行为覆盖</span></span><br><span class="line">insertHTable(connection,<span class="string">"HadoopAndSpark"</span>,<span class="string">"artitle"</span>,<span class="string">"Hadoop"</span>,<span class="string">"002"</span>,<span class="string">"Hadoop for me"</span>)</span><br><span class="line">insertHTable(connection,<span class="string">"HadoopAndSpark"</span>,<span class="string">"artitle"</span>,<span class="string">"Hadoop"</span>,<span class="string">"003"</span>,<span class="string">"Java for me"</span>)</span><br><span class="line">insertHTable(connection,<span class="string">"HadoopAndSpark"</span>,<span class="string">"artitle"</span>,<span class="string">"Spark"</span>,<span class="string">"002"</span>,<span class="string">"Scala for me"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除记录</span></span><br><span class="line">deleteRecord(connection,<span class="string">"HadoopAndSpark"</span>,<span class="string">"artitle"</span>,<span class="string">"Spark"</span>,<span class="string">"002"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//扫描整个表</span></span><br><span class="line">scanRecord(connection,<span class="string">"HadoopAndSpark"</span>,<span class="string">"artitle"</span>,<span class="string">"Hadoop"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//根据表名、行键、列族、列名取当前Cell的数据</span></span><br><span class="line">getAResult(connection,<span class="string">"HadoopAndSpark"</span>,<span class="string">"artitle"</span>,<span class="string">"Hadoop"</span>,<span class="string">"002"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">//删除表测试</span></span><br><span class="line">deleteHTable(connection, <span class="string">"HadoopAndSpark"</span>)</span><br></pre></td></tr></table></figure></p><h1 id="4-后记"><a href="#4-后记" class="headerlink" title="4 后记"></a>4 后记</h1><p>Spark可以通过所有Hadoop支持的外部数据源（包括本地文件系统、HDFS、Cassandra、关系型数据库、HBase、亚马逊S3等）建立RDD，本文没有讲到的，后续视情况补充。Spark支持文本文件、序列文件及其他任何Hadoop输入格式文件。</p><h1 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5 参考资料"></a>5 参考资料</h1><p>[1]Karau,H.&amp;A.Konwinski.Spark快速大数据分析[M].王道远译.北京:人民邮电出版社.2015-09:64-65,81-85<br>[2]余辉.Hadoop+Spark生态系统操作与实战指南[M].北京:清华大学出版社.2017:136-140</p>]]></content>
      
      
      <categories>
          
          <category> 大数据 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spark </tag>
            
            <tag> Hadoop </tag>
            
            <tag> HDFS </tag>
            
            <tag> HBase </tag>
            
            <tag> RDD </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Xv6学习小记（一）——编译与运行</title>
      <link href="/Xv6%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%A11/"/>
      <url>/Xv6%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%A11/</url>
      
        <content type="html"><![CDATA[<h2 id="1-说明"><a href="#1-说明" class="headerlink" title="1 说明"></a>1 说明</h2><ul><li>Xv6是一个Intel x86平台下的类Unix教学操作系统，最新源码获取地址为<a href="https://github.com/mit-pdos/xv6-public" target="_blank" rel="noopener">https://github.com/mit-pdos/xv6-public</a></li><li>运行xv6可以用qemu和bochs，本文介绍在Ubuntu系统下用qemu运行的方式。</li><li>本文包括qemu的安装步骤、编译并运行Xv6的步骤、Xv6编译生成物的说明以及使用不同CPU数量运行Xv6系统的方法。</li></ul><a id="more"></a><h2 id="2-安装qemu"><a href="#2-安装qemu" class="headerlink" title="2 安装qemu"></a>2 安装qemu</h2><p>直接使用<code>apt-get</code>安装即可,即输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install qemu</span><br></pre></td></tr></table></figure></p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfbvwd0k4j20ic05mt9w.jpg" alt=""><br>然后输入<code>qemu-system-i386</code>，如果弹出qemu即表明安装成功：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfbwtj29fj20og0hsdl4.jpg" alt=""></p><h2 id="3-编译xv6"><a href="#3-编译xv6" class="headerlink" title="3 编译xv6"></a>3 编译xv6</h2><h3 id="3-1-解压下载好的xv6-master-zip文件"><a href="#3-1-解压下载好的xv6-master-zip文件" class="headerlink" title="3.1 解压下载好的xv6-master.zip文件"></a>3.1 解压下载好的xv6-master.zip文件</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfbys5kcmj20wu077tau.jpg" alt=""></p><h3 id="3-2-进入解压好的xv6-master目录下，并输入make命令进行编译"><a href="#3-2-进入解压好的xv6-master目录下，并输入make命令进行编译" class="headerlink" title="3.2 进入解压好的xv6-master目录下，并输入make命令进行编译"></a>3.2 进入解压好的xv6-master目录下，并输入<code>make</code>命令进行编译</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfbyzaacdj20m407d40j.jpg" alt=""></p><h3 id="3-3-编译结束后可能会出现以下错误"><a href="#3-3-编译结束后可能会出现以下错误" class="headerlink" title="3.3 编译结束后可能会出现以下错误"></a>3.3 编译结束后可能会出现以下错误</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfbz7bq8wj20m4067jsw.jpg" alt=""><br>这是因为static_assert重定义了，到xv6的解压文件下找到mkfs.c，注释掉这句代码，保存然后重新make一下即可。如图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfc1ick2nj20mi0apmza.jpg" alt=""></p><h3 id="3-4-编译成功后如下图所示"><a href="#3-4-编译成功后如下图所示" class="headerlink" title="3.4 编译成功后如下图所示"></a>3.4 编译成功后如下图所示</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfc2wgxuij20me07zac5.jpg" alt=""></p><h2 id="4-用qemu运行xv6"><a href="#4-用qemu运行xv6" class="headerlink" title="4 用qemu运行xv6"></a>4 用qemu运行xv6</h2><h3 id="4-1-在xv6-master目录中找到并打开Makefile文件"><a href="#4-1-在xv6-master目录中找到并打开Makefile文件" class="headerlink" title="4.1 在xv6-master目录中找到并打开Makefile文件;"></a>4.1 在xv6-master目录中找到并打开Makefile文件;</h3><h3 id="4-2-在“QEMU-”后面填写qemu-system-i386，并删掉前面的“-”"><a href="#4-2-在“QEMU-”后面填写qemu-system-i386，并删掉前面的“-”" class="headerlink" title="4.2 在“QEMU=”后面填写qemu-system-i386，并删掉前面的“#”;"></a>4.2 在“<code>QEMU=</code>”后面填写<code>qemu-system-i386</code>，并删掉前面的“#”;</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfc4vwc5zj20eb01ljr9.jpg" alt=""><br>完成后应如下图所示：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfc54lb79j20eo01lq2v.jpg" alt=""></p><h3 id="4-3-进入xv6-master目录下，并输入make-qemu，如下图"><a href="#4-3-进入xv6-master目录下，并输入make-qemu，如下图" class="headerlink" title="4.3 进入xv6-master目录下，并输入make qemu，如下图"></a>4.3 进入xv6-master目录下，并输入<code>make qemu</code>，如下图</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfc5gn7dcj20on0drgo8.jpg" alt=""><br>Xv6运行成功。</p><blockquote><p>注：如果输入<code>make qemu</code>后出现以下错误<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfcxhh24lj20iz059751.jpg" alt=""><br>说明qemu在Makefile中未配置正确，检查是否删掉QEMU前的“#”，重新执行第2步。</p></blockquote><h3 id="4-4-也可以通过在命令行中输入qemu命令的方式来运行xv6系统。"><a href="#4-4-也可以通过在命令行中输入qemu命令的方式来运行xv6系统。" class="headerlink" title="4.4 也可以通过在命令行中输入qemu命令的方式来运行xv6系统。"></a>4.4 也可以通过在命令行中输入qemu命令的方式来运行xv6系统。</h3><p>事实上，输入<code>make qemu</code>等价于输入“<code>qemu-system-i386 -serial mon:stdio -hdb fs.img xv6.img -smp 2 -m 512</code>”<br><code>qemu-system-i386</code>即表示在x86平台下运行<br><code>-hdb</code>命令是系统要加载的第二个镜像文件<br><code>-hda</code>是第一个，可省略不写<br><code>-smp</code>是选择要用几个核来执行此系统<br><code>-m</code>是指给此系统分配的内存大小<br>如图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfd08le2mj20oo0ax0vf.jpg" alt=""></p><h2 id="5-编译生成物的说明"><a href="#5-编译生成物的说明" class="headerlink" title="5 编译生成物的说明"></a>5 编译生成物的说明</h2><p>xv6系统编译成功后，主要生成了xv6.img和fs.img这两个img文件。</p><h3 id="5-1-根据Makefile-84-87行"><a href="#5-1-根据Makefile-84-87行" class="headerlink" title="5.1 根据Makefile 84-87行"></a>5.1 根据Makefile 84-87行</h3><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">xv6.img: bootblock kernel fs.img</span></span><br><span class="line">dd if=/dev/zero of=xv6.img count=10000</span><br><span class="line">dd if=bootblock of=xv6.img conv=notrunc</span><br><span class="line">dd if=kernel of=xv6.img seek=1 conv=notrunc</span><br></pre></td></tr></table></figure><p>可以看出，bootblock和kernel都被加入到了xv6.img中，即xv6.img包含启动块和内核文件。</p><h3 id="5-2-根据Makefile-159-177行"><a href="#5-2-根据Makefile-159-177行" class="headerlink" title="5.2 根据Makefile 159-177行"></a>5.2 根据Makefile 159-177行</h3><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">UPROGS=\</span><br><span class="line">_cat\</span><br><span class="line">_echo\</span><br><span class="line">_forktest\</span><br><span class="line">_grep\</span><br><span class="line">_init\</span><br><span class="line">_kill\</span><br><span class="line">_ln\</span><br><span class="line">_ls\</span><br><span class="line">_mkdir\</span><br><span class="line">_rm\</span><br><span class="line">_sh\</span><br><span class="line">_stressfs\</span><br><span class="line">_usertests\</span><br><span class="line">_wc\</span><br><span class="line">_zombie\</span><br><span class="line"></span><br><span class="line">    fs.img: mkfs README <span class="variable">$(UPROGS)</span></span><br><span class="line">./mkfs fs.img README <span class="variable">$(UPROGS)</span></span><br></pre></td></tr></table></figure><p>可以看出fs.img包含了Unix系统的一些常用命令，故而猜测xv6.img和fs.img一起运行可以使xv6系统使用这些Unix命令。</p><h2 id="6-用不同CPU数量启动xv6"><a href="#6-用不同CPU数量启动xv6" class="headerlink" title="6 用不同CPU数量启动xv6"></a>6 用不同CPU数量启动xv6</h2><h3 id="6-1-单核"><a href="#6-1-单核" class="headerlink" title="6.1 单核"></a>6.1 单核</h3><p>在命令行中输入<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-i386 –serial mon:stdio –hdbfs.imga.img –smp 1 –m 512</span><br></pre></td></tr></table></figure></p><p>（上文说过，smp命令即可指定CPU个数，故个数为1即为单核）<br>输入后执行，如图所示：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfnviarpwj20q20ge79e.jpg" alt=""></p><h3 id="6-2-双核"><a href="#6-2-双核" class="headerlink" title="6.2 双核"></a>6.2 双核</h3><p>将smp的1改为2，执行。如图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfnwfuaz2j20n30av0uo.jpg" alt=""></p><h3 id="6-3-三核"><a href="#6-3-三核" class="headerlink" title="6.3 三核"></a>6.3 三核</h3><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1frfnx6bp99j20ob0a0ac0.jpg" alt=""></p>]]></content>
      
      
      <categories>
          
          <category> 操作系统 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> XV6 </tag>
            
            <tag> 多核 </tag>
            
            <tag> qemu </tag>
            
            <tag> Ubuntu </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>实用博文&amp;踩过的坑</title>
      <link href="/%E5%AE%9E%E7%94%A8%E5%8D%9A%E6%96%87/"/>
      <url>/%E5%AE%9E%E7%94%A8%E5%8D%9A%E6%96%87/</url>
      
        <content type="html"><![CDATA[<blockquote class="blockquote-center"><p><strong>好记性不如烂笔头</strong></p></blockquote><p>本文将记录一些看到的觉得有用的博文和自己在日常学习工作中踩过的坑及解决方式。<br><a id="more"></a></p><h2 id="CentOS虚拟机和物理机共享文件夹实现"><a href="#CentOS虚拟机和物理机共享文件夹实现" class="headerlink" title="CentOS虚拟机和物理机共享文件夹实现"></a><a href="https://www.linuxidc.com/Linux/2017-04/142897.htm" target="_blank" rel="noopener">CentOS虚拟机和物理机共享文件夹实现</a></h2><h2 id="Spark认识-amp-环境搭建-amp-运行第一个Spark程序"><a href="#Spark认识-amp-环境搭建-amp-运行第一个Spark程序" class="headerlink" title="Spark认识&amp;环境搭建&amp;运行第一个Spark程序"></a><a href="https://www.cnblogs.com/wonglu/p/5901356.html" target="_blank" rel="noopener">Spark认识&amp;环境搭建&amp;运行第一个Spark程序</a></h2><h2 id="spark-将DataFrame所有的列类型改为double"><a href="#spark-将DataFrame所有的列类型改为double" class="headerlink" title="spark 将DataFrame所有的列类型改为double"></a><a href="https://blog.csdn.net/dkl12/article/details/80256585" target="_blank" rel="noopener">spark 将DataFrame所有的列类型改为double</a></h2>]]></content>
      
      
      <categories>
          
          <category> 记录 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>一句话流水账</title>
      <link href="/%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%B5%81%E6%B0%B4%E8%B4%A6/"/>
      <url>/%E4%B8%80%E5%8F%A5%E8%AF%9D%E6%B5%81%E6%B0%B4%E8%B4%A6/</url>
      
        <content type="html"><![CDATA[<blockquote class="blockquote-center"><p>吾日三省吾身：为人谋而不忠乎？与朋友交而不信乎？传不习乎?</p><p><strong>——曾子</strong></p></blockquote><a id="more"></a> <h2 id="2018-12-9"><a href="#2018-12-9" class="headerlink" title="2018.12.9"></a>2018.12.9</h2><p>今天，我成为了一名光荣的中共（预备）党员。</p><h2 id="2018-11-20"><a href="#2018-11-20" class="headerlink" title="2018.11.20"></a>2018.11.20</h2><p>TensorFlow那个项目算是做完了，说实话还是学到了点东西的，后续将补上日志。</p><p>最近毕设开题，经过和老师讨论，我的毕设题目定为了《基于知识图谱的大数据分析技术研究与应用》，我是第一次听说知识图谱这个名词，老师也说挺有挑战性的，所以，未来一年加油干咯！</p><h2 id="2018-10-31"><a href="#2018-10-31" class="headerlink" title="2018.10.31"></a>2018.10.31</h2><p>俗话说“金九银十”，对找工作的学长学姐们来说更是如此，秋招已经进入了尾声，学长学姐们基本也都签到了满意的工作，我女票也是如此[笑脸]。</p><p>女票签到了上海，去了花旗银行，年薪22w，与互联网公司比算中等水平，但是比互联网公司轻松多了，基本不加班，她也挺满意的。</p><p>这儿有一张今年互联网公司的校招薪酬表<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fwrpjjaf5rj20o10bd0u9.jpg" alt=""><br>在以前，我看到类似的薪资表，第一反应是不信，当时是双非本科，大家平均月薪4k、5k，有个别优秀的也才拿七八千。。后来阅历丰富了相信了之后也觉得与自己相差太远了，觉得那些都得是极为优秀的人才能拿到。</p><p>今年女票的同学年薪大都在20w+，没听说谁年薪低于15w的，拿30w+的也有好几个，还有个大佬腾讯阿里都给50w左右抢人，然后他在犹豫去哪个（我感觉这个问题对我而言就跟小时候考虑要上清华还是北大一样，膜拜大佬啊），而且居然还有几个拒了BAT的offer选择一些AI独角兽创业公司的，都好强啊。。。我也好想拒一下阿里offer啊[笑cry]。。</p><p>这个时候我再看这张图，和以前完全不一样了，现在觉得这就是正常现象啊，这不就是在描述我们的就业情况嘛。。而且我现在竟然觉得BAT给的挺低的（从图中能明显看出来BAT比TMD(头条、美团、滴滴)给的低），呀我一定是飘了。。。不过话说回来，本质原因还是学校好啊，看来还是得上985啊！</p><p>为了达到毕业之后和女票年薪50w+的小目标，我明年得拿到28w+，按14个月工资计算的话就是月薪20k，20k啊20k…加油吧~</p><h2 id="2018-10-24"><a href="#2018-10-24" class="headerlink" title="2018.10.24"></a>2018.10.24</h2><p>今天是1024程序员节，西安市举办了第二届全球程序员节，晚上还在高新区创业咖啡街区广场举办了晚会，整个广场也加入了好多程序猿元素，好不热闹！<br>感受到了社会对程序猿们的尊重~<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fwrl47mf8mj23402bskjo.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fwrl493gezj22bs3401l1.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fwrl49k4dyj22bs3401l1.jpg" alt=""></p><h2 id="2018-10-10"><a href="#2018-10-10" class="headerlink" title="2018.10.10"></a>2018.10.10</h2><p>好难啊 我连TensorFlow都没用过 神经网络也没有过深入了解 现在老师交给我的任务里竟然需要改TensorFlow的源码，而且11月初就得做好。。。TF的源码是C++写的，我也没学过C++，我的天呐，努力加班加点干吧。。</p><h2 id="2018-10-04"><a href="#2018-10-04" class="headerlink" title="2018.10.04"></a>2018.10.04</h2><p>算了一下，我9月份赚了好多钱啊，分别是：</p><ul><li>兼职辅导员工资 2000</li><li>9月助研费 1000</li><li>9月助学金 700</li><li>教研室值班费 350</li><li>卖了24份专业课资料 2200左右</li></ul><p>合计6250，我的天呐，比我工作时的工资还多。。。</p><h2 id="2018-09-07"><a href="#2018-09-07" class="headerlink" title="2018.09.07"></a>2018.09.07</h2><p>老师说那个大数据的项目不做了，因为甲方的给的需求不明确、数据也比较乱等等，从5月份做到9月份，学了4个月hadoop、spark，现在突然不做了，有点sad…<br>不过也不能说白学了，技术学到的就是自己的，只是不能现在用而已，说不定以后有机会用呢</p><h2 id="2018-09-03"><a href="#2018-09-03" class="headerlink" title="2018.09.03"></a>2018.09.03</h2><p>现在才真正算研二了，按以往经验，研二这年应该挺重要的，希望自己在这一年能多沉淀一些东西吧~</p><p>回顾研一的学习生活，研一上学期主要精力都在搞多核操作系统的实现，然而也没啥大的进展，只做到了读取当前电脑共有多少个核这一步，发现自己对这个真是提不起兴趣啊，不过也有很多好处，最大的好处就是熟悉了Linux系统；</p><p>研二下学期刚开始导师管的松，然后就偷着没搞操作系统，自学了点Python、了解了些机器学习的基础知识、瞎搞了搞服务器、学了学Hadoop，好巧不巧，学期中教研室另一个老师准备接一个有关大数据的项目，缺人手就把我调过去了，我这学期自己瞎折腾的这些东西竟然都能用到，简直开心~</p><p>总体来说，研一学的东西也不算少，希望那个大数据的项目能成功接下来，要不然我可能得被安排去做有关MPI的一个项目了。。。在做项目的同时，研二一定要过六级啊，哦对，也要拿到驾照！</p><h2 id="2018-08-09"><a href="#2018-08-09" class="headerlink" title="2018.08.09"></a>2018.08.09</h2><p>本来说8月10号放假呢 现在看来也不行了 暑假可能只放1周 或更少。。。加油！</p><h2 id="2018-07-03"><a href="#2018-07-03" class="headerlink" title="2018.07.03"></a>2018.07.03</h2><p>从本科到现在，好多课程的大作业（或说课程设计）都是四到八个人为一小组进行的，一般情况下每个小组的所有工作就只是一两个人做的，这一两个人被称为“大腿（或大神）”其他人就被称为“抱大腿”。。</p><p>我不明白为什么，我一直是这个“大腿”，我也想抱个大腿啊，轻轻松松的就拿到分数了，最气的是大二时数据结构课设，整个项目都是我做的，连报告都是我写的，最后我得的分是全组最低的。。</p><p>原来想的上了研究生就可以抱别人大腿了，可事实是，每次有需要分组时，西工大本校学生会扎堆，外校学生只能找外校的，然后我就又成了大腿。。唉，好累……</p><h2 id="2018-07-01"><a href="#2018-07-01" class="headerlink" title="2018.07.01"></a>2018.07.01</h2><p>6月份终于忙完了，先说说以前立的那个flag，就是本来准备用hadoop做<a href="http://qiming.info:8080/score">学生成绩分析系统</a>的那个,说来也巧，hadoop看了一半，老师让我学spark，所以学着spark我便顺势用spark做了一遍这个东西，并且将它作为了我们云计算课程的一次大作业，写的博客在此：<a href="https://qiming.info/基于Spark的学生成绩分析系统/">基于Spark的学生成绩分析系统</a>；然后就是自学了DBSCAN算法并做PPT在数据挖掘课上讲解，自己还是太紧张，讲完满头大汗。。。此外，杂七杂八的课程大作业也做了一大堆，忙碌的6月终于结束了，可以迎接忙碌的7月了。。。[笑cry]</p><h2 id="2018-05-28"><a href="#2018-05-28" class="headerlink" title="2018.05.28"></a>2018.05.28</h2><p>困扰了几个月的买房大业终于结束了，运气超级棒，2193人摇号选88套房子，摇号到第二组时就摇中了我，就是说我选房时前面只有一组（10个）人选了房子，我的可选空间还特别大，真是太棒了。</p><p>房间是111.12平的，7楼东户，三室两厅一厨两卫，而且明厨明卫，户型方正，南北通透，感觉真是赚到了~^_^~</p><p>说说价格吧，一平10480，总价1164538，首付家人付了53万多，半辈子的积蓄还借了不少钱，真的是挺感动的，可是又不知道怎么说，总之，我爱你们！剩下63万贷款，以后要好好加油，找个好工作，努力赚钱~</p><h2 id="2018-05-25"><a href="#2018-05-25" class="headerlink" title="2018.05.25"></a>2018.05.25</h2><p>教研室另一个老师让我参与了一个有关spark大数据分析的项目，终于可以做做自己感兴趣的东西了，很开心，虽然对spark还一点都不会而且最近还要考试、做一些课程的大作业等还挺忙的，不过抽时间挤时间都要学，做自己喜欢的事最幸福了！</p><h2 id="2018-05-13"><a href="#2018-05-13" class="headerlink" title="2018.05.13"></a>2018.05.13</h2><p>今天是母亲节，同时也是我和女票的10000000000B(1024)天纪念日~嘿嘿，神奇，今天与我生命中最重要的两个女士都有关，特此记录一下。</p><h2 id="2018-05-10"><a href="#2018-05-10" class="headerlink" title="2018.05.10"></a>2018.05.10</h2><p>开始学学Hadoop，立个flag，6月10日之前将学生成绩分析系统用Hadoop实现一遍，因为实践才是最好的学习技术的方式！</p><h2 id="2018-05-03"><a href="#2018-05-03" class="headerlink" title="2018.05.03"></a>2018.05.03</h2><p>今天的《云计算基础》可能是上研究生以来听得最认真的一节课了:joy:。。。所以专门在此记录一下，主要讲了谷歌分布式系统的BigTable的原理。感觉认真听还是能学到东西的，突然觉得如果没有手机，我能做好多事啊，效率也能提高很多！</p><h2 id="2018-05-01"><a href="#2018-05-01" class="headerlink" title="2018.05.01"></a>2018.05.01</h2><p>看了西安的无人机表演，竟然表演失误了，为市政府觉得尴尬。。。不过个人感觉还是挺震撼的，祝大西安发展的越来越好吧~</p><p>来看看对比图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fr52lxiniuj20ex0dcgm2.jpg" alt=""><br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fr52o0p1npj20ey0dcwf8.jpg" alt=""><br>（18.05.06补充：无人机表演团队亿航公司今日发声明称“乱码”情况为无人机受到了定向干扰）</p>]]></content>
      
      
      <categories>
          
          <category> 记录 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 日记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里云CentOS下Hexo+Nginx建站过程</title>
      <link href="/%E9%98%BF%E9%87%8C%E4%BA%91CentOS%E4%B8%8BHexo+Nginx%E5%BB%BA%E7%AB%99%E8%BF%87%E7%A8%8B/"/>
      <url>/%E9%98%BF%E9%87%8C%E4%BA%91CentOS%E4%B8%8BHexo+Nginx%E5%BB%BA%E7%AB%99%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>讲Hexo建站的有很多，但几乎都是用Hexo和Github||coding.net上搭建的，再加上其中有好多是在Windows版本下的，所以本文可能是国内首个讲在CentOS下使用hexo和nginx服务器搭建网站的教程了，我会写的很详细，如果有哪里不对或没讲明白的欢迎评论！</p><p>看完本篇你将学到：</p><ul><li>阿里云控制台的部分操作</li><li>CentOS下Git的安装方法</li><li>CentOS下Node.js的安装方法</li><li>CentOS下Nginx的安装及配置方法</li><li>Linux系统的一些指令操作</li><li>HEXO博客的安装及使用方法</li><li>一些建站知识</li></ul></blockquote><a id="more"></a><p>前几天阿里云做活动，一年云服务器99块钱，顺便看了眼域名，有个还不错的域名（就是正在使用的这个：<a href="http://qiming.info">QIMING.INFO</a>）也不贵，首年11元，正好最近想搞个博客，于是没有过多犹豫就果断入手了。</p><p>我买的是CentOS 7.3版本的，是一个纯净的系统，所以本文将介绍CentOS从零开始用Hexo和Nginx建站的过程。</p><h1 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1 准备工作"></a>1 准备工作</h1><h2 id="1-1-阿里云控制台中开启相关端口"><a href="#1-1-阿里云控制台中开启相关端口" class="headerlink" title="1.1 阿里云控制台中开启相关端口"></a>1.1 阿里云控制台中开启相关端口</h2><p>新购买的阿里云系统中默认是没有开启80端口的，而这是HTTP协议的端口号，不开启别人是无法访问你的网站的。下文中还会使用到4000端口，所以首先在阿里云控制台中开启这两个端口，具体步骤如下：</p><ol><li><p>进入阿里云管理控制台，选择管理实例<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqntn16n62j213h0hfdiw.jpg" alt="Markdown"></p></li><li><p>点击本实例安全组，选择配置规则<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqntnya2wrj212u0dmgn1.jpg" alt="Markdown"></p></li><li><p>点击右上角的添加安全组规则<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqntot74epj213807jgml.jpg" alt="Markdown"></p></li><li><p>依次将80端口和4000端口添加进去</p><p>如下图为添加80端口的示意图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqntqvvwwuj20kb0mbq3t.jpg" alt="Markdown"></p></li></ol><h2 id="1-2-安装git"><a href="#1-2-安装git" class="headerlink" title="1.2 安装git"></a>1.2 安装git</h2><p>直接使用yum即可，即在命令行中输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum –y install git</span><br></pre></td></tr></table></figure></p><p>完成后输入<code>git version</code>,若显示git版本信息即安装成功。</p><h2 id="1-3-安装Node-js"><a href="#1-3-安装Node-js" class="headerlink" title="1.3 安装Node.js"></a>1.3 安装Node.js</h2><p>Node.js 是运行在服务端的 JavaScript, 是基于 Chrome JavaScript V8 引擎建立的平台。</p><p>Hexo基于Node.js，所以安装Node.js是必须的，具体步骤如下：</p><h3 id="1-3-1-下载安装包"><a href="#1-3-1-下载安装包" class="headerlink" title="1.3.1 下载安装包"></a>1.3.1 下载安装包</h3><p>我下载的是v6.10.1版本的，当然你也可以在<a href="https://nodejs.org/en/download/" target="_blank" rel="noopener">官网</a>上找其他版本的下载链接<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://nodejs.org/dist/v6.10.1/node-v6.10.1-linux-x64.tar.xz</span><br></pre></td></tr></table></figure></p><p>待下载完成后，进行下一步</p><h3 id="1-3-2-解压缩改名放到-usr-local"><a href="#1-3-2-解压缩改名放到-usr-local" class="headerlink" title="1.3.2 解压缩改名放到/usr/local"></a>1.3.2 解压缩改名放到/usr/local</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xvJf node-v6.10.1-linux-x64.tar.xz</span><br></pre></td></tr></table></figure><p>将解压的 Node.js 目录移动到 /usr/local 目录下<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mv node-v6.10.1-linux-x64 /usr/<span class="built_in">local</span>/node-v6</span><br></pre></td></tr></table></figure></p><h3 id="1-3-3-软链接到-bin-目录"><a href="#1-3-3-软链接到-bin-目录" class="headerlink" title="1.3.3 软链接到 /bin 目录"></a>1.3.3 软链接到 /bin 目录</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ln -s /usr/<span class="built_in">local</span>/node-v6/bin/node /bin/node</span><br><span class="line">ln -s /usr/<span class="built_in">local</span>/node-v6/bin/npm /bin/npm</span><br></pre></td></tr></table></figure><h3 id="1-3-4-配置环境变量"><a href="#1-3-4-配置环境变量" class="headerlink" title="1.3.4 配置环境变量"></a>1.3.4 配置环境变量</h3><p>将 /usr/local/node-v6/bin 目录添加到 $PATH 环境变量中可以方便地使用通过 npm 全局安装的第三方工具<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">'export PATH=/usr/local/node-v6/bin:$PATH'</span> &gt;&gt; /etc/profile</span><br></pre></td></tr></table></figure></p><p>使环境变量生效<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> /etc/profile</span><br></pre></td></tr></table></figure></p><h3 id="1-3-5-测试是否成功"><a href="#1-3-5-测试是否成功" class="headerlink" title="1.3.5 测试是否成功"></a>1.3.5 测试是否成功</h3><p>输入<code>node -v</code>和<code>npm -v</code>,若显示版本号，即安装成功，如图：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqntz2hmsoj205w01sq2q.jpg" alt="Markdown"></p><h1 id="2-安装并初步了解Hexo"><a href="#2-安装并初步了解Hexo" class="headerlink" title="2 安装并初步了解Hexo"></a>2 安装并初步了解Hexo</h1><h2 id="2-1-安装Hexo"><a href="#2-1-安装Hexo" class="headerlink" title="2.1 安装Hexo"></a>2.1 安装Hexo</h2><p>执行以下命令即可安装Hexo：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure></p><blockquote><p><strong>注：目前npm官方源在国内访问并不稳定，如果你无法直接安装，请更换国内npm源</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">npm config <span class="built_in">set</span> registry https://registry.npm.taobao.org</span><br></pre></td></tr></table></figure></p></blockquote><p>完成后输入<code>hexo version</code>，若显示一系列版本信息则安装成功。</p><h2 id="2-2-初步使用"><a href="#2-2-初步使用" class="headerlink" title="2.2 初步使用"></a>2.2 初步使用</h2><p>安装 Hexo 完成后，请执行下列命令，Hexo 将会在指定文件夹中新建所需要的文件。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ hexo init &lt;folder&gt;</span><br><span class="line">$ <span class="built_in">cd</span> &lt;folder&gt;</span><br></pre></td></tr></table></figure></p><p>新建完成后，指定文件夹的目录如下：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">├── _config.yml</span><br><span class="line">├── package.json</span><br><span class="line">├── scaffolds</span><br><span class="line">├── <span class="built_in">source</span></span><br><span class="line">|   ├── _drafts</span><br><span class="line">|   └── _posts</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure></p><p>详细说明如下：</p><blockquote><p>1、_config.yml是YAML格式文件，也是Hexo的站点配置文件（敲黑板！重点重点！）<br>2、package.json配置hexo运行需要的node.js包，不用手动更改<br>3、scaffolds是模板文件夹。这个“模板”就是指新建的markdown文件的模板，每新建一个markdown文件（由于Hexo使用markdown语法，在渲染生成静态HTML页面之前，源文件都是markdown文件），就会包含对应模板的内容。<br>该文件夹内有三个模板：</p><ul><li>draft.md，草稿的模板</li><li>page.md，页面的模板</li><li>post.md，文章的模板</li></ul><p>4、source是资源文件夹，资源文件夹是存放用户资源的地方。除_posts 文件夹之外，开头命名为 _(下划线)的文件 / 文件夹和隐藏的文件将会被忽略。Markdown 和 HTML 文件会被解析并放到 public 文件夹，而其他文件会被拷贝过去。<br>5、themes是主题文件夹。Hexo 会根据主题来生成静态页面。</p></blockquote><h2 id="2-3-第一次运行"><a href="#2-3-第一次运行" class="headerlink" title="2.3 第一次运行"></a>2.3 第一次运行</h2><p>输入<code>hexo generate</code>命令来生成静态文件。</p><blockquote><p>注1：生成的静态文件存放在public文件夹中<br>注2：此命令可简写为<code>hexo g</code></p></blockquote><p>然后输入<code>hexo server</code>(可简写为<code>hexo s</code>)来启动服务器。</p><p>默认情况下，端口号为4000，上文已经开启过此端口号，所以服务器启动成功后，在浏览器中输入<code>http://&lt;你的IP地址&gt;:4000</code>，即可看到第一次运行的状况：<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqntt0uu4hj20yg0kr7du.jpg" alt="Markdown"><br>结束访问按<code>Ctrl+C</code></p><h1 id="3-安装并配置Nginx"><a href="#3-安装并配置Nginx" class="headerlink" title="3 安装并配置Nginx"></a>3 安装并配置Nginx</h1><p>安装Nginx主要是想让网站能随时随地访问，不像上文中hexo提供的server，只能手动输入命令后才能访问到网站。</p><h2 id="3-1-安装-Nginx"><a href="#3-1-安装-Nginx" class="headerlink" title="3.1 安装 Nginx"></a>3.1 安装 Nginx</h2><p>在 CentOS 上，可直接使用 yum 来安装 Nginx<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install nginx -y</span><br></pre></td></tr></table></figure></p><h2 id="3-2-启动Nginx"><a href="#3-2-启动Nginx" class="headerlink" title="3.2 启动Nginx"></a>3.2 启动Nginx</h2><p>安装完成后，使用以下命令启动 Nginx：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start nginx</span><br></pre></td></tr></table></figure></p><p>此时，用浏览器访问 <code>http://&lt;你的IP地址&gt;</code>便可以看到 Nginx 的测试页面，即表示Nginx启动成功！<br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqnttlsr12j21ci0hsn00.jpg" alt="Markdown"><br>继续输入以下命令使Nginx开机自动启动：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl <span class="built_in">enable</span> nginx</span><br></pre></td></tr></table></figure></p><h2 id="3-3-配置静态服务器访问路径"><a href="#3-3-配置静态服务器访问路径" class="headerlink" title="3.3 配置静态服务器访问路径"></a>3.3 配置静态服务器访问路径</h2><p>Nginx 需要配置静态资源的路径信息才能通过 url 正确访问到服务器上的静态资源。<br>即是要将HEXO生成的静态资源的路径放置到Nginx的访问路径</p><p>打开 Nginx 的默认配置文件 /etc/nginx/nginx.conf ，将默认的 root /usr/share/nginx/html 修改为: root /…/&lt;folder&gt;/public （此处可能在此配置文件的42行，&lt;folder&gt;即为hexo初始化的文件夹）</p><p>修改完成后保存，输入以下命令重启Nginx：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nginx -s reload</span><br></pre></td></tr></table></figure></p><p>此时再次访问你的IP地址，若显示上文的hexo初次运行的样子，则说明配置成功。</p><blockquote><p><strong>注：</strong>可能会报403错误，原因是nginx没有权限访问public文件夹，修改方法有两种：<br>1.修改public文件夹的权限，修改为777（即任何人可读可写可执行），不推荐<br>2.修改nginx.conf中的user（可能在第5行），改为可以访问public文件夹的用户，如root。</p></blockquote><h1 id="4-配置Hexo"><a href="#4-配置Hexo" class="headerlink" title="4 配置Hexo"></a>4 配置Hexo</h1><h2 id="4-1-站点配置"><a href="#4-1-站点配置" class="headerlink" title="4.1 站点配置"></a>4.1 站点配置</h2><p>配置hexo时，需要修改上文提到的根目录下的<code>_config.yml</code>文件，我将自己的部分配置贴上来，主要修改的就是这部分：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Site</span></span><br><span class="line"><span class="attr">title:</span> <span class="string">QIMING.INFO</span> <span class="comment">#网站标题</span></span><br><span class="line"><span class="attr">subtitle:</span>          <span class="comment">#网站副标题</span></span><br><span class="line"><span class="attr">description:</span>       <span class="comment">#网站描述，可以是你喜欢的一句话</span></span><br><span class="line"><span class="attr">keywords:</span>          <span class="comment">#网站关键词  </span></span><br><span class="line"><span class="attr">author:</span> <span class="string">Qiming</span>     <span class="comment">#你的名字</span></span><br><span class="line"><span class="attr">language:</span> <span class="string">zh-CN</span>    <span class="comment">#网站使用的语言</span></span><br><span class="line"><span class="attr">timezone:</span>          <span class="comment">#网站时区，默认使用服务器的时区</span></span><br></pre></td></tr></table></figure></p><p>其余的文件内容可以使用默认值，萌新可不必修改，具体参见<a href="https://hexo.io/zh-cn/docs/configuration.html" target="_blank" rel="noopener">官方文档</a>。</p><blockquote><p>注：修改<code>yml</code>文件时应注意<code>“:”</code>后面应加空格。</p></blockquote><h2 id="4-2-切换主题"><a href="#4-2-切换主题" class="headerlink" title="4.2 切换主题"></a>4.2 切换主题</h2><p>你可以在<a href="https://hexo.io/themes/" target="_blank" rel="noopener">主题列表</a>中寻找你喜欢的主题，然后将其下载（或使用<code>git clone</code>）到<code>themes</code>文件夹下，然后修改站点配置文件<code>_config.yml</code>里的<code>theme</code>设定即可。例如，我使用的是<code>next</code>主题：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">theme:</span> <span class="string">next</span></span><br></pre></td></tr></table></figure></p><h2 id="4-3-主题的配置"><a href="#4-3-主题的配置" class="headerlink" title="4.3 主题的配置"></a>4.3 主题的配置</h2><p>每个主题也会有一个<code>_config.yml</code>文件，在此主题的根目录下，用于配置主题。</p><p>我使用的NexT主题有着丰富详细的使用说明，其内置了很多实用功能如第三方评论、文章阅读次数统计、动态背景、站内搜索等，具体设置可参考其<a href="http://theme-next.iissnan.com/" target="_blank" rel="noopener">官方使用文档</a>，如有不懂可评论告知。</p><h1 id="5-开始使用"><a href="#5-开始使用" class="headerlink" title="5 开始使用"></a>5 开始使用</h1><h2 id="5-1-创建文章"><a href="#5-1-创建文章" class="headerlink" title="5.1 创建文章"></a>5.1 创建文章</h2><p>你可以执行下列命令来创建一篇新文章。<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new post &lt;title&gt;</span><br></pre></td></tr></table></figure></p><blockquote><p>注：post可以不写，因为其为layout的默认值，其余layout还有page（页面）和draft（草稿）。</p></blockquote><p>之后，你的<code>source/_post</code>文件夹下会产生一个<code>&lt;title&gt;.md</code>的文件。</p><h2 id="5-2-编辑文章"><a href="#5-2-编辑文章" class="headerlink" title="5.2 编辑文章"></a>5.2 编辑文章</h2><h3 id="5-2-1-Front-matter"><a href="#5-2-1-Front-matter" class="headerlink" title="5.2.1 Front-matter"></a>5.2.1 Front-matter</h3><p>打开此<code>&lt;title&gt;.md</code>后你会发现在最上方有以<code>---</code>分隔的区域，这部分即称为Front-matter，用于注定个别文件的变量，例如本篇文章的Front-matter：<br><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">title:</span> <span class="string">阿里云CentOS下Hexo+Nginx建站过程</span> <span class="comment">#标题</span></span><br><span class="line"><span class="attr">tags:</span>                      <span class="comment">#标签</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">HEXO</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">建站</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">nginx</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">nodejs</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">阿里云</span></span><br><span class="line"><span class="attr">categories:</span>                <span class="comment">#分类（注：不支持同级并列分类）</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">教程</span></span><br><span class="line"><span class="bullet">-</span> <span class="string">Hexo</span></span><br><span class="line"><span class="attr">date:</span> <span class="number">2018</span><span class="bullet">-04</span><span class="bullet">-20</span> <span class="number">15</span><span class="string">:52:08</span>  <span class="comment">#文件建立时间</span></span><br></pre></td></tr></table></figure></p><h3 id="5-2-2-写作"><a href="#5-2-2-写作" class="headerlink" title="5.2.2 写作"></a>5.2.2 写作</h3><p>Hexo仅支持Markdown语法的写作，在此服务器中用vim编写的话看不到预览效果，所以我是在Windows上用<del><a href="https://maxiang.io/" target="_blank" rel="noopener">马克飞象</a></del>（用了一段时间发现这个东西竟然还收费，哼，不用了）<a href="https://typora.io/#download" target="_blank" rel="noopener"><code>Typora</code></a>写好之后，粘贴到<code>&lt;title&gt;.md</code>里的。</p><h2 id="5-3-运行"><a href="#5-3-运行" class="headerlink" title="5.3 运行"></a>5.3 运行</h2><p>写完文章后，在你的博客根目录下输入：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hexo g</span><br></pre></td></tr></table></figure></p><p>hexo就会将写好的文章生成静态网页并存放在public文件夹下了。</p><p>如上，如果nginx配置正常的话，你现在已经可以通过访问<code>http://&lt;你的IP地址&gt;</code>来看到你的博客了！</p><blockquote><p>注：hexo里还有两个常用命令没有讲到，分别是<code>hexo clean</code>和<code>hexo deploy</code>（可简写为<code>hexo d</code>）：</p><ul><li><code>clean</code>：清除缓存文件 (<code>db.json</code>) 和已生成的静态文件 (<code>public文件夹</code>)。在某些情况（尤其是更换主题后），如果发现您对站点的更改无论如何也不生效，您可能需要运行该命令。</li><li><code>deploy</code>：用于部署生成的静态文件(<code>public文件夹</code>)，本文中，因为配置了nginx服务器的访问地址直接指向了<code>public文件夹</code>，所以用不到此命令。</li></ul></blockquote><h1 id="6-后续工作"><a href="#6-后续工作" class="headerlink" title="6 后续工作"></a>6 后续工作</h1><p>现在，再购买一个域名，备案完成后，在阿里云控制台上将此域名解析到你的IP地址上，就可以通过域名访问你的博客啦~</p><p>在完成了本文中所讲的操作后，搭建的博客还有很多部分可以完善，那么具体该怎么完善呢，可以参考<code>shenzekun</code>大佬的这篇文章：<a href="http://shenzekun.cn/hexo%E7%9A%84next%E4%B8%BB%E9%A2%98%E4%B8%AA%E6%80%A7%E5%8C%96%E9%85%8D%E7%BD%AE%E6%95%99%E7%A8%8B.html" target="_blank" rel="noopener">hexo的next主题个性化教程:打造炫酷网站</a>。</p><p>此外，如果想做SEO优化，使你的文章被更多人搜到，可以参考这篇文章<a href="http://www.yuan-ji.me/Hexo-%E4%BC%98%E5%8C%96%EF%BC%9A%E6%8F%90%E4%BA%A4sitemap%E5%8F%8A%E8%A7%A3%E5%86%B3%E7%99%BE%E5%BA%A6%E7%88%AC%E8%99%AB%E6%8A%93%E5%8F%96-GitHub-Pages-%E9%97%AE%E9%A2%98/" target="_blank" rel="noopener">Hexo 优化：提交 sitemap 及解决百度爬虫无法抓取 GitHub Pages 链接问题</a></p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Hexo </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HEXO </tag>
            
            <tag> 建站 </tag>
            
            <tag> nginx </tag>
            
            <tag> nodejs </tag>
            
            <tag> 阿里云 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Openlava安装教程</title>
      <link href="/Openlava%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
      <url>/Openlava%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<p>  OpenLava是一个开源的HPC项目，是100%免费、开源、兼容IBM Spectrum LSF的工作负载调度器，支持各种高性能计算和分析应用。<br>  由于OpenLava的命令行和文件格式与大多数LSF功能相兼容,因此用户和管理员都将非常熟悉OpenLava的操作。组织和机构可以充分利用数以百计的商业和开源软件的已有集成，保留他们在设计、集成和技能方面的已有投资，并快速摆脱在生产环境中对商业许可证的依赖和限制。<br>  目前国内关于Openlava的安装教程几乎没有，故写此篇来介绍，有不对之处还请指正。</p><a id="more"></a><h1 id="1-系统要求"><a href="#1-系统要求" class="headerlink" title="1 系统要求"></a>1 系统要求</h1><p>支持主流的64位x86 Linux发行版，包括RHEL、CentOS、SUSE、和Ubuntu</p><h1 id="2-网络要求"><a href="#2-网络要求" class="headerlink" title="2 网络要求"></a>2 网络要求</h1><p>安装Openlava需要：a)主机联网 b)各个主机可以互相通信，即可以互相Ping通对方主机名。<br>使用快捷键CTRL+ALT+T（或者在桌面点击右键，选择open terminal）进入系统的终端界面：</p><h2 id="2-1-查看系统主机名"><a href="#2-1-查看系统主机名" class="headerlink" title="2.1 查看系统主机名"></a>2.1 查看系统主机名</h2><p>在安装开始前，我们需要知道本机器的主机名，在终端输入hostname –f即可看到</p><h2 id="2-2-测试两台主机的网络状况"><a href="#2-2-测试两台主机的网络状况" class="headerlink" title="2.2 测试两台主机的网络状况"></a>2.2 测试两台主机的网络状况</h2><p>当设置好网络之后结果应如下所示：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[jensd@master ~]$ ping -c 1 node</span><br><span class="line">PING node (192.168.202.102) 56(84) bytes of data.</span><br><span class="line">64 bytes from node (192.168.202.102): icmp_seq=1 ttl=64 time=0.380 ms</span><br><span class="line">--- node ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.380/0.380/0.380/0.000 ms</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[jensd@node ~]$ ping –c 1 master</span><br><span class="line">PING master (192.168.202.101) 56(84) bytes of data.</span><br><span class="line">64 bytes from master (192.168.202.101): icmp_seq=1 ttl=64 time=0.211 ms</span><br><span class="line">--- master ping statistics ---</span><br><span class="line">1 packets transmitted, 1 received, 0% packet loss, time 0ms</span><br><span class="line">rtt min/avg/max/mdev = 0.211/0.211/0.211/0.000 ms</span><br></pre></td></tr></table></figure><h1 id="3-下载准备"><a href="#3-下载准备" class="headerlink" title="3 下载准备"></a>3 下载准备</h1><p>进入Openlava官方网站：<a href="http://www.openlava.org/" target="_blank" rel="noopener">http://www.openlava.org/</a> ，点击Download标签，下载安装包：openlava-2.2.tar.gz，将文件存储于主机某个指定位置（例如将文件存放于浏览器自动下载的~/Download目录下）</p><h1 id="4-安装Openlava"><a href="#4-安装Openlava" class="headerlink" title="4 安装Openlava"></a>4 安装Openlava</h1><p>以下文档以CentOS 7操作系统为例，其中：主机 master作为集群中的管理主机，node为本集群中的一个执行主机。<br>注：在一个Openlava集群中，可以有很多个执行主机，此处仅以node这一台执行主机为例。</p><h2 id="4-1-管理主机安装Openlava"><a href="#4-1-管理主机安装Openlava" class="headerlink" title="4.1 管理主机安装Openlava"></a>4.1 管理主机安装Openlava</h2><h3 id="4-1-1-安装依赖包"><a href="#4-1-1-安装依赖包" class="headerlink" title="4.1.1 安装依赖包"></a>4.1.1 安装依赖包</h3><p>打开终端，在终端中逐条输入以下命令，以安装Openlava所需要的依赖包:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum update</span><br><span class="line">yum upgrade</span><br><span class="line">yum install tcl-dev ncurses-dev autoconf libtool</span><br></pre></td></tr></table></figure></p><p>注：如在Ubuntu系统下，指令稍有变化：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get upgrade -y</span><br><span class="line">sudo apt-get install -y tcl-dev ncurses-dev autoconf libtool</span><br></pre></td></tr></table></figure></p><h3 id="4-1-2-打开防火墙"><a href="#4-1-2-打开防火墙" class="headerlink" title="4.1.2 打开防火墙"></a>4.1.2 打开防火墙</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -I INPUT -p tcp --match multiport --dports 1024:65535 -j ACCEPT</span><br><span class="line">sudo iptables -I INPUT -p udp --match multiport --dports 1024:65535 -j ACCEPT</span><br><span class="line">sudo iptables-save|sudo tee /etc/sysconfig/iptables</span><br></pre></td></tr></table></figure><h3 id="4-1-3-解压Openlava安装包"><a href="#4-1-3-解压Openlava安装包" class="headerlink" title="4.1.3 解压Openlava安装包"></a>4.1.3 解压Openlava安装包</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cd ~/Download</span><br><span class="line">tar zxvf openlava-2.2.tar,gz</span><br><span class="line">cd openlava-2.2</span><br></pre></td></tr></table></figure><h3 id="4-1-4-执行安装"><a href="#4-1-4-执行安装" class="headerlink" title="4.1.4 执行安装"></a>4.1.4 执行安装</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./configure --prefix=/opt/openlava</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br></pre></td></tr></table></figure><h3 id="4-1-5-添加Openlava用户"><a href="#4-1-5-添加Openlava用户" class="headerlink" title="4.1.5 添加Openlava用户"></a>4.1.5 添加Openlava用户</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Create a Openlava user to own all lsf processes</span><br><span class="line">sudo useradd -r openlava</span><br></pre></td></tr></table></figure><h3 id="4-1-6-复制默认配置文件"><a href="#4-1-6-复制默认配置文件" class="headerlink" title="4.1.6 复制默认配置文件"></a>4.1.6 复制默认配置文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Copy the configurations to the system</span><br><span class="line">cd config</span><br><span class="line">sudo cp openlava /etc/init.d</span><br><span class="line">sudo cp lsf.cluster.openlava lsf.conf lsf.shared lsb.params lsb.hosts /opt/openlava/etc/</span><br><span class="line">sudo cp openlava.sh openlava.csh /etc/profile.d/</span><br></pre></td></tr></table></figure><h3 id="4-1-7-配置环境变量"><a href="#4-1-7-配置环境变量" class="headerlink" title="4.1.7 配置环境变量"></a>4.1.7 配置环境变量</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">. /etc/profile.d/openlava.sh</span><br></pre></td></tr></table></figure><h3 id="4-1-8-编辑lsf-cluster-openlava文件"><a href="#4-1-8-编辑lsf-cluster-openlava文件" class="headerlink" title="4.1.8 编辑lsf.cluster.openlava文件"></a>4.1.8 编辑lsf.cluster.openlava文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd /opt/openlava/etc</span><br><span class="line">vi lsf.cluster.openlava</span><br></pre></td></tr></table></figure><p>如下所示为需要新增的文字，其中，第一行为系统认为的管理主机，因此将管理主机的主机名放在灰色部分的第一行，并将后续需要加入集群的执行主机主机名依次加入该列表：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Begin   Host</span><br><span class="line">HOSTNAME       model      <span class="built_in">type</span>   server  r1m  RESOURCES</span><br><span class="line">master        IntelI5     linux    1     3.5    (cs)</span><br><span class="line">node          IntelI5     linux    1     3.5    (cs)</span><br><span class="line">End     Host</span><br></pre></td></tr></table></figure></p><h3 id="4-1-9-编辑-etc-hosts"><a href="#4-1-9-编辑-etc-hosts" class="headerlink" title="4.1.9 编辑/etc/hosts"></a>4.1.9 编辑/etc/hosts</h3><p>将需要加入本集群的主机名用以下命令添加至/etc/hosts：<br>sudo printf “33.33.33.31 master\n33.33.33.32 node\n” | sudo tee -a /etc/hosts<br>如需添加更多主机，可参照如下列表：<br>33.33.33.31 master<br>33.33.33.32 node<br>33.33.33.33 node1<br>33.33.33.34 node2<br>33.33.33.35 node3</p><h3 id="4-1-10-确保安装权限正确"><a href="#4-1-10-确保安装权限正确" class="headerlink" title="4.1.10 确保安装权限正确"></a>4.1.10 确保安装权限正确</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo chown -R openlava:openlava /opt/openlava</span><br></pre></td></tr></table></figure><h3 id="4-1-11-验证安装"><a href="#4-1-11-验证安装" class="headerlink" title="4.1.11 验证安装"></a>4.1.11 验证安装</h3><p>开启Openlava服务，如出现如下字段则表示安装成功且Openlava服务已开启：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[jensd@master ~]$ sudo /etc/init.d/openlava start</span><br><span class="line">Stopping daemons...</span><br><span class="line">Starting daemons...</span><br><span class="line">lim started</span><br><span class="line">res started</span><br><span class="line">sbatchd started</span><br></pre></td></tr></table></figure></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[jensd@master ~]$ lsid</span><br><span class="line">openlava project 2.2, Nov  6 2017</span><br><span class="line"> </span><br><span class="line">My cluster name is openlava</span><br><span class="line">My master name is master</span><br></pre></td></tr></table></figure><h2 id="4-2-执行主机安装Openlava"><a href="#4-2-执行主机安装Openlava" class="headerlink" title="4.2 执行主机安装Openlava"></a>4.2 执行主机安装Openlava</h2><p>方法与管理主机基本相同，需要注意的是，在上节第8步（编辑lsf.cluster.openlava文件）时，将管理主机的hostname仍放置在第一行，执行主机的顺序与上节第8步的顺序一致。</p><h1 id="5-安装Openlava-Web端"><a href="#5-安装Openlava-Web端" class="headerlink" title="5 安装Openlava Web端"></a>5 安装Openlava Web端</h1><h2 id="5-1-安装依赖包"><a href="#5-1-安装依赖包" class="headerlink" title="5.1 安装依赖包"></a>5.1 安装依赖包</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum -y install python-django python-pip git python-devel gcc lighttpd lighttpd-fastcgi</span><br><span class="line">sudo pip install flup cython</span><br><span class="line">sudo pip install –v Django==1.8</span><br></pre></td></tr></table></figure><p>注：在Ubuntu系统中，指令稍有变化：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install python-django python-pip git python-devel gcc lighttpd lighttpd-fastcgi</span><br><span class="line">sudo pip install flup cython</span><br><span class="line">sudo pip install –v Django==1.8</span><br></pre></td></tr></table></figure></p><h2 id="5-2-安装openlava-python"><a href="#5-2-安装openlava-python" class="headerlink" title="5.2 安装openlava-python"></a>5.2 安装openlava-python</h2><p>从GitHub上下载openlava-python：<br>    sudo git clone <a href="https://github.com/irvined1982/openlava-python.git" target="_blank" rel="noopener">https://github.com/irvined1982/openlava-python.git</a><br>确认该文件中的变量lsfdir所示为真实的openlava安装目录：<br>    sudo vi openlava-python/openlava/setup.py<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"><span class="comment"># Find lsbatch</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">        lsfdir=os.environ[<span class="string">'LSF_ENVDIR'</span>]</span><br><span class="line">        lsfdir=os.path.join(libdir,<span class="string">".."</span>)</span><br><span class="line"> </span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">        lsfdir=<span class="string">'/opt/openlava'</span></span><br></pre></td></tr></table></figure></p><p>安装openlava-python：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/openlava-python/openlava/</span><br><span class="line">sudo python setup.py install</span><br></pre></td></tr></table></figure></p><h2 id="5-3-安装openlava-web"><a href="#5-3-安装openlava-web" class="headerlink" title="5.3 安装openlava-web"></a>5.3 安装openlava-web</h2><p>从GitHub上下载openlava-web：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo git <span class="built_in">clone</span> https://github.com/irvined1982/openlava-web.git</span><br><span class="line"><span class="built_in">cd</span> openlava-web/</span><br><span class="line">sudo git submodule update --init –recursive</span><br></pre></td></tr></table></figure></p><p>执行安装命令：sudo python setup.py install</p><h2 id="5-4-创建Django项目并配置"><a href="#5-4-创建Django项目并配置" class="headerlink" title="5.4 创建Django项目并配置"></a>5.4 创建Django项目并配置</h2><p>在/opt目录下创建Django项目openlava_webui：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /opt/</span><br><span class="line">sudo django-admin startproject openlava_webui</span><br><span class="line">sudo cp -r /opt/openlava-web/openlavaweb/ /opt/openlava_webui/</span><br></pre></td></tr></table></figure></p><p>编辑/opt/openlava_webui/openlava_webui/urls.py文件及openlavaweb.urls文件：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> django.conf.urls <span class="keyword">import</span> patterns, include, url</span><br><span class="line"> </span><br><span class="line"><span class="keyword">from</span> django.contrib <span class="keyword">import</span> admin</span><br><span class="line">admin.autodiscover()</span><br><span class="line"> </span><br><span class="line">urlpatterns = patterns(<span class="string">''</span>,</span><br><span class="line">    <span class="comment"># Examples:</span></span><br><span class="line">    <span class="comment"># url(r'^$', 'openlava_webui.views.home', name='home'),</span></span><br><span class="line">    <span class="comment"># url(r'^blog/', include('blog.urls')),</span></span><br><span class="line"> </span><br><span class="line">    url(<span class="string">r'^admin/'</span>, include(admin.site.urls)),</span><br><span class="line">    url(<span class="string">r'^'</span>, include(<span class="string">'openlavaweb.urls'</span>)),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>编辑/opt/openlava_webui/openlava_webui/settings.py文件来包含openlavaweb：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSTALLED_APPS = (</span><br><span class="line">    <span class="string">'django.contrib.admin'</span>,</span><br><span class="line">    <span class="string">'django.contrib.auth'</span>,</span><br><span class="line">    <span class="string">'django.contrib.contenttypes'</span>,</span><br><span class="line">    <span class="string">'django.contrib.sessions'</span>,</span><br><span class="line">    <span class="string">'django.contrib.messages'</span>,</span><br><span class="line">    <span class="string">'django.contrib.staticfiles'</span>,</span><br><span class="line">    <span class="string">'openlavaweb'</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><h2 id="5-5-设置防火墙"><a href="#5-5-设置防火墙" class="headerlink" title="5.5 设置防火墙"></a>5.5 设置防火墙</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -I INPUT -p tcp -m state --state NEW -m tcp --dport 808 -j ACCEPT</span><br><span class="line">sudo iptables-save|sudo tee /etc/sysconfig/iptables</span><br></pre></td></tr></table></figure><h2 id="5-6-打开服务器"><a href="#5-6-打开服务器" class="headerlink" title="5.6 打开服务器"></a>5.6 打开服务器</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[jensd@master opt]$ sudo python /opt/openlava_webui/manage.py runserver 0.0.0.0:808</span><br><span class="line">Validating models...</span><br><span class="line"> </span><br><span class="line">0 errors found</span><br><span class="line">December 05, 2017 - 12:31:18</span><br><span class="line">Django version 1.6.8, using settings <span class="string">'openlava_webui.settings'</span></span><br><span class="line">Starting development server at http://0.0.0.0:80/</span><br><span class="line">Quit the server with CONTROL-C.</span><br></pre></td></tr></table></figure><h2 id="5-7-验证openlava-web端"><a href="#5-7-验证openlava-web端" class="headerlink" title="5.7 验证openlava web端"></a>5.7 验证openlava web端</h2><p>在浏览器中访问地址即可看到web界面：<a href="http://0.0.0.0:808/：" target="_blank" rel="noopener">http://0.0.0.0:808/：</a><br><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqnt71ly27j20so0pjab2.jpg" alt="Markdown"></p><h2 id="5-8-使用Lighttpd"><a href="#5-8-使用Lighttpd" class="headerlink" title="5.8 使用Lighttpd"></a>5.8 使用Lighttpd</h2><p>编辑/etc/lighttpd/modules.conf文件：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">server.modules = (</span><br><span class="line">  <span class="string">"mod_access"</span>,</span><br><span class="line">  <span class="string">"mod_alias"</span>,</span><br><span class="line">  <span class="string">"mod_fastcgi"</span>,</span><br><span class="line"><span class="comment">#  "mod_auth",</span></span><br><span class="line"><span class="comment">#  "mod_evasive",</span></span><br><span class="line"><span class="comment">#  "mod_redirect",</span></span><br><span class="line"><span class="comment">#  "mod_rewrite",</span></span><br><span class="line"><span class="comment">#  "mod_setenv",</span></span><br><span class="line"><span class="comment">#  "mod_usertrack",</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p> 编辑/etc/lighttpd/lighttpd.conf文件，将以下代码新增至文件结尾：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">alias.url = (</span><br><span class="line">    <span class="string">"/static"</span> =&gt; <span class="string">"/opt/openlava_webui/openlavaweb/static/"</span>,</span><br><span class="line">    <span class="string">"/media"</span> =&gt; <span class="string">"/var/www/olweb/media"</span>,</span><br><span class="line">)</span><br><span class="line"> </span><br><span class="line">fastcgi.server = (</span><br><span class="line">    <span class="string">"/olweb"</span> =&gt; (</span><br><span class="line">        <span class="string">"main"</span> =&gt; (</span><br><span class="line">            <span class="comment"># Use host / port instead of socket for TCP fastcgi</span></span><br><span class="line">            <span class="string">"host"</span> =&gt; <span class="string">"127.0.0.1"</span>,</span><br><span class="line">            <span class="string">"port"</span> =&gt; 3033,</span><br><span class="line">            <span class="comment">#"socket" =&gt; "/home/user/mysite.sock",</span></span><br><span class="line">            <span class="string">"check-local"</span> =&gt; <span class="string">"disable"</span>,</span><br><span class="line">        )</span><br><span class="line">    ),</span><br><span class="line">)</span><br></pre></td></tr></table></figure></p><p>开启Lighttpd：sudo systemctl start lighttpd</p><h2 id="5-9-创建登录用户"><a href="#5-9-创建登录用户" class="headerlink" title="5.9 创建登录用户"></a>5.9 创建登录用户</h2><p>为了可以登录网络接口，需要创建一个用户，在其中设置自己的用户名和密码（创建成功以后可在网页右上角的Login登录并提交作业）：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">[jensd@node01 opt]$ sudo python /opt/openlava_webui/manage.py syncdb</span><br><span class="line">Creating tables ...</span><br><span class="line">Creating table django_admin_log</span><br><span class="line">Creating table auth_permission</span><br><span class="line">Creating table auth_group_permissions</span><br><span class="line">Creating table auth_group</span><br><span class="line">Creating table auth_user_groups</span><br><span class="line">Creating table auth_user_user_permissions</span><br><span class="line">Creating table auth_user</span><br><span class="line">Creating table django_content_type</span><br><span class="line">Creating table django_session</span><br><span class="line"> </span><br><span class="line">You just installed Django<span class="string">'s auth system, which means you don'</span>t have any superusers defined.</span><br><span class="line">Would you like to create one now? (yes/no): yes</span><br><span class="line">Username (leave blank to use <span class="string">'root'</span>): jensd</span><br><span class="line">Email address:</span><br><span class="line">Password:</span><br><span class="line">Password (again):</span><br><span class="line">Superuser created successfully.</span><br><span class="line">Installing custom SQL ...</span><br><span class="line">Installing indexes ...</span><br><span class="line">Installed 0 object(s) from 0 fixture(s)</span><br></pre></td></tr></table></figure></p><p><img src="http://ws1.sinaimg.cn/large/b40cee9bly1fqnt5x6zivj20sh04ojr9.jpg" alt="Markdown"></p><h2 id="5-10-给Django项目指定端口号："><a href="#5-10-给Django项目指定端口号：" class="headerlink" title="5.10 给Django项目指定端口号："></a>5.10 给Django项目指定端口号：</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo python /opt/openlava_webui/manage.py runfcgi method=prefork host=127.0.0.1 port=3033 pidfile</span><br></pre></td></tr></table></figure><p>至此，可在浏览器中输入地址<a href="http://master/olweb" target="_blank" rel="noopener">http://master/olweb</a> 访问openlava web端！</p>]]></content>
      
      
      <categories>
          
          <category> 教程 </category>
          
          <category> Openlava </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HPC </tag>
            
            <tag> Openlava </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/hello-world/"/>
      <url>/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><a id="more"></a><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
