<!DOCTYPE html><html class="theme-next muse use-motion" lang="zh-CN"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=2"><meta name="theme-color" content="#222"><link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2"><link rel="stylesheet" href="/css/main.css?v=7.1.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.1.0"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.1.0"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.1.0"><link rel="mask-icon" href="/images/logo.svg?v=7.1.0" color="#222"><script id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Muse",version:"7.1.0",sidebar:{position:"left",display:"post",offset:12,onmobile:!1,dimmer:!1},back2top:!0,back2top_sidebar:!1,fancybox:!1,fastclick:!1,lazyload:!1,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><meta name="description" content="前文中介绍了一些用TensorFlow实现神经网络的例子，但是如果你不懂神经网络的一些基础概念的话，会看得一头雾水。所以本文将介绍以下神经网络中常用的关键知识点：  前向传播与误差反向传播 激活函数 softmax算法 损失函数 优化器  当然侧重点还是在使用上，目的是让您理解使用的道理即可，不会涉及过多原理、底层算法知识等。"><meta name="keywords" content="神经网络,激活函数,损失函数,softmax"><meta property="og:type" content="article"><meta property="og:title" content="&lt;未完成&gt;深度学习基础——神经网络关键知识点简记"><meta property="og:url" content="https://qiming.info/深度学习基础——神经网络关键知识点简记/index.html"><meta property="og:site_name" content="QIMING.INFO"><meta property="og:description" content="前文中介绍了一些用TensorFlow实现神经网络的例子，但是如果你不懂神经网络的一些基础概念的话，会看得一头雾水。所以本文将介绍以下神经网络中常用的关键知识点：  前向传播与误差反向传播 激活函数 softmax算法 损失函数 优化器  当然侧重点还是在使用上，目的是让您理解使用的道理即可，不会涉及过多原理、底层算法知识等。"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2019-04-18T14:59:52.778Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="&lt;未完成&gt;深度学习基础——神经网络关键知识点简记"><meta name="twitter:description" content="前文中介绍了一些用TensorFlow实现神经网络的例子，但是如果你不懂神经网络的一些基础概念的话，会看得一头雾水。所以本文将介绍以下神经网络中常用的关键知识点：  前向传播与误差反向传播 激活函数 softmax算法 损失函数 优化器  当然侧重点还是在使用上，目的是让您理解使用的道理即可，不会涉及过多原理、底层算法知识等。"><link rel="alternate" href="/atom.xml" title="QIMING.INFO" type="application/atom+xml"><link rel="canonical" href="https://qiming.info/深度学习基础——神经网络关键知识点简记/"><script id="page.configurations">CONFIG.page={sidebar:""}</script><title><未完成>深度学习基础——神经网络关键知识点简记 | QIMING.INFO</未完成></title><noscript><style>.sidebar-inner,.use-motion .brand,.use-motion .collection-title,.use-motion .comments,.use-motion .menu-item,.use-motion .motion-element,.use-motion .pagination,.use-motion .post-block,.use-motion .post-body,.use-motion .post-header{opacity:initial}.use-motion .logo,.use-motion .site-subtitle,.use-motion .site-title{opacity:initial;top:initial}.use-motion .logo-line-before i{left:initial}.use-motion .logo-line-after i{right:initial}</style></noscript></head><body itemscope="" itemtype="http://schema.org/WebPage" lang="zh-CN"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">QIMING.INFO</span><span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle">You are more than what you have become now.</p></div><div class="site-nav-toggle"> <button aria-label="切换导航栏"><span class="btn-bar"></span><span class="btn-bar"></span><span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://qiming.info/深度学习基础——神经网络关键知识点简记/"><span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person"><meta itemprop="name" content="Xu Qiming"><meta itemprop="description" content="软件工程硕士在读"><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization"><meta itemprop="name" content="QIMING.INFO"></span><header class="post-header"><h1 class="post-title" itemprop="name headline"><未完成>深度学习基础——神经网络关键知识点简记</未完成></h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i></span> <span class="post-meta-item-text">发表于</span> <time title="创建时间：2018-11-26 15:22:32" itemprop="dateCreated datePublished" datetime="2018-11-26T15:22:32+08:00">2018-11-26</time> <span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i></span> <span class="post-meta-item-text">更新于</span> <time title="修改时间：2019-04-18 22:59:52" itemprop="dateModified" datetime="2019-04-18T22:59:52+08:00">2019-04-18</time></span> <span class="post-category"><span class="post-meta-divider">|</span><span class="post-meta-item-icon"><i class="fa fa-folder-o"></i></span> <span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing"><a href="/categories/深度学习/" itemprop="url" rel="index"><span itemprop="name">深度学习</span></a></span></span></div></header><div class="post-body" itemprop="articleBody"><p>前文中介绍了一些用TensorFlow实现神经网络的例子，但是如果你不懂神经网络的一些基础概念的话，会看得一头雾水。所以本文将介绍以下神经网络中常用的关键知识点：</p><ul><li>前向传播与误差反向传播</li><li>激活函数</li><li>softmax算法</li><li>损失函数</li><li>优化器</li></ul><p>当然侧重点还是在使用上，目的是让您理解使用的道理即可，不会涉及过多原理、底层算法知识等。</p><a id="more"></a><h1 id="1-神经元的拟合原理"><a href="#1-神经元的拟合原理" class="headerlink" title="1 神经元的拟合原理"></a>1 神经元的拟合原理</h1><h2 id="1-1-前向传播"><a href="#1-1-前向传播" class="headerlink" title="1.1 前向传播"></a>1.1 前向传播</h2><h2 id="1-2-BP算法介绍"><a href="#1-2-BP算法介绍" class="headerlink" title="1.2 BP算法介绍"></a>1.2 BP算法介绍</h2><h1 id="2-激活函数"><a href="#2-激活函数" class="headerlink" title="2 激活函数"></a>2 激活函数</h1><h2 id="2-1-sigmod"><a href="#2-1-sigmod" class="headerlink" title="2.1 sigmod"></a>2.1 sigmod</h2><h2 id="2-2-tanh"><a href="#2-2-tanh" class="headerlink" title="2.2 tanh"></a>2.2 tanh</h2><h2 id="2-3-relu"><a href="#2-3-relu" class="headerlink" title="2.3 relu"></a>2.3 relu</h2><h2 id="2-4-选择合适的激活函数"><a href="#2-4-选择合适的激活函数" class="headerlink" title="2.4 选择合适的激活函数"></a>2.4 选择合适的激活函数</h2><h1 id="3-softmax算法"><a href="#3-softmax算法" class="headerlink" title="3 softmax算法"></a>3 softmax算法</h1><h1 id="4-损失函数"><a href="#4-损失函数" class="headerlink" title="4 损失函数"></a>4 损失函数</h1><h2 id="4-1-二次代价函数"><a href="#4-1-二次代价函数" class="headerlink" title="4.1 二次代价函数"></a>4.1 二次代价函数</h2><h2 id="4-2-交叉熵"><a href="#4-2-交叉熵" class="headerlink" title="4.2 交叉熵"></a>4.2 交叉熵</h2><h2 id="4-3-选择合适的损失函数"><a href="#4-3-选择合适的损失函数" class="headerlink" title="4.3 选择合适的损失函数"></a>4.3 选择合适的损失函数</h2><h1 id="5-优化器"><a href="#5-优化器" class="headerlink" title="5 优化器"></a>5 优化器</h1><h2 id="5-1-梯度下降"><a href="#5-1-梯度下降" class="headerlink" title="5.1 梯度下降"></a>5.1 梯度下降</h2><h2 id="5-2-Adam"><a href="#5-2-Adam" class="headerlink" title="5.2 Adam"></a>5.2 Adam</h2><h2 id="5-3-TensorFlow中的优化器"><a href="#5-3-TensorFlow中的优化器" class="headerlink" title="5.3 TensorFlow中的优化器"></a>5.3 TensorFlow中的优化器</h2><h1 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6 参考资料"></a>6 参考资料</h1><p>[1]李金洪.深度学习之TensorFlow:入门、原理与进阶实战[M].北京:机械工业出版社.2018-01</p><p>（未完待续）</p></div><footer class="post-footer"><div class="post-tags"> <a href="/tags/神经网络/" rel="tag"># 神经网络</a> <a href="/tags/激活函数/" rel="tag"># 激活函数</a> <a href="/tags/损失函数/" rel="tag"># 损失函数</a> <a href="/tags/softmax/" rel="tag"># softmax</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/Hexo博客中加入代码块复制功能/" rel="next" title="Hexo博客中加入代码块复制功能"><i class="fa fa-chevron-left"></i> Hexo博客中加入代码块复制功能</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"></div></div></footer></div></article></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span><span class="sidebar-toggle-line sidebar-toggle-line-middle"></span><span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap"> 文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap"> 站点概览</li></ul><div class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">Xu Qiming</p><div class="site-description motion-element" itemprop="description">软件工程硕士在读</div></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"> <a href="/archives/"><span class="site-state-item-count">23</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"> <a href="/categories/"><span class="site-state-item-count">8</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"> <a href="/tags/"><span class="site-state-item-count">48</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="feed-link motion-element"><a href="/atom.xml" rel="alternate"><i class="fa fa-rss"></i> RSS</a></div></div></div><div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-神经元的拟合原理"><span class="nav-number">1.</span> <span class="nav-text">1 神经元的拟合原理</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-前向传播"><span class="nav-number">1.1.</span> <span class="nav-text">1.1 前向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-BP算法介绍"><span class="nav-number">1.2.</span> <span class="nav-text">1.2 BP算法介绍</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-激活函数"><span class="nav-number">2.</span> <span class="nav-text">2 激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-sigmod"><span class="nav-number">2.1.</span> <span class="nav-text">2.1 sigmod</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-tanh"><span class="nav-number">2.2.</span> <span class="nav-text">2.2 tanh</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-relu"><span class="nav-number">2.3.</span> <span class="nav-text">2.3 relu</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-选择合适的激活函数"><span class="nav-number">2.4.</span> <span class="nav-text">2.4 选择合适的激活函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-softmax算法"><span class="nav-number">3.</span> <span class="nav-text">3 softmax算法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-损失函数"><span class="nav-number">4.</span> <span class="nav-text">4 损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-二次代价函数"><span class="nav-number">4.1.</span> <span class="nav-text">4.1 二次代价函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-交叉熵"><span class="nav-number">4.2.</span> <span class="nav-text">4.2 交叉熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-选择合适的损失函数"><span class="nav-number">4.3.</span> <span class="nav-text">4.3 选择合适的损失函数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-优化器"><span class="nav-number">5.</span> <span class="nav-text">5 优化器</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-梯度下降"><span class="nav-number">5.1.</span> <span class="nav-text">5.1 梯度下降</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-Adam"><span class="nav-number">5.2.</span> <span class="nav-text">5.2 Adam</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-TensorFlow中的优化器"><span class="nav-number">5.3.</span> <span class="nav-text">5.3 TensorFlow中的优化器</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-参考资料"><span class="nav-number">6.</span> <span class="nav-text">6 参考资料</span></a></li></ol></div></div></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2019</span><span class="with-love" id="animate"><i class="fa fa-user"></i></span> <span class="author" itemprop="copyrightHolder">Xu Qiming</span></div><div class="powered-by">由 <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> 强力驱动 v3.8.0</div> <span class="post-meta-divider">|</span><div class="theme-info">主题 – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a> v7.1.0</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script>"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script src="/lib/jquery/index.js?v=2.1.3"></script><script src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script src="/js/utils.js?v=7.1.0"></script><script src="/js/motion.js?v=7.1.0"></script><script src="/js/schemes/muse.js?v=7.1.0"></script><script src="/js/scrollspy.js?v=7.1.0"></script><script src="/js/post-details.js?v=7.1.0"></script><script src="/js/next-boot.js?v=7.1.0"></script></body></html>